 Real camera and things like that to make sure that mortgages and make sure that this is obvious. I'm sure this was later on. Thank what restaurants as well as our transformed as this has all this stuff because she also makes sense. The lead, your camera is going to be on source one for your starting. We're just gonna share, okay, and then you want to share, it sounds obvious. And you unshare the screen. Oh, yeah. Perfect. Okay. I have to do that every morning. You have to do that every morning. And then your source once it's here. So all the time the camera changes here, we can actually image like this is what I would suggest for you. Because since you have that one over there and then you can write down this side. And also you have an overhead camera if you want to use for base that way things. And they will see this screen and that screen and iterate. And then the only thing I want to make sure that when you're done with the computer as you look at ASU and you want to make sure you turn on. That's basically because this, I know if this stays on, that it causes a problem for the density curve. Gets crushed down, payment technology arise to switch out. The thing I think this gets everything I said is in your setup is why you're doing the one camera, basically assume shell script that checks out. We're also available so you feel a refresher can always turn on those kind of screenings on the map, which is this giant going to pop up a lot of string. That's right. And I know this was crashed. He also That's great day. All right. Thank you very much. No problem with that slope. Which has got a yes. All right, so Hello everyone and happy to be here with you. And it's also really happy to say that this is a successful plus regarding enrollment because we have or we will have I don't know when or more students that are remote students. So I'm going to start with a, with a syllabus. Just a real quick. While it's syllabus here, you have it there. I don't know how to write these things. There's no standard. Bye. And in the Mustang other microphone, I hope everyone can hear ME when they join the recording anyway. So this is my office office hours idiocy. All right. And then okay. So they classroom is not correct. It says if you tackle the fact that it's that. What else? So let's start with the, with the topics. Write this glass is, is an introduction to machine learning. So here you will see many fundamental topics that will give you an intuition on how to do machine learning. This is not a glycine which we will put together machine learning algorithms. This is not equivalent to go to the driving score. For example, say you have a car, you don't know how to drive it and you need somebody to teach you how to drive a car, right? This is not what we do here. If you get in the car and suddenly the car stops, then what do you do? These are things that they don't teach you that meme in dreams ball. Or if you want to increase the performance or you want to use the car for a different board posts are done just permuting. Here we will learn this. Thanks. All right, so the idea is how machine learning works inside the guts of machine learning. And that includes field theoretical concepts. I'm not going to go to the, inside the theoretical concepts. But we will see songs, right? This class is not. In this class has some bad reputation. People say that it's difficult. Arrived by not the ones that follow this class and, and, and finish that. Alright. It's not difficult, but it includes some new concepts. Alright? And then some of them, they are counter-intuitive. And then in some cases, well, in, in a month, we will go inside infinite-dimensional Hilbert spaces. And then we cannot trust our intuition as it is. We have to trust algebra. And so we will develop different forms of intuition, right? For example, you might have some data and you represented in a Hilbert space, in a three-dimensional space. And then one common mistake is to try and represent the data in your computer and try to see it. But this doesn't work when you have 20 dimensions. It's even worse when you go into infinite dimensions because things become counter-intuitive. I did beginning. And then when your mind is used to this concept, it's counterintuitive anymore. But you cannot visualize the data, right? As I was saying, whatever happens in aerospace, it stays in other respects. You cannot start that. And so since we cannot get inside an infinite-dimensional space, we're going to see that, right? So these things, we will go working now. I don't know why I was saying this. These are the topics. We'll start with statistical learning theory. And here we will start with some things, which is just a part of machine learning. Machine learning, you have three main, three main blocks, statistical learning theory, we just kinda learning, deep learning and the ensemble. Here we will talk about corner learning, right? And it's there. It's, it's probably not extremely intuitive, but it's the easiest way to a preference sugar. So in statistical learning theory, we will only same linear machines. Only linear. And why? Well, because then, once we are used all these concepts and we're used to the theme. Criteria are the structures and they Data Structures 2. Then we will talk about reproducing kernel Hilbert spaces. The core of this is what we call the kernel trick. It's a trick that allows us to take any linear algorithm. The non-restricted conditions, very easy conditions. We take any linear algorithm and we turn it into a non-linear way that has infinite capacity. So basically we can make the machine to wherever, wherever we want, which is not good. So we have to confirm it. All right? So we will have infinite capacity machines and this capacity, we have to control them. Then once we have these concepts learn and we practice, then we'll go two Gaussian process networks. Statistical learning theory is based on a given criterion. Here, we will learn at different criteria and we will apply the concepts of Cherokee for spaces in order to demonstrate nonlinear ships. Here we will talk about classification and regression. Primarily. Regression, because it's good enough for you to understand on this part. Where we'll finish this class with adaptive basis function models. That is different kinds of structures for our learning machines. So with this, you will have a, an overview of machine learning. You will get some practice, right? Because we need to do some exercises on. And so you will be ready to keep. Right during the second semester. I will have another class which is about deep learning. And I always prefer that students that go to my deep learning classes, they have knowledge about corner. Because then we can skip fundamental. Thanks and we can. Go deeper again how to construct such structures and make them work. This class is, it has a lot more theory, deblurring. It has a lot more products. So there is an assessment which is based on homework, quizzes. There's no exams in this class, right? I put an exam for several years. And it's always a disaster. Because in an exam I need to put theoretical concepts and I write to the progression that it takes more than one semester to get the maturity to solve this kind of problems. But you will get to there by just learning and practicing. All right, so I don't care too much about that, but the homework has to be done and it needs affords, dedicate. All right, and as some, there's some quizzes for you to just to review your, your lessons. Well, then there is a lot of thinks about how well they stand. Our syllabus. There is something about masks and vaccinations. And I hope you are able to breed that and follow this mandate from the promise, but also from the government. Know Mexico because it's fundamental for our health and those who are with us, okay, I'm not going to lecture you about that because you all know everything about businesses that we are. So please, if you have any doubt and how to and what are the rules for attending the class? Take that as mean and I will try to give them answers. Yes, I will. Classes be required. This class is being recorded and it will be posted on? Yes. So in any case, attendance is mandatory around this. Remote events are for you to reveal the glass. And my experience says and have been teaching this for a number of years now. If you attend the glass, you finish. You, you, you won't have any problems arise. When sometimes you will stall with the theory or with the problems you've come here. We talk, we fix the problems we made in office hours. And at the end of the semester, you will done. If you don't adapt glasses, then you will have you will struggle, but you want to have the contact with the instructor and this is going to be dafur you. All right, So yes. So we have a number of students or nine here, everyone. Hello everyone. And I hope you can listen to my voice clearly with no problems because I don't even know where the microphone is. So if you have any traveled listening, just let me know or you can talk, just unmute yourself and say something, right? I will be changing from this B0, which is the white worth, to the projector screen. If I forget or you have I told you to said let me know, arise. And I really appreciate if you if if I see your faces. Whereas I think that that's that's the bare minimum that I need to explain here. Any questions? No. I just don't want wasn't about the project you remember I mentioned about, I mean, I was looking into oil Threadless them. It was like national life and yet yes. So you mentioned that. Oh, yeah. Well, so the students, they can propose a project arrived and as well. This will Third Wave song Bo, all of sound or part of the homework, right? But then we have to, I have to evaluate the project and what are the outcomes? Sometimes with projects, the students are too, too confident on what they're gonna do. And sometimes things have not been easy. Sometimes the topics there a way out of them because they have the context, right? So I have to evaluate first, but projects are, well, right. And there are some students that are working in that bar in at another other departments. And at least one professor told me to, to do a project in common with the students, right? So if you have an advice or that wants to do something and machine learning in this context and write a paper or whatever. I will be very happy to, to help, to assist, right. But I need to evaluate first the proportions. Thank you for money. Any other questions? Yeah. In this case, let's start site. You click on Course Home. I didn't update it the dates, right? I'll do it today. But here you will have, if we click here, you will see, let's go to Student View and see if you click on here. So you will have an overview. They dominated with a picture of somebody and then a motivational sand dance around this. Brian is a musician. The rest they are assigned. It says play until your fingers bleed. Right? My one of my guitar teachers. This is what he told me to do. I tell him, when do I need, how much do I need to practice every day? And he said that play under your fingers, bleed until you are you say I can practice anymore. Right. So don't do it as much as you can. I know that you have many other things to do. Right? But that's the only way. All right. Also, Richard Feynman said that you keep learning things until you learn something that nobody else had learned before. And this is science. And that is my motivation of thank you. Now, so here you have all the, all the lessons, right? And the quizzes and the assignments. And every, in every module you'll have for this discussion over. And then I take a look to them from time to time, and I answer questions by this discussion worse, therefore, you to make questions and answer them, right? I will be just a moderator. If somebody says something which is not totally correct back and I say, well, yeah, but we need to change this or that. Usually people are correct in what they say when they answer. Right? So let's start with module one. Money-wise might think the, I think so. Yeah, okay. It doesn't appear, it doesn't matter. So let's go to the introduction to this class and see if they spoke. So here, basically what I have is what I explained. That's mean. I'm a professor. I also have all this. What is the time to give this kind of annoying? I don't know what to you. I'm Alec. I will still doesn't know the password to get into the thighs. So let's say so you have to go to Zoom meetings. And then so that's, let's go to instruction and invitation. And then is fascinating denotation, sorry, invitation to go down. Inside. You scroll down. Yeah, let's go now and I'm going to change this password because I thought that. So it's 9571493 to the picture. Right. Okay. Thank you. I'll just change this thing. And I think that I'm screen-sharing, but I will talk about complexity a lot. We have to minimize complexity in order to thanks for making the water optimally. All right, they, they racers at a Occam's razor. Principle will become a theorem here. So the Occam's razor is a mathematical truth. Sometimes happens that things are too complex and data. Well, anyway, so that's me. I hold a chair which is sponsored by the King of Spain. This is a curiosity thing. I've been working in machine learning for 100 years since 1988. I finished my PhD, 99. So in machine learning for communications. And I thought I had been teaching many, many subjects for the different classes. Machine-learning, probability, signal processing, communications, electronics, communications electronics, magnetics, certain ways. I don't know anything, many things. So that's my experience. This is something that you need to do now. We have some objectives, right? We have to learn the fundamentals of machine learning from a theoretical point of view. And also we need to learn how to apply machine learning to real life problems. Well, I, I'm not going to use real life problems, but almost all the data that we will see in order to do machine learning, it's made up, but it's data. The data that you will see. It has a justification, right? Since I've been working in communication so many years. Some of these examples will be in communications, or I might it's fully justified. So you're going to do our research. At least. This is where you want. Sometimes people, they follow other bots, but in principle, you're going to research, research needs to be published. And well, I didn't publish too many papers in my life. And in your eyeball is maybe a Best Buy. I think Oregon, many years. Okay. So it's not that my MBA is huge and I have to say that I didn't successful publishing papers. So Olivia, Olivia business omitted, they ended up being published. And so I wanted to share with you my thoughts, my experience and how to write a paper so it has more, better chances to be published. So we will, we're going to write two papers. But I don't mean to publish that. It's going to be a simulation. I say you're going to write your beverage in super vector machines and you're in a Gaussian processes just pretending you already regional office. And we will see how to put everything together in an efficient way. From the introduction to the concussions with all the theory and all the experimentation in a, in a, in an efficient way, right? You want to publish your paper to be published, and then you have to go through a filter, which is a peer review. So other experts in the area will review your paper if they understand it, they like it and they think that it paper, it has, it contains a novelty than the paper has a good chance to republish. And we have to make all this thing understandable and instructor, there are many ways to write papers. I'm just going to share with you my my experience and my thoughts. It's not what I'm going to say. It's not written in stone, right? So you can always do other things. Am not going to share with you the way to write them, which is my way to write them. And so you will get some experience with that. And that's it. All right, also, you will have a chance to peer-reviewed papers. What else? Below this? We have to attend the class, completed quizzes, the quizzes, the homework, and, and use the date, the discussion worse, whenever you, whenever you write. So too are the homework or journal papers are works that you have to price in the form of journal papers pipetting. And these are the these are the modules. We have 10 modules down from above. Mine actually. Alright, so from two to eight. These are the core modules, the modes in which you will have, we will get the most knowledge, right? And this two, they access, right? Well, we'll go through them if we have time to do the type of cells. So pulsatility is almost cases. Programming assignments. And, and there's two papers. Knowledge that you have to have enough. Basic algebra and probability, right? So this class is kind of self-contained. I won't require you to get knowledge that I don't explaining falling and a whiteboard or in the slides. But it's a visible that you have this knowledge are ready because what I'm going to do is to review that thing. We will review these concepts, right? In algebra. You need to know what it is or space. What is a dot product? How to multiply two matrices? We want to use any cancerous here. So we want to require tensor, Tensor operations. My matrices, a particular index. And so we will use a particular notation in which all the vectors are columns. Right? Whenever I write symbol that corresponds to a vector, it's going to be a column. If I want the vector to be a row, I will put the transpose operator, right? And so this things, we will work them out. But I want you to review if you have if you have downs in this concepts, I want you to take a look through your notes or your algebra. We're saying with probability theory. I will explain the probability starting with the base theorem, right? So I will explain what is the conditional probability, the concept of conditional probability, independency and the very stiff while a certain firstName. And this Bayes theorem is very important response. And I always say that you, if you get a job and they ask you about your name and you hesitate, There's no problem. You hesitate. I don't remember my name. Oh, yeah. No problem. There. They're not going to fight. You don't remember our base theorem. They might. Alright? So I want you to remember the Bayes theorem better than your name, right? And I will insist a lot. Hey, in this classes, you will hear my favorite sentence, which is posterior proportional to prior times likelihood. Maybe you don't really know what a talk by talking about. Now, I will expand. And this is something that we will use a lot in this class and also in probabilistic machine learning if you attended classes next semester. And this is fundamental in machine learning. So I want you to, to have basic knowledge of ideas and also take a look to Matlab or Python in order to do their homework. Alright, I'm going to teach you my language, Python here. But that's something easy to understand, right? Python is very easy. It's slow, but it's easy to understand and it's very well suited for machine learning and AI. And you can use method. That's it, right? There's a lot more here, but it's about them. Which one of these, each one of the models might even take a look to the emulator. So you have no cross terms. Where do I go? What are business? You have no questions. I'm just going to start. Doesn't work. So let's start with the introduction to machine learning. And so they should be opening. So there are many definitions of machine learning, right? I'll show you mine. By computational intelligence. In general, or artificial intelligence is intended to give machines the ability to learn from data, from what they can observe the environment, right? And then take a decision as a consequence of what is learned, right? The environment as the data that they acquired. And what is a machine? A machine is anything that has a processor, a sign that can do logic operations themselves, right? So anything that has a processing side, yes, in principle, suitable for any kind of learning of machine learning. And as you know, better than I do, a robot scars, home appliances, smart grid, the electrical grids. When it's smart, it can hold processors that do machine learning, so they take data and use it to take decisions. That's it. All right? But how do I define machine learning? Learning is a process. In general, learning is a process where the input consists of any available data. This is inductive learning, right? Inductive where we observe the world and then we get the data. And from the data, we extract the information. Sometimes we call them who got that information, the features of the data. And using this information, we infer knowledge. And this is what we're going to do many times here. Yet data, gather the information or the features. There are many ways to do that. And then extracting from a extract that knowledge. And again, there's many ways to do that, right? What is an example of this? Well, you'd get an MRI, a 3D picture of the brain, right? Of many people. Some of them they are controls, some of them they are cations of a given disease. And so this image, it may have 20000 to 0.5 million voxels, which are pixels in three-dimensions, right? This is the data. The data is a set of 10 source three-dimensions with numbers inside. We put them, we vectorize them, we'll put them in a vector. So we are in a space of 20000 dimensions or more. Right? So this, as we will see soon, this is a lot of dimensions. Provided that we want to have too many patients and controls. 100,100 thousand patients and controls, well, we have 20 thousand dimensions. An insider's is 20000 dimensions, only 100 thousand data patterns or 1000 vectors. So this space is basically empty. And this is something that we will work out. In a more conceptual way. The space doesn't contain almost anything. We have empty dimensions. So we have to reduce the dimensionality. But we have to do it in a, in a very, in a very careful way in order not to destroy the information. What we do, for example, is to take these areas of the brain that contain the information about the disease. And this is something that we can do in many ways. For example, having cite information. Well, the doctor said that, say that this information is in the amygdala for in the motor cortex, whatever. Okay, So we get the amygdala, we discard the rest. And from that, we get, from the boxes of the Amiga, we get some statistics. And so we pass from many dimensions to a few. A few numbers that are significant in order to distinguish between patients and controls. And that is the information. And this is what we pass to a learning machine in order to detect what are the differences and classify between box. That will be a simple example. So what is the knowledge here? In this case? Their knowledge is what we decide over a new passion, a new person that is not among this training data that we use to teach the machine. And when they machine the tax or classifies between classes, then we got knowledge. But if we don't know whether this is the disease is and we construct the machines so it automatically focuses in these spots that are significant for the disease. Then this is another class, another way of getting not the machine is telling me when aware that he says is in the brain. All right? So this is knowledge. Knowledge as things that we know, that we didn't know before. Of course, we can do this in many, many ways. This machine learning covers a spectrum of different techniques. And we will see some here. So that is how bright machines do not take decision from our knowledge. This is what we would call that an expert system where you add prior knowledge already infer by humans. And then they let the machine decide you're seeing a tree or something like that, right? But this is not what we call a learning machine, right? Learning is from data which is always fed in form of numbers. So the data is colors or shapes. In any case, we always need to pass this into numbers one way or another for another, for the machine to be able to work. That is an example. We have a machine that classifies between cows and horses. And so what they do is, what the machine does is to take a picture of the animal when it cross through other appointment. All right. So I know I need to know whether a cow or a horse pass through the door. But they do is they put a sensor that Victor, and then I measure the white and the height of the animal. And so we construct an algorithm, learns to split the points in the space dependent on the bus. What is, what does this mean? Well, I first extract two features of the picture. The victory, maybe VGA, whatever, many pixels, right? I don't, I don't need all this. I just need two numbers. The high anyway, this is something that it might be easy to get. And we assume that the horses are taller and skinnier and the cows are wider and shorter. This is prior knowledge or out, but I believe that they apply in order for them and for my machine to be symbols simpler. That's right. So I get this to animals and when I get a cow, while the cow as fat, the horses skin. So I take the bitter start the information and do a classification. Now, how do I do this classification? And this is the beginning of machine learning. This is the easiest possible or the machine that would suck. I know that many of you may know about that. I'm not I'm not I don't want to insult your intelligence. All right. I just, I just want to give you a really, really simple example, silly one. So we introduced this example, some concepts that we will be using for the rest of this class. And this is a concept of feature space. So the machine takes the height and weight of each subject. And these teachers are represented in a vector. And this vector, it has two dimensions. It's just two features, right? And in one of the artists like with the height and the other one is for the white. And then I construct a vector x that contains both. Write this vector. It will in general contain another dimension which is used to construct a bias. But we will, we let this for this point, I just have this vector that contains all the features, in this case two of them. And I, so I do that for many subjects. And that is a human classifying horses and cows. As you can. Same horses are in the upper bond here. And Gauss argue, alright, Are, these are Swiss, Swiss cups. What? Black and white, so that the horses, they have and in average height, which is higher than the ones they are the gaps. But if I only see the height, what I would say is a rejection of this data over this axis and everything. Well, they mix it. Mix. If I only see the y is going to be the same. So these two features, by themselves, they are not going to be significant. Just a little bit of the difference between both classes where both ions. But when I put them together, then I discover a structure. And this is a study in which I have two clusters of Theta, one plus the protocols, one recessive for the courses. And this is one I want the machine to discover why itself. Recall, here I have two dimensions. It's easy to see that. And then I can just draw a line, and that's it. But what if I need 20 dimensions? Right here we see clearly that we can infer knowledge. We cannot classify based on one picture way too. It might be the case that we need more than two. We might need Twain. In this case, we're going to see the data impossible. But we can construct the machine that using a given technique discovers the structure of the data and places classifying hyperplane between both. How does this thing work? Well, in this case, imagine that we have a machine that these others, that they separated a hybrid plan should be around him. And how do we put this a month? Whoops. I did not. Which one? Can see? Missing two slides. Okay. I guess I need to do it. You might see white board. So it's too late. It's like you can tell me if I'm if I'm late, you can tell me a the glass is finished. I will respect that. Okay. So I'm sorry, I did an exam. It's hidden. So I see you next week. Next Wednesday. Send me any questions and I will be in my office now for office hours. Thank you very much. And yes. For the CAPGI picture where it's like part of nature, like the cow, horse had white sheet, where to differentiate between the pixels, right? Like, how do I get that number? Easy. Right? I have my, this is my my barn and hearing screen dimension. Great. Okay. And then how the animal right here is the camera theorem, but they're good for I. And so this is the camera. And so were they going to get a bitter, I Have a Dream things. And then they shape of the animal objects, right? And then so again, I can turn the green offering, okay, take the green tick and distinguish between the brain and any other color. And then just black and white, and then just on the y axis. But how far is it to get there to measure this measure using is it techniques can select 20 minutes. Yes, I just noticed that. I just noticed, sorry about that. Learning. That happens to me. I'm very absent-minded. You will, you will say that. So I have these two clusters, or at least hyperplane errors, which is aligned in this case. And service line here is defined as the following. This line goes through the origin. All right? So this line is define us. W1 X1 plus W2 X2 equal to 0. What does this one, for example? And this is x2, right? So all the points in this line satisfy this equation. This is the definition of a hyperplane. In general, we can construct two vectors, x, which is x, x1, x2. And I always put our line below four in order to, in order to denote that this is a vector in W, is another vector of parameters W1 and W2. And then my machine can be written as for the hyperplane can weaken. The hybrid run time, can be written as w transpose x equal to x0. And SBS dot product, a dot product between the set of parameters and the set of vectors that live in the same space. So this is the first concept. The dot-product is w transpose x is equal to the sum of x i times w by 49 equal to one. To leap for me is the dimension of the space. In this case there is two. This is a dot product. And so all this points here satisfy this frog. Now, what is W? W is a vector. This, which is normal to this hyperplane. W is this, this is.org vector that points towards the opposite direction. Let's assume that my vector is pointing towards this direction. Guess the summation. What does that leave out? The capitally. Thank you. So now w, it has this property. W is always a vector, which are you asking for? Hebron. So, alright, and then let's assume that we have about a bone in here. And then we do the dot product between w and this point. So we have now what they call y. Let's call this point x. Then y is equal to w transpose x. They answer, they read, they output cell phone. It's not going to be 0. So since this one here is represented by this vector, and this vector has with respect to this one, a number which is less than 90 degrees. Then y will be higher than one highlight zip file. So here, this can be heightened. By pets. Have a point here, which is x prime, will never have an output W transpose X prime, which is going to be negative. Right? And this is something that you can prove in many ways. But using the definition of cosine of angles, they actually easier with right here. The angle is higher than the 90 degrees, so it's going to be negative. And this is the way in which we classify between cows and horses. Cows will have an output which is negative horses and our witch. And so we will be doing this for ossification for the rest of this class. No matter my machine is linear or non-linear. What is a nonlinear machine? Well, let's assume that we have some sort of house. I don't know, Longhorns. I don't know. Whenever that they are tall and skinny. There will be here. So this will be in horses, this is cows, and this is cos 2. So then we need something that is not aligned anymore. It might be something like that. Right? So this algebra is not valid. While we will use a different algebra by, in this different algebra. My problems will keep being linear. And we will kind of solve these problems using linear approaches. Right? So that's it. But in general, so in general for the rest of the class, my machine will have this shape and buy, this machine has not this one, but this original linear machine. It has a restriction, which is kind of annoying. What does a restriction that I have in this machine taken? Yes. Yes, it goes through the origin is a blame and then as a hyperbola and write n as a hyperplane. So it should contain the origin because it's a space, right? And so we have a problem where the clusters are like that. I get unsalted. I need an affine space, right? So we're in a space. In this case one I mention that can be placed here, but we are bias. So we take it out of the origin. So this is another barrier space, but it's an affine space. So this is strictly speaking, non-linear. Height is non-linear because it doesn't contain the origin. By, for us, we will consider it linear because it's a line or a hyperplane in general. So 111 machine that, that performs an operation like that is simply written as y equal to w transpose x plus b, where b is, well, these are two vectors, a and b is a scalar. Hammers bank. And so for us to prove that, that the same principle holds about whether they, this vector and deploying they are, they describe and I know of more or less than 90 degrees. We just need to think of it as this. By itself. By adding a bias. Equivalently, we are running. I mentioned I'm an extra dimension to the space which contains a scalar or constant, one. Right? People used to call this dummy variable. It's not adequate. Timestamp. Is it better? Right? Yes, not dumbing is another ray or it's a constant and we put a one arbitrarily. And so when we multiply, sorry, this is a product. When we multiply this, that this, this is equivalent to this, right? This is equal to W1 X1 plus into dimensions. So plus b times 1. So this is a dot product between this set of parameters and this background three languages. And with this, we have a general machine that can basically specify anything, right? I am not as, as long as the classification is linear so that the machine is optimal. Prefix layer weights are linear or will need to do more things, right? You will see it's extremely easy to do that. So that's it. That's, these are the slides that I mixed. This is the easiest machine. Now, how do we pitched them? Right? So we need this or this one to be in the right place. What do we do? In machine learning? There are two things that are more, thanks. All right, but let's start with this too. I will, I will, I will actually mentioned, thanks. Important. First, the structure of the machine. For us. All the machines will have this structure. This time. For this, which is equivalent, right? This is the structure of the machine. You can represent it. Using algebra or even represent that in this case, multivariate case with a drawing, right? Or you can represent it with a diagram. So you have your payment, your features. And then, so when you do this to multiply each one of the features times a coefficient or parameter, and then you add them together. This is a graphical way of representing the structure of the machine. And here you see an actual struct. Then there is another thing related to how to teach the machine. And this is the right. Once we choose our stagger, this one for us, then we need a criterion to optimize a machine by criterion to get the output that we want from the machine. And once we have this criteria, then we have to implement it using mouse and then using a program in a computer. And this is the algorithm. And these things should not be mixed. If you mix these three things in a paper in becomes difficult to understand or right. And I've seen that in many papers, they do not distinguish between the three. And it's so easy to the saints like that. Structured, stricter criteria. Our three tanks, they of course they are in, they are related. Some criteria can be applied to some structure and some algorithms. They can be applied to some graduating. From a great deal, I can, I can derive different algorithms to achieve the same objective. Right? So these three things, short-term, criterion, an hour, and then how to find our criteria here. Well, there are many. There are many of the most popular ones are wrong. Most popular one, or the easiest one is the minimization of this white paper. Right? So here I have a set of data for which I know the labels. I assume that this cows, they have a label equal to plus one because I1, I want a machine to get a positive output. And for the Gauss negative, because they all live our life, it doesn't, right? I put plus one here as labels and minus one. And then I adjust these weights. So they square error between the output of the machine and the label is the minimum. Mean square error is let's call this. Let's call this y. Then. Let's call this. Let's call this point. And then they end for now the label. We can call it L. So this one error is equal to 0, y minus L length. And then mean squared error is equal to the expectation of the error. How do I compute the expectation of the error? Okay? Oh, there is a role in his path. For every question that I answer, that I am every Muslim they put the answer is no. I compute the expectation of the error. The answer is no. Why? Does this the positive values and negative values that Kubernetes neutralize each other. So the outcome will be, but now this will be always positive. Square root squared. That is a problem-solving for feature films. Let's formulate a question differently. How do I compute the expectation of something? The expectation of a variable v. What is expectation of available? The p-value. No, no. In general, the variable v, The expectation is equal to V times the probability of the differential of B. We agree that, all right, or if you want for, this is for continuous variables, this variable p, y. So the error is given by, so of course for the, for the holder might be discarded, happen they'll be much. What is the problem with this? Now we have to it. What is the problem of doing things like that? The main problem. Second, is hard to interpret. It. It might be hard by, even if it's hard when there's ways to, to do integration numerically wherever the membrane. This is, if we could do that, I will not have a job. Machine learning would be totally useless. By, why do we have machine learning? Because we don't know p. We don't notice, right? So the expectation can be computed. There is a distribution with unknown. Now, we got to your answer. The expectation of V can be computed like that. And this is what you meant. This is what we do. And this is the best we can do given the weak law of large numbers, right? I will re, lot of March now. Alright, so the expectation of the squared error is 1 over the sum of mirror school. And this is my gradient. And we will be downloading this during the names. And this, and that. This is going to be a full example from, from cover to cover of the easiest possible machine learning machine that you might have. Thank you very much and I'll see you next session. So when you write papers, repeatable architectures, like yes, this is not a vector is they hadn't tough. Now I would say use it for an estimated signal or estimated it ever be willing to this foundation.