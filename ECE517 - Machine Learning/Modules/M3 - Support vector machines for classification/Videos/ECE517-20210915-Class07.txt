Alright, so let's, let's start from the beginning of the present module, support vector machines. And right, I've been told that this was a little fast. All right. So I got to slow down. So we're going to do is to start from the beginning, like summarizing periods. So everything starts with classifier, binary classifier with a given structure weights. We know very well, which is w y equal to 0 when you transpose x plus b, where w is a vector space, beam dimensions, X is rather new dimensions. Y is the label, herbicide label. So we have an error, right? This is the assignable. This is the estimation. So between the label and the estimation, we have an error that we're trying to minimize. So the first concept here is h, which is the VC dimension. And as you probably know very well already, h is equal to a nonlinear machine. H is equal to d plus 1, right? So if w and x Bailey in a space of B dimensions, h is equal to the plus end. Which means that this classifier is able to classify in any arbitrary way, d plus one points. And this then is a number that tells me what is the expressive capacity of the machine. So that the power of the machine to classify things. If the number of data we have is less than d plus 1, then the machine is able to classify anything regardless of the distribution of the labels. And then this is bad because it is about because during the training, when we know the labels, the machine is able to classify everything with 0 apples. But in practice, my problems, they won't be necessarily linearly separable. In reality. Right? By half a problem which is, which is not linearly separable. When I have many points, they will be mixed by. If I have less than d plus one points in d dimensions, I will always be able to put classifier classifies with 0 errors. So for example, we have a problem that goes like that. Something like that, right? So in this problem is clearly non linearities about it. We'll take a look to this problem. Well, probably a good, a good separating hyperplane will be this one. Right? But now assume that for training we only have three ln, three beta, take three at random. Which is what we do, right? We take a number of data for training, and this data is randomly chosen. We do the observation of the world. And so for example, we have these three. This is my training set. Well, in the training, then I will have a separating hyperplane which is like that. But the abdomen will be this one. And this is because the running diameter dimension here is three. So we need to be able to apply a gradient that minimizes this effect. In this case, it will be sufficient to ignore one of the data to get something which is more reasonable. So if the machine is able to ignore the sample here, then we will have something which is more reasonable than general. When we want to do is to limit the damage. Harmony is dimension of their machines. This example is silly because we are dealing with two dimensions on it. But if we are dealing with 100 dimensions, then the problem. So Cage is a big key here. Now. There are several theorems. And one theorem says that the risk is bounded by the available address plus a term that we call structural risk. First, what is our baseline? R of alpha? Alpha being a set of parameters that define my machine. This is equal to the expectation of the error. That this is something we cannot prove it. But then we have this theorem that says that this race is bounded with a probability. With probability equal to 1 minus a quantity eta is bounded by the beta risk plus a term that we call the dot raise. That depends on depth by me turmeric is Iran shot. That depends on the data, but inversely. And also it depends on mu. But this NEO is arbitrary. And so this empirical risk is the expectation of the error during the test. This is the observed error during the training. Recall, remember that big on Greece, we computed as one over two n times the sum of y and minus w transpose x plus b m, or n from one to having over. Right here. I'm forgetting about this notation where we are back. Now. This is the north, right? So when we have an error, this quantity is equal to two. When we don't have an error. Because education is correct. This is Sharon from now as well, because education is correct, this quantity is 0, but rather by the 2 times 2, then this is the observed error of my right. I'm sorry. And this is something that doesn't depend on the data on an advanced age. And it eventually. And this is the key concept that leads to what we call the structural, trust me, principle of a conductive. So database organizational principle while battling blanks. This philosophical terms, right? This inductive learning. It's inductive learning because we learn from the observation. This convert to be dug deep learning. We don't need that. They'd like the learning. When we write theorems. They do not come from the observation by pure reason. It machines, machines that we know they do not do. Inductive reasoning just end up. Hi, this is related to name, guile and completed a theorem and other things. My dad's does philosophy. You will have a lot of it in the box by partner if you like, this kind of stuff. So this is the theorem and this happens with this probability. Now, graphically speaking, what do we have? Well, if H is dimension is very low, the, the rays are Alpha, as a function of age will be high. The machine will be very, to seem right. If we use our two simple machines than the other, maybe very high. Then if we increase the complexity or the capacity of the machine and the machine will be able to explain the data better. And then we will see that the anaerobic quizzes. But then when the machine is too complex, then well, the explanation won't be that good. Basically what it does is to increase again. This is what the theorem says. Why this effect? Well, when they in complexity is too low during the training, the error will be high. The machine during the training will be doing a good job. But if we increase the complexity by the capacity of the machine age, then they training error will go to 0. Dy is the empirical risk. The same time. While that, since the machine is able to classify all the training samples with an arbitrary, no matter what happens, is that this machine is going away from the actual distribution of the data. And it's just learning each one of the samples. That's it. All right. Here, we take into account that there is a distribution of the data. But away from this point, we basically are putting all the black dots on one side or the white dots at the other side, regardless of the distribution. So the machine is not working properly. And during the test we will have an increase of error. And this is what we call the stockholders. This is David stockholders. And this is, this is what happens in any learned English. If we change its expressive capacity by the machine. Sorry, the theorem also says that this stoked about race tends to 0 when the number of sample stamps to infinity. Think of deep learning. Well, you know, about a little bit about the learning, probably you know that they're learning. You have very complex machines with a high number of parameters that they are structured in layers, right? We'll start with this next semester. These machines, they have thousands or even millions of parameters, right? Even the first deep learning machine, they, them first convolutional neural network used by generally, in the original paper. He tells how many parameters we have and it's Craig, what we have tens of thousands of parameters in summer if somebody types of predictions. So they are very complex. It's not that we can compute a bunch of them because I mentioned, that's such a shame. But we can validate high because we have a lot of parameters to optimize. What happens with these machines is that in general, they need a lot of data to be trained properly. And this is a particular case of this theorem. Says, well, if you want to reduce this quantity, which is a measure of overfitting, you need to increase the number of theta. Then I'm going to data has to be way larger than h. That's the reason for, which is deep learning in general. In general, not always, but in general than in deep learning needs a lot of data. Here we're talking about machines that they were better with not too many data right away. And we will see why. We will see all those things. So. That is basically the principle of minimization on the structural effects. What we have to do is to find this point, this area here where the performance is the best possible. What we do that just adjust any complexity to the optimal pay. There is a problem with that. The problem is that this cannot be done for many reasons. First, there's risk. We cannot compute it. Said one. This age, we're going to compute it either. And third, this week I'm going to build it when we can deal with that. Because it's not mathematically tractable in practice. It's not differentiable. It's something that it's a function I got 0 or two, voluntary. No way. So this, There's, this principle. It's not construct. It will be like Shannon's theorem that says that if your code the signal properly, then when you receive it, then the number of errors is arbitrary. Love. This is why we have mobile phones and everything. We have communication. This still doesn't say, doesn't tell us how to do things, how to do it. They say, this is what happens then. Now figured out, right? And so, well, then chunk of others, e sub l We own, by the way, is a researcher that was key in, in, in support vector machines and we do not cite her enough. Isabell were young and I would very saga. They formulated the general expression of a support vector machine as we will say. How do we start? How do we think there's going to be, then we know it's bounded by this. We're going to compute it. While this we can use it with them. Alright, so let's choose something which is similar to this, which behaves the same way. So here, we're gonna choose an approximation to the empirical risk, which is linear. This is highly non-linear and non-financial. And I choose something which is linear, right? In, in minimum mean square error, we have a measure of risk which is quadratic. Here. When I choose a linear one, something that we can work with, there is our quadratic version of support vector machines or explain it because anything with it. And here we need to do is to choose something that we can control. And that changes monotonically with h. Right? So here we have a linear expression. And here we put something that we can control. And that behaves proportionately to, not proportionally by monotonically with age. So something that if we decrease, makes degrees. And that's Ed Dyess, they way in which we construct our criteria. So for this is what we do, but we need to justify it, right? And all there is about the separating hyperplanes on the margins that we explain we suddenly, the last session is a way to justify what we do here. I don't think there are other ways to justify, or a place, or they're elegant ways to justify. Why, why they criterion that we chose is consistent with this principle. So that will be two or three. Yes. Let's define I'm sorry, the maximum margin as a justification of the US the SVM criterion. Right? Now, I hope you have a bleeding when I explain to the very easy to remember, to reproduce it, Right? One thing too. Learn. And to check that you have learned is to take a pencil and paper, try to produce everything without taking a look through your notes. Right? I don't really care about the actual expression of theorem. It's there. And I don't care about the proof. It's there. We can put a limit on. We can go to Resources and say, it's not, it's not there for just this. Now. They said, let's define a margin. And then connected with us. When we have a machine, which is defined as W transpose plus b equal to 0. So all the points in this machine or the voids in this pain, they satisfy this equation. We can define us as well. Two more planes. And these planes, they are w transpose x plus b equal to minus our given quantity. Let's put a minus one arbitrarily, saying one into here, w transpose plus b x, x plus b equal to one. So all the avoids here, they satisfy this condition. Then what happens is that we can define a margin here as 2D. There is a distance. D is the distance between these two, and it's called a margin. Right? So this machine is classifying something. So we have points here. But I'm properly classified. Points here that are probably classify. And some points there will be misclassified. Right? So I'm claiming that this is the optimal machine. It's just want. And so what do we do here? Well, I wanted, what they want to do is to find their machine that has the maximum possible margin. And at the same time, it has the minimum quantity of data inside emerging. Right? How do I relate this to this? From my point of view? If the machine is very, is very large, then the machine will be very simple. And we will see again a variety of machines that have a much larger here. But this is not clear for us yet. What would be a very complex machine. But really complex machine. Here is a machine that doesn't have any sample inside the margin. Right? Because then in this case, the machine will be able to classify all the training data with no error. Let's, let's drive. So this machine, this machine here, it classifies all the training data with 0 errors. What is the margin? The margin will be defined these two points here. And here. When I said two points. So this point is right in the margin. This point here, right in the margin. And the rest, they are outside of it. Let's make it a little bit more clear. So actually we need three points. Alright? So this, otherwise this interim solutions that have the same or the same submersion. So this machine has a lower margin. All right. So decrease in the margin. Let's do a machine that naturally flips more points outside and less points inside the limit. Here, we have a machine that is able to classify everything with 0 errors. This is the machine with the maximum possible by whichever Anika, as I mentioned, which is one of a three here. And it needs three points on the margin. Basically three to be defined, to be correct guys. Other Other machines, they will necessarily have samples in some way. So that is the idea. Okay? So that, that will be the area. So if I increase the margin, the complexity of the machine decreases. Because if I increase the margin, there is no way I can find a position in which I have enough samples inside. I will for sure final position with a given margin than that lives and the minimum quantity of samples in time. But they are not going to be 0, right? This machine will be less complex. If I decrease the margin, then I might find a solution that classifies with 0 errors. And in general, the minimum margin is the minimum Monte machine is the one lives deadliest possible number of samples inside this much. Increasing the margin. Makes similar machines. So increasing the margin is equivalent to decrease pitch. And conversely, increase in the margin increases. Right? Now how about, how about the empirical risk? This machine as an empirical risk, which is 0, because there is nobody inside the margin, so everything is properly classify. These machines will probably have some errors because some samples are inside emergence. So it might be the case and some samples that are the wrong side of the mountain. So increasing the logic makes decrease the empirical risk. I'm decreasing the margin increases the empirical risk. So we see here two bombardments of criteria that are contrary, that go in the opposite direction. If I increase the margin, I have simpler machines. With a higher. If I increase the margin, I have decreased symbolic, as I mentioned, increase error and, and all the way around. So this criteria of controlling the margin is in line with what we want to note here. You see that is clear for you. But this is just an intuitive explanation. All right? We have to put things, we have to put this in a mathematical way to control the margin. If we want to follow edge. If I'm traveling, as I mentioned, and at the same time be a big risk in a way in which if we increase one, the other decreases. Now, let's go to another theorem which says that increasing they are performing their normal parameters. H sub. If I increase w, then I decrease it. Right? Under the constraints that we have. Quadratics, the chin classification machine. So if we increase the norm of the parameters, everything this again, copy this because I kind of lost. Define increase w and psi. Increase omni-channel English language, right? So machine, a similar machine is a machine that has a norm. If I increase the norm of my machine, my parameters, then there will be running, as I mentioned, increases monotonically. It's not there. We don't have a linear relationship between this and this. For example, in dimension 3, two more, I can have any possible value of w. But the manager running, as I mentioned, is limited to three. So by controlling the audio between 0 and infinity, iPhone 12, divided into monkeys I mentioned between 031313, which are the limits of the momentum I, as I mentioned in US-based. Right? So this is another theorem and it's in the books, is in the papers I'm going to demo. But then there's another file fit. That justifies this in a different way. We know here from an intuitive point of view that if we increase, the age, decreases, right? And we proved that if we increase D, Sorry, Age lending because, okay. So there are two ways to say this theorem will go to this intuitive explanation. If we increase, the will increase w, B decreases. If the decreases, then they will be traveling, as I mentioned, in gracious. So that this is a little cumbersome idle increase, decrease or no. I don't I don't know how to explain it better than it's everything is here. So then we have a practical way to control the 1700s. I mentioned falling W, the norm of w. Right? Now in line with this and this explanation, how do we construct something that moves monotonically with this? When m is something does, when it increases, disinterested, overwhelm other, we do it. Well, we defined we defined when we call this lagged variables or losses. As lagged variable is a quantity tiny fine. Graphically, this way we have samples that aren't properly classify. And outside the margin. I don't care. If I have a sample which inside the margin, I define chain. Right now. For example, I can have one value of cheat here. And then I have samples that are around. Here. Are the samples here, chain. I define it as 0. I force them. Are 0. Only when a sample is inside the margin, I define a quantity, big change, and how do I define it? She is equal to the difference between between the response of this class. If this margin, that will be one, in this case, will be minus one for the sample. And the value of the response of my glass occupational machine. So I defined this way why By times w transpose x plus b Negro is high or equal to 1 minus chamber. So robust and so far. So if, if the sample is the sample, if our sample is over this margin here, this quantity will be equal to one. This label will be equal to one. So the product is one, and then T will be 0. All right, For this case, the label is one. But this quantity will be between 10 because the sample is between these two points, these two hyperplanes. Right? So then here we will have a positive quantity. Here we have a positive quantity. This will be positive. Since this is less than one, this quantity will be less than one. So team will be a positive one, right? For me to repeat it. So for the sample, the output of the classification machines is between 0. That will be the sample was here, and one if the sample was here. So the response of the specification machine is less than one, but positive. And the sump and the label is plus one here would be minus 1 is plus 1. So here we have two positive quantities by the product is less than one. So this quantity is positive. Sales habits with this sample here, the label is negative right here, and the response here, the response, in this case here, the response will be positive and less than one. So if we put this quantity here, this quantity will be negative, right? So Ci will be higher than one. And positive. For a sample. Here, the response will be between minus 10. So we'll have a negative quantity here, indicated by the deal less than one in your videos. So here we'll have a positive quantity less than one. So it will be a positive quantity less than. Basically in some ways probably classify I4 cheat to be 0. If the sample is inside the margin and properly classify, she will be between 01. If somebody is not misclassify that case, then she will be higher level, but always positive. And then we define, we can compute something which is similar to the address by adding together all these variables and minimizing the risk. The empirical risk will be similar to minimize the sum of it's like barriers. If the sum of it's like variables is 0, remember they are always positive or 0. If the sum of them is 0, that means that all of the variables are zeros, so there are no samples inside the margin. There is a question. Alright? So if we minimize the sum of slack variables, we managed to make them 0. We will have 0 training error for short. Then what happens? We have a machine with a much more complexity and the minimum, that'll be something like that. The margin is really, really tight. You see now. So we have something that is also consistent with the theory. If we minimize the empirical risk, we minimize the origin. We maximize edge. Or conversely, if we, if we do not control the complexity and we try to minimize the number of errors. The number I was like variables or there's some slack variables that we will arrive to a machine with zeros, which means that we have for machine with a high vacuum ceremony few strategies. Right? So then finally, seven criteria is construct a machine that minimizes the squared error. Minimizing the norm of the error. Also minimize the squared error plus a constant times some slack variables. So we have to minimize this with respect to w, be subject to y i, W transpose X i plus b, less or hybrid or equal to y minus t. And where TIM are positive or 0, we know we do not all negative values of t. Otherwise this doesn't work. So this is my SVM primal functional, right? This is your support vector machine. Anybody else? The idea here is to go really, really slowly. I know this is not straightforward. When I started this back in wherever, I don't know, 201936 or something like that. I was doing my PhD. It took forever, forever for me to get the idea two interrelated. There's son of Kronos, some Gaussian processes of symbol machines, deep learning, all this stuff. And this is where a teacher, because I know there are better ways to teach, died. Just big papers, right? Believe me, I know that this is, it takes time. So let's go step-by-step. Is there anything that you didn't really understand a year? Now? If so, then what is the problem now? Well, now we have to, to optimize this in order to optimize and to use techniques that minimize functionals subject to constraints. So we have to find the minimum by this. But we hope to serve this constraints. We have to fit these constraints. So what do we do? Let's write again. So this is the primal or what I call the subarctic. The machine graduate as a function of w and b, which is above a USB and also to Pi is equal to 1 over 2 norm of w squared plus c times the sum from I equals one to n. I think I'm using. Whenever you see an IR. Well, that's cheap. Subject to y i times w transpose x i will be higher than, let's put it like that. Plus t by minus 1, hiring autism. The same. And then TI, they are higher or equal to z. And so the limit here of these two equality, they define a plane. They defined a blade, each one. So we have multiple blades, One for each one of the constraints or the data. I'm actually two for each one of the samples. Where do we put a c here? Well, we need to see, because this changes the same way as the starting address. And this changes the same way as the big arteries does spy. They are not equal, they are not proportional, right? If they were, we don't know what is the proportion. So we need to assume that. And the minimum. Both, both minima outweigh the risks and the minima of this. They much in the same point for a given quantity C, for a given value of C. But we don't know which one. Right? If we move seeing the minimum, the minimum changes, right? So we need to find the optimal value of c. So how do we solve this? We have this thing which is quadratic in two dimensions, will be w1, W2. And the dimensions that movie, something like that, right? Anybody know what to do that? So it's 120. Anyways. So we have here the value on the normal w is kernel, is a paraboloid, right? But we have in other dimensions the constraints. Let's assume that we only have one was one that depends on something. And this constraint is linear. Right? Really pedantic thing here is this, this is linear. Recall that, remember that my, my cost function was going to be a linear thing. Right here you've added. And then the constraints, let's assume that it's linear and the limit is a plane. So if we put an equal here, this is a plane as a function of w, as a function of WE b, right? So the blade goes like that. This is my constraint. It depends on W and it depends on a quantity cheap. So the minimum, absolute minimum, the one they had, the machine that minimizes the damage and running is perplexity. Dementia, I'm sorry. Is here a machine that has normally want a 0, right? That will be trivial. What we want is the machine that minimizes w. While the machine at the moment is W plus this quantity here, which won't be necessarily the origin wherever. But at the same time satisfies the condition. So the foundation is something that is around here, but the limit is here. And so the minimum nor that simplifies the condition should be here, right here. And this point, and this point, both gradients, they go in the same direction. So for example, we can say that this is minus the gradient of the condition with respect to w b. And this is the gradient of the norm of w with respect to. So in a minimum, these two grains, well as W plus z times some cheat on. So in this point, but gradients, they are proportional to each other. They are linearly dependent. So if we, I construct a linear combination of them for a given value of the linear combination, it will be 0, right? So we multiply this quantity times a constant, a given consent to treatment, we add them together. They will Vizio, right? So we're going from a formulation that finds a linear combination of both radius. And we knew that then we have a solution. What happens is that Let's see. What they want to, they want to do is to minimize this. So the first step is to construct a Lagrangian. So we first compute a linear combination of the cost function or the function of sorry, and the constraints. And we compute the gradient. Then we have a linear combination of the grades. So they might mention is equal to minus 1.5. Plus 1.5 of w squared plus c times the sum of Ci minus the sum of constraints multiplied times our Lagrange multiplier Alpha. These are the elements of my combination. Y i, W transpose X i was b minus plus T I minus one. And this one minus mu two. Right? And I add the condition that either, either they have, either the limit is satisfying or Alpha is 0. Right? So it might be the case that the limit is satisfied. In this case, this quantity will be 0, or the limit is not satisfied. And in this case, this quantity must be 0. If this happens in the optimal point, then this will be 0. And we'll do the same here. So the optimal boy, what we do is to minimize this quantity because it's still a movie, right? We have to add this condition I was thing doesn't work. So we have these conditions. These conditions, they might be higher or equal. When the condition is equal, then this quantity is 0. This might be non-zero. Otherwise. If this quantity is higher than 0, then this will be 0. Right? So if we think of it as we minimize this, but since this is negative, this is negative. We're actually maximizing. Maximizing maximum is say. All right, so what we have here is something which looks like a saddle, as like a saddle horse out of that has Convex, Convex directions and concave direction. Anyways, so this is what we have to solve. In order to solve it, the only thing that we need to do is compute the gradient with respect to ball prime of parameters w and b and equal to 0. And that is a boring algebra part, right? And I'm going to do everything here because it's in the slides. That is one thing which is worth to remember. And it's the biowaste. I computed the derivative of the Lagrangian with respect to w. The gradient with respect to w about this Lagrangian depends on W b t alpha mu, right? And so many things. When it will be the derivative, the gradient when they have here is a gradient of this is done. You have a young, we have a vector. And when I compute the derivative with respect to this quantity here with respect to w. I mean, when they have is alpha i, y i, X i. On the rest, they do not depend on w. So we have minus the sum of alpha i, y, i, sorry, x, x. And y has to equal this to 0. Remember? So the result here is w is equal to the sum of alpha i y i. W is a linear combination of the data. I like to explain to, to write this as a main thing. So we have to put here an x or the data matrix Y. And here we have all the training data from 1 to n. As we know in columns. Here we have a diagonal matrix that contains all the labels plus or minus one and say I want to match it. And here we have a vector that contains n Lagrange multipliers. We can move this thing to save. Thanks much. Here we have a matrix with all the data. So we have the rows and n columns and columns of data. Here we have a diagonal matrix that contains all the labels. We have N labels. Then the matrix should be n times n. This is n times n. And here we have a Lagrange multiplier per sample. So we have a vector with n Lagrange multipliers and it's a column vector. So it's n rows, one column. So this product, this to disappear in his private business, IBM, what we have is something that is d times 1, the rows, one column, just as w, Right? So much as this is not ball. And let me see if I can find waiting to go to for me to go get checked. So let me so here your database and all the rest to present you the recording. Yes. Rob so easily shows that it's recording. It says up here that's your screen share. Yeah. I don't see that. It's red circle. We can see a recording online, so seconds are in one line. We can see that it's recording. All right, thank you. So this is nine right now. Sorry. This is my Lagrangian. The way I wrote it here. What was exactly? And then here we have all the derivatives. These are the colors from the recommendations. And this is the first one that says that w is a linear combination of the data. There is something that we will see paradigms. I will repeat it. And it has good consequences for us. Then these are the rest. Here we get the derivative with respect to t. We have the result. We want the derivative with respect to two. To be. The result. Will still need to compute the derivative respect to View, which is not here. And here. The complimentary conditions that said that the product of the conditional times the Labor Day when the buyer must be 0. All right, we know we need to force this in both cases. And also they compliment eye conditions that we must force. Two weeks are multipliers and gallops like variables must be positive or 0. Right? Now, from 24, we see that if our vector is outside and writing alpha is 0, if our vector is on the margin, then alpha is between 0 and see. And if the batteries inside dementia or misclassified outside, then the multiplier is equal to c. Assemble inside the writing are misclassified outside. It has a saturated value for which is kind of so. Again, if the cell bodies inside of origin or misclassifying outside, then the management plane saturated for C, that's the maximum possible value of c of alpha. Sorry. If somebody's on the margin on its, on its dashed line, then the sample value of alpha is non-saturated. It's between, it's somewhere between 0 and C. And we will see that this value is indeterminant. There is determination in that. So that poses a problem is support vector machines actually. And surprisingly I advise able to write a paper on that and get it published. An interpretation of why this happens. Why support vector machines are not exactly like dance. We will see that support vector machines and Malik simulate that in order to avoid this problem. Because this alpha, it's endothermic, is between 0 and see which way do I arrow? And an interpretation of physical goods. And so it resembles, well classify and outside the margin, we force T equal to 0, and that means that Alpha could visit. And this is why we call them support vector machines. Because the machine is proportional to a subset of samples for which alpha is non-zero. And these are the samples that are either inside the margin, on the margin or outside right? So the rest of sample data ignore the samples that are away from the Pacific Ocean hyperplane. They are not used by an easy to understand consequence of that. Remember this two-port, they, even with munis worse, died, was prone to bias, overfitting due to outliers, right? Or somebody that was, well, it was fine but was way out. It actually a high error. To minimize that. We needed to bias them, achieve that with wrong. While these machines, they are robust. Somebody's is a walk as far away from the classification margin, it is ignored. What happens whenever somebody is misclassified and way out of the rest of the samples, it has a huge am, a quadratic error. By in this machine, its contribution is limited to see which is the maximum value of Alpha. So no matter where the sample is, the sample, we've learned tribunes with C, right? And that is good because these machines, they are robust to outliers, right? And this is something that doesn't always happen. Now, what is the rest of the thing? Well, we need to go ahead and find a solution for, for this, right? So, so the next class, basically what I'm going to show you is from the additions, we will arrive. Two different expressions for my machine. And we will write you a different expression for the Lagrangian. Remember the Lagrangian which is up, it's not here. It's here using the corresponding conditions. And we blend them here. Then we want to write to an expression of this that doesn't depend on w or g, it will only depend on alpha. And this is what I call ideal expression for my functional. And this deal expression after all this boring algebra, it's fully explain here, but it's kind of cumbersome. We will arrive to this expression. Right? So we pass from this primal cost function or this primary criteria that has these constraints to some expression, which is this. And it only has these constraints alpha I surely positive. And remember that I told you that we minimize with respect to w. When we must maximize with respect to alpha. Yes, this is what we do. This quantity is negative. We want to maximize it, right? The extreme point is a maximum. So now we have a different problem. We haven't solved the thing. We have to solve no product in ways. That machine has to be maximized with respect to path. But that is something that is solved using what we call quadratic programming. And I'm going to explain nothing. This is not a subject of this class, right? We're going to explain how to implement it. That's it. I don't explain it because once we have a solution, this solution will be exactly the one that I explained. I explained to you. For vectors are tiny margin Alpha is better on the margin. Alpha is between 0 and c vectors inside the margin, Alpha is equal to c. You will find the solution. You're right away. And after that, I take my office up here. And this is my right. And then will they will be tied to play with them to see examples and everything. To start, to finish today's class, we will explain how we arrived at this. How do we optimize or it's like 40. Sorry about that. Professor. Yes. Is there a list or guide for the readings you like for us to do? Week-by-week. You can use bit. Is there anywhere a guide for the readings you like for us to do each week? While I have I have the dates for each one of the modules. That's the only thing. I don't know. I guess that's the only thing that I have. If you want, I can try and write. But for example, for this week, this set of slides, right? This is wondering but re-explaining. Next week. Hey, I met the readings from the textbook separate assigned. Okay. Well, what is the problem with his boss that he's not have textbook? We don't have the textbook. And it's already all right. So the only thing, and I'm doing it for deep learning my way, but not for this class. So the only thing that we have for foreign, for this part of the, of the class is the tutorial by works, which is here. And I know it's past time. Let me so if you go to Course Home, Volume 3, overview that here you have the supplementary materials for I, so you'd click on that and you have the bigger right away. While not right away to play it again, right? This is a tutorial on support vector machines. And this is the reading for this class, for this, for this model. Alright? This is the only thing that we have. Of course, there are many books, but this is a problem. There are many books. We don't have a book with the contents of this class. So rather than recommended you several books for different aspects of the class, where they put these tutorials and two books that are accessible for free legal, right. And so the chapters I explained in the chapters are indicated in each one of the modules in as I said, in or do we go back? We're done. Right here. In the overview of the model. Right? We'll find out in supplementary materials in every one of them. Isn't good for you. Yeah. Thanks. Thank you. All right, so let's finish here and let's keep working in epsilon.