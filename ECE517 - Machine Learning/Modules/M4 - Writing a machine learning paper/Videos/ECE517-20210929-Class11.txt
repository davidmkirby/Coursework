Okay. Today. I'm going to show you some papers. And so where do you mean yes. You want is you need to submit pictures of the graphs. Raja, that for us. Yes, we'll see how it works. It says right there in my rights and also in Europe is length one. So we can start. So let's summarize all this stuff that I'm that I show you a last session one day. And it's about some tips on how to, how to write a paper. And so it's a good idea. I think. As I said, all this is my opinion. It's my my video and thanks. Bye. There are many other ways to write papers. Or is I'm not a professional Viner. Iv is trying to dive short course on writing papers with professional writers. And we have many. The URM, are they Department of English, right? By this difficult, this is always the people they want to do it. And I think that it would be a nice thing to have a class on that because this is something that is a, this is the knowledge that we learned. And also following the same idea of disseminating knowledge that we produce. We should be able to, to produce, to construct the fact that a nice presentations, right? How to do a presentation. It's a whole different world, world. And there are many techniques that most people use. Slides. They use PowerPoint. I hate PowerPoint and similar things. Best. I don't really like it. I don't think it's a good thing to the presentation, but I don't have anything better. And I've been, I'm trying different things and then experimentation different Thanks. Agitates without slides. Anyway. So since I'm doing research in many, many thanks. Probably I will never come up with a nice solution for that. But anyway, writing our papers of the documents that we create in all cases, for journals, for book chapters, conferences, they have all the same starter, right? So we have an introduction. Probably need to go to a whiteboard. Alright, so introduction. Everything is important, everything and the inputs, right? So we have to pay attention to all the elements of our paper. And the first thing, not necessarily for, the first thing that we do, but the first thing that people see is they introductions. And so what are the elements? Motivation. And then the introduction of our justification, of our, what is our novelty is here, It's right here as I approach 0. So what is one? And then a discussion about advantages versus trade-offs. So this takes a lot of time regarding their motivation. This is probably the easiest part of words because we know what is our motivation, but it's easy to think of it. It's not as easy to write it in a way that people that don't know anything about our research or may not lead of our research they understanding, right? So sometimes things based on grade and our brains. But then when you write them, they've done look so great. So we have to pay attention to the way we explain our motivation. Then. This is tedious. The state of the iron bytes, as I said, after one year working in a topic, you know everything. You must know everything. Otherwise, you are not doing it well. You must know the state of the art with other people the other groups are doing. Save your work in machine learning. You know, what are the main groups around the world doing things? Not necessarily in our country, around the world. Okay. Then what are the, what are the trends? And among all this, what is related tongue works for that here. And then after that, my approach, approach should be connected to the state of the art. The approach and the advantages and trade-offs they should be connected to the state of the art. So what is novel with respect to the state of the art? And this justifies our favorite, what is the novelty? What we do that hasn't been done before. We go and answer this question. We cannot pick, right? Because epiblast to contain novel the knowledge that is not in other vapors. Our, our bigger is not perfect. Right? Think of the no free lunch theorem for more sticky stigma and affluence theorem says that in average, any machine learning has the same rate of better. So if you take our learning machine and train and test that with every possible set of data, then the probability of error is going to be pretty much the same as any other learning machines. So then if we have a specific problem and we want our machine 2, we better than others in that specific problem, then it's going to be worse in other problems. So I have to modify the algorithm to adapt it to my palette. And here is when I have advantages and trade-offs, why I introduce something in a machine to make it work better. And then this modification comes with some additional halfway, with some additional trade-offs. It might be computational modeling, it might be that many assets, right? Super vector machine. They weren't great, but they have a parameter, at least. See these parameters, there's no way to, to train it. I have to adjust that artificially using cross-validation. But I had to explain distance, right? With this, we have a nice introduction. And so this is the first exercise I want you to do. The paper. Pretend that you are introducing super vector machine and explain all this. Yes. So I'm sorry that you had been so he didn't know that. The novel David will be I understood that. And so that worldwide. Because not to say that because I really apologize, but I don't understand your question. It's a matter of my hearing is not great. What I'm trying to say. Okay. And it should be talking about the novelty of the research that yeah. Exactly. Then we should put it here. Yes. I'm sorry about that. So yes. In my approach, I have to include the novelty and I have to, I have to highlight it. For example, I can say the novelty of our, we use the portal, the mothers, the pronoun. We don't say novelty of my work. The novelty of our work is best. There's this compare to the state of the art. In of course, we should not be derogatory with respect to the other approaches. Right? So for example, we should not say paper and 11 ignores the fact that this kind of language is to be avoided, right? Week My said this paper, it doesn't take into account, right? So we have to tell whatever we thing, but in a nice way to others. And of course, whenever it's applicable, we should be inclusive and in our language. But this is a whole different topic. So we have to novelty but always related to the state of the art. So this problem has been tackled from this point of view and we have a solution here. And this solution has this abandoned these habits and interchange. We have this and this trade-off, right? So that will be the introduction. Then we go to the theory. And I will show you a couple of papers with theory. A good one or bad one. I'm not going to show bad papers. Papers that are part of books. I've seen papers and papers, but since I had to present our paper adequate issue they might write. I'll show you one that paper that I coauthor. So, and one of the things that is not probably don't see a theory has to be structured in a way that is understandable, given for people that are not into our AR research. Take for example, when happens with machine learning, if everyone is interested in machine learning, I mean, working with virtually every, every faculty they see in, in electromagnetics. And there are some propagation communications. Physics, particle physics, plasma physics. I worked in medicine. I'm working with a psychologist that does treatment for alcohol abuse. I worked with psychiatrists and neurologists in neuro-image. I worked with people in the national security, not in this country of ours because I'm not living on our green card. Still angry about I worked with the military and Spain. And did I discover why they want to meet you with them? So I quit. I work with many different people. Different scientists are made from a 25-year south, right? Where they went. But the point is that everyone wants to use machine learning to sense and not, not everyone is an experiential learning. Machine. Learning itself is void. It's users. You need to do real engineering or real science and then include your machine learning. And so if you are a real scientist, physicist, or a physician or whatever, don't necessarily understand our diet. But you want to say it's particularly important in machine learning in many obligations. Or unless you publish theoretical paper in, in the genre of machine learning research or something like that. Or in announcer probability. If you publish an application paper in an engineering journal, you, you may expect that your audience is not expert in machine learning. So we have to explain our theoretical background in a general way so other people can understand what grit. Yesterday, time. Yesterday, I am writing a boredom can be bulging out. And so people in machine learning use what they call 10 soaps. And I try to get, to get more knowledge about cancer. Because we talk about tensors solid high. And I will stop for me was almost impossible to understand what a, what a tensor is, what really a dance variance, because people do not explain it for experts, foreign experts. I went to, I went to papers from mathematicians, physicists. Almost impossible. So I quit until I found a paper written by three people of Zambia to mathematicians at Sandia. They're used to work with others that are not mathematicians. And they explained in a paper, published paper really nicely. So I got a right and this is what we need to do to be to be to talk in a language that others can understand. Why it's not just for our, not just for four or five gurus in children. So we have to my full screen. So when we summarize the theoretical background, we have to bear in mind, let's explain it the easy way. And then using your us till you run your approach. Theoretical depth. In this theory. Your criteria should be explicit. And then you develop your algorithm, Right? Which is more technical and more practical and theoretical. Plus the advantages and trade-offs, the most important thing of everything, yes, the experiments, right? So we have to start authentic. First. What experiments you want to do, and then why you want to do these experiments. So what do you want to prove with these experiments? Okay, Then after you explained why do you want to do and justify why that explain the details. Although you attend the data, how do you corresponding parameters, all these details? And then when everything is explained in detail, the experimental setup, while this is probably something that go together, how do you obtain the data? How do you your parameters then only then you show your results. And in your experimental part sometimes is called Experiments advances part results. In this section, you only put results. And this is a nice way to do it. And it's pretty standard. In many areas. In results, you only put results so people can see it, can see your results. And if they want, they can take their own classrooms. But the most important thing is that they understand what you did then in a separate section or in the same section, but only after that, then you discuss your results. It's not a good idea to explain a result and then discuss it. Just first present, explain your results. In this graph, we present the probability of error, blah, blah, blah. Once you have present the results, then you'll discuss them. And then they, somebody that doesn't know anything about real research that they had, they have a much easier structure to understand why did finally convulsions and compressions. The conventions. They should be useful for the reader to know what to take home. What is important one not to forget, right? You might have a theorem and prove a theory. Maybe it's not important to remember the proof, but it is important to retain the interpretation for the theorem or why you did, or how you use it. All right? So whatever you think it is important. Whenever you think it's the most interesting by the things that they should not forget. You put that in order to do that, you go through the paper, outline, whatever you think it's essential, and then you summarize in your compassion. That's it. And in many papers, they also have a future work, right? And the good paper that I will present, they don't have future work because basically what they do is to present a theoretical, a theoretical result with some examples, right? But in others. Basically you say, this is not all, there is a lot more to do. And some things that we can do this this or that. This is a good thing? Yes. Because it shows that your research it will lead to more research. It's not, it doesn't die there. It's a good thing to do that if you really know that these are things that can't be done. All right, so let's same. If I find those papers. Let's go Let's go for this. It's up. Paper written by per night Zhukov and Alexander's mother and browse Robert Mueller. So these three guys, I like, I really like barbershop. He is one of the people that introduced the super vector machines. And he, in particular he introduced the kernel support vector machines with another researcher, Bobby Sarah Louis on and he, he visited her for six months and, or for several months. And they, they made a derivations of the super vector machines. And I am, I had the honor of meeting him. He invited me to his lab a long time ago. I met him in, in a, in a conference. We start with Target and he said, Why don't you counterweight to my department? Max Planck Institute, spend a couple of months. And I, that there I met Alexander smaller too. He was the one who introduced super vector machines for depression among other things. Also called Robert Mueller. I never talked to him except he came to to say, congratulations for a presentation that I gave him in a conflict. That's it. But these are, these are giants. They're really smart people, mainly. Shop. He is a physicist and mathematician and philosopher. He started the three, the three, the three things at the same time. You started with mathematics, secondary or his, or the physics theory or philosophy. Because he needed more material of the story. So they introduce here. Then non-linear component analysis. Non-linear PCA, principal component analysis. By using a non-linear way, you're seeing infinite-dimensional Hilbert spaces. Inside the title. The title, the title is probably, it's very, it's very informative, right? I would have put non-linear prints, principal component analysis. But if you are into Hebrew spaces, you get the thing right away. Right away. And you will. Because we are going to study, we're going to see Colonel analysis. In order to generalize our machines to non-linear, to have normally improv properties. So in a couple months, you will be able to understand this title right away. Moreover, we will go through the favor and we will explain it from from the beginning to the end. This is something that you will understand right away. It has quite a bit of algebra of course. So, so if you take a look to this introduction, love it, just the page. Something like that. Right? And just take a look the way they start. Principal component analysis is a powerful technique for extracting startup from possible high dimensional datasets. This is the motivation. So PCA, PCA, right? Well, if you don't do well, because we have astype that PCA is a powerful tool, Alright, well, so they explain BCA for whatever. Food doesn't really know what it is. And then what they say is, we're going to extend the PCA to infinite-dimensional spaces. And so we will provide a non-linear version of PCA, which is way more power. But then if I want to impress my audience, I will choose different words. I will start talking about maybe Calhoun and lower transforms or the representation theorem. I don't know. I can make up many. I can throw many words to impress the audience and say, and some people say, Wow, this guy really knows about that topic, but this is not the point. The point is not to show how smart I am. And this guy, he's a mathematician. They are, the three conditions are good ones. But this is not the point. The point is to go to the point, right? So motivation. And then here they, they add some minimum state of the art. And and then yes, we'll be zooming in. Zooming. Yes, of course. I will not sign. So they there was some state of the art of course, does not a lot of state-of-the-art PCA, SPCA. That's it. All right. And then so they say in the next section will be a standard VCA, blah, blah. So here what they do is to, to put paragraph with a structure of the paper, but I don't think this is necessary. I mean, progressions from bank or questions. All right. Okay. So they start, they, they, they have this many, in many, many people have this habit you to put the structure of the paper. But they give the boy is that they construct a paragraph with a motivation. Then they have to introduce some state of the art and then they say what they want to. Just take a look to this small thing. And then after that, whether they DO well exactly as I said, theoretical background. And then they approach what is the third February, but this day, the theoretical background while the PCA, they explain the BCA. Alright? But they explain it using infinite-dimensional Hilbert spaces. That's, that's the point. They do that. But at the beginning of it, what they do in these equations is to explain the plane PCA. Alright? They explain the brain BCA then after this devo to date approach, which is PCA using Hilbert spaces. And this, you might understand dissipation, you might not. But in a couple months, maybe one month, you will be able to understand this equation right away. Okay, So I don't really, you don't have to beg, you don't get anything over the paper. This is not the point is that theoretical background and then my approach, so they go and that our body approach. And then finally in three day. And then finally they go to their babbling ray diagrams in several parts. It's very long. And here is the Lasswell. 34 is the power. That's, and then after this, they, of course they talk about the computational complexity. This is advantages and trade-offs. And then experiments. Right? So they talk about maybe not in exactly the same way as I propose when they talk about what experiment you are going to see. First I examples and then productive information. I don't know what else. Write the examples and collective evolution. So they explain the experiments first. Then they present them with with quantitative data. Right? Explain the experiments. They, what kind of damage want to do, what kind of data you will use. In this case there's not a lot about not alot of a parameter evaluation. But after that, after explaining all this, they present the results. And only after presented the results, they go through a discussion. Finally, they have, this discussion is very long of course. And finally I have a question. Decompression is exactly what we want. What do I want to take home? Right? We're going to have this annotated because the concussion is is very significant in this case. Rather than go through it, I'm, I I recommend you to take a look to this paper. As an example of a well written paper is, this paper is one that I write once and I understood the whole thing right away. And this is not common. This is not common. But there is something that you mentioned which are the candidates, right? So when you, when you want to add about the innovations that do you think that are important, but very important for the paper. But you don't want to this truck the reader with the mathematical derivations. You put them in an, in an appendix. And so the interested reader, they can go and see okay, how these guys make these elevations. Or you can just ignore it. And that's it. That is very nicely written paper. Just an example one yes. Is here and when it says examples of papers and you right? And so that is another paper, that paper that they bother. And so take a look at this, MS. MS. That's my first paper. And he got quite a bit of of references, right? And thanks to this paper, I'm just a second author. Right? Bye. Thanks to this paper. This paper opened many, many doors for me. So it's worth, but it's poorly written. And it's mostly my fault because I wrote almost out of it. This paper from idea to patients. Guys, why it's my first paper, then I have a second paper up my dissertation. Both, they are brief papers. They're supposed to be brave. And part of the same part of the mass is that it's, it's a very painful day. They, reviewers said there should be a review paper, so you have to compress this. But anyways, they're going to do this introduction just a close. How do I zombies hardware? Table up to this equations in the introduction. Just got today, actually click in a paper at random and see if they have equations in the introduction, they don't arrive. It was not justified to have equations in the introduction. This is not a real introduction. We do not go to the point, though. This is what I wanted. I wanted to, but the point I was so excited to explain my findings and I started explaining them right away. Now. Alright, no motivation. State of the art, this is here, here and here, and then, you know, it's around, it's around the beam. It's mix with this explanation which is, you know, And here I fire attempt to do a comparative between the state of the art and what I introduced this paper. But this is not, this is not the way to the right. And it's so long that the reader thinks of a, what is the pool, right? So this is the impression that you get if you write a paper like that. What a mess. All right. Then so it's not clear what is the, what is the background, what is the novelty of the paper rights? And while you take, although you will see that you understand anything, right. So this is 10. So you have mixed theory, experiments, discussion. Everything is replaced. So not, but as you can see, not particularly proud of this work, right? Still, we were able to write a paper that says super vector and they, in their title. All right, and this super vector at that time was clickbait, right? So this title was kind of goes it make sense at that time, right? This is something that we did. Well, the rest we did not. And this guy as my advisor and we will discuss. All right, so that's it. That's it. Now, the next step is for you to write a paper, right? What is, what is what I want you to do while you have done so far, you have done experiments and you turn them in. And I'm going to try to, to have them graded today or at least during this week before Friday. And so when I grade, if the work is great, I just say it's great and you'll have a blast. And end of the story. If it's an upgrade, I tell you mine, right side, something which is wrong or it can be improved. I tell you what you can do and if possible how small comment. And then you can resubmit. You can always resubmit if you don't like your grade. If you don't really know how to improve your work, just come to my office hours. We will work it out. Alright. It's not about the grade. It's about doing it well, while you get your eight safe, you don't do that. You don't have a clue on how to do make things work. Please come to my office, world filled out. So you have done these experiments and you will have done some theory, right? I asked you to write some theory to explain things. Now it's time to use that theory and that experiments and put them in a paper. And so just pretend that you introduce a super vector machines. But do not go to the original while you have to go to the rehab because of other conditions, of course, to mention them, to cite them if you want. But don't try to do it their way because this is undefined. Do it your way. So to start, we got an introduction and motivation is the first thing to write. Why do you introduce a super vector machine? What are the advantages of a super vector machine, right? And why you want to introduce them. And dy is going to be very difficult. Now what is the state of the art? And not a lot. We have to make it make it up by whether we have as the state of the art that can be compared to our work. This is a linear support vector machines. So we have to compare apples to apples. We compare our work to other linear classifiers. What do we know what other Linux device that we have? We have three. Thanks. Three approaches. The first one, we didn't talk about it, but you might introduce it if you want, which is the perceptron. We can see the whiteboard online. I'm sorry. Yes. Then this is your right? Right. So the percent that we haven't talked about that time, it was introduced by Roman out in the fifties, I think. He was. And he was a psychologist. His study. He theorized about the brain tissue. They are there, the visual cortex. And so he came up with a machine which is called the mike Mark 1%. Then it was another bearer. There was a machine, He was an electromechanical machine. And I believe that this is why we use this term machine learning for what we do. Because the first learning. Device was an electromechanical machines. And their weights of the machine were adjusted using potentiometers, are rheostat connected to mothers. All right, So turn to automate more or less signals. And the input, it was a, a matrix of 400 photoreceptors. It was like a primitive camera or primitive version of what we know as a CCB now. And this was able to perform linear classification. I didn't converge unless the problem was perfectly separable. There was the first things that we and the American Defense, Department of Defense of the United States, they were super excited about that the other day that this thing was going to lead to our machine able to take decisions and you don't have a conscious. Never happened. But that was the first thing is, do we have a minimum mean square error? And then three, we have a ridge regression. All of them. They are they are Datalog to train the same machine. A linear classifier, Rumelhart bond, called a perceptron. Right? So these are the training criteria. And the perceptron was by using the person. So then for who had a support vector machine. So that would be the state of the art. Now. Now, what is the novelty of the super vector machine compared to the previous facts? And this is a question that I'm asking you. What is the novelty? What is new? What is a new concept in the super vector machine? Think of this as insensitive to outliers. This is an advantage. Yes, it's an advantage. It's not the novel provides an advantage. So we put it in a advantages file and trade-offs to buy. But what is the novelty that leads to disadvantage? Say something. It might be right, it might be wrong. It's going to be ideas. This is called brainstorming. Brainstorming. Bowser. It's a maximum margin machine. And but this is a mechanical if you want interpretation of what the machine does. And that comes from what concept? The concept of maximum margin, which is the way we call them chimps. They comes from what more abstract concept? I think Dr. W. Minimizing the norm of w is it's a higher step of obstruction, or pretty much the same as margin. They are equivalent right side, my money maximize the margin, I minimize w. But again, that is a more abstract concept on top of it. When we switch the edge, the damage that I mentioned, visa by Michel one running, as I mentioned, they control of their money by meter running this dimension, or they fall on the generalization properties of the machine. Right? Through, when we call they are structural risk minimization principle. And this is the novelty. This machine, well, it was an agreement. The machine was the first one, right? And so this guy may his place in history. By this machine, what they didn't control an effect. There was only able to work if the problem was linearly separable. Of course, in 400 dimensions of F, the minimum mean square error is able to converge even if the problem is not linearly separable by minimizing the squared error. But we know that we just minimize this training. The machine has generalization problems. They overfit. In order to reduce the overfitting, we introduce our regularization term here. Infringe regression. So this machine works better than this one because it converges in a problem which is not drift, not linearly separable, it has a solution at each unit. We're going to say the same of this machine. This machine works better than mean square error because it has some capabilities to control. They overfitting by using a term in, using an additional term. In the optimization. Silver metal machines. They have two different sets. First, they explicitly or they provide an explanation of why using the minimization of w maximizes the generalization. And secondly, instead of using a squared error, we use our linear, a linear cost function. And the linear function is fundamental to control. They influenced them. Why do you sense or in Canvas? It's the outliers, the influence of outliers. So this is the novelty of the machine and then you explain your way. Okay. What is our major trade off of my support vector machine? Well, one advantage. Let's start with an advantage. One advantage is that if I have a problem with 400 dimensions, but they only have 20 data, none of those. I wanted to provide a reasonable solution. Basically, they still are there. Why don't you to overfit, right? So we have 10 dimensions and 20 data. This produces the best, the best possible result. But if we have 400 dimensions and 2 million data, then what happens? When might say, well, I want to be on data. You know, the theorem says that they are structural term. Actually. It's, it's, it's negligible. So I can use ridge regression for example, and maybe it will work. Well, this is not the point of what I say. Width of this is not a one-to-one, I want to say now, if I had 2 million data and 400 dimensions here and ridge regression, or a minimum mean square error. I will have to work with a matrix or 400 times 400 dimensions. Because they still, they use r, which is equal to one over n X, X transpose X is a matrix of column vectors, so it has d times n, and this is n times z. If n is 2 million, well, I have a hard time. I will have hard time to work with that because I have to do a lot of floating point operations. But at the end of the day, and I will end up with a matrix d times d, which is relatively small. With a support vector machine. I need to work with K, which is x transpose x matrix products between data. So this is n times d and d times n. So the matrix is n times n. It's 2 million, nice the millions. So the computational burden here explodes. Hi. If my brother has a lot of data, but still debye meter run, as I mentioned, is an issue. I have to reduce the complexity then. And I need to use super vector machines. I cannot use the original super vector machine today. Explain. I had to use sparse approximations that produce matrices that are smaller. By, for example, is carrying data in a smart way, right? So I have problems to put the support vector machine if I have a lot of patrons. And then I have a parameter to optimize, which is C. I have a parameter here, I call it Lambda. And pretty much the same parameter here, I call it sea, land and sea. They are inverse to each other. Because when I use it to multiply, That's w and c, I multiply times a sub baby. The barriers. But that's, that's another trade-off. The computational complexity when the data is very sad, is a huge. And the fact that I'm at least I have to cross-pollinate one brand, something that doesn't have it. Here. Here I have a boss solution, only one. These are advantages. I'm fed up. Alright? So the support vector machine doesn't solve all the problems. That will be my introduction. And of course, it's up to you want references you put here. You have to report the results set by the database. I should not compare this to what your network, a multilayer perceptron. Now, because they're not dilemma cetera, what it does is to apply a nonlinear transformation to the data lake they make the multilayer perceptron is a non-linear classifier. So we cannot compared to linear. This is not the point. We know that super vector machine is linear. The other is not. So in this context, the neural network, it might work better. But this is not the point here. The point is they can follow the complexity they control, or the expressive capacity of the machine or the control and evaluate children, I guess dimensional, through what we call mistook the original message. This is the point and neural memory and syllabus at the elision and C. This can follow the complexity the same way as we do in super vector machines. Right? Costumes. This is just an exercise. It's an exercise for you to remember, for you to attend, for you to write better papers. And I'm not claiming that you don't know what to do. And this is just my view of things. And it's an exercise. You might say now, I want to do it in a different way. If you justify why another way, or they think it's better or equal than I expected. And I will, by the way. Yes. So as far as the experiment can be just feed the data and draw some graphs because I want to protect some experiment. So what should be our approach for the exam it apart? Well, the data, it, it should never be fake. Or the graphs, the data might be beneficial, maybe some static. This is what you met Dr. Sanders? Yes. Why do you say your data is not fake? It's artificial. And seven, I propose you the use of some, some data right? Into dimensions to illustrate how it works. Right? There are many ways of generating data, two-dimensions, for example, where they propose there is to use forecasters for Gaussian clusters that you can separate. You can do a good job by separating them without separating hyperplane. Or you have data in 10 dimensions. So for Dame, for the reading up on it, on the experiments are good way would be to start with a resonant institutional principle. So explain it. We all have our guide, may have guidelines, you have an outline on how to explain that in the slides. You can go take those lights and summarize them or expand them. If you want. Rights. I started with age than the Stederal minimization principle, the magnetization principle. And then you go way, they found this principle. Then you, you, you get a great helium. And then you have a cost function which is the criterion is your cross-functional or more functional. And then with this, you have to consult with your cost function. Right? This is the way to send a birthday present, a concept of maybe trying, as I mentioned, from that, using a CRM. A CRM, I present this minimization. From this theorem. I construct a criterion which is a cost function that contains, that contains the empirical risk. It contains the term related to the minimization of a stroke risk. This is my function. And then I need to do math in order to construct my algorithm, which is actually my dual function. Alright? And what are the experiments that you can use after you construct your theory? And if you want, this is the theoretical background. Because we are not going to provide a proof of this theorem. And this is de novo from a clinical point of view. Now the experiments, well, so you can have experiments to, to show the stockholders minimization principle. What does the experiment that, that you did to prove this is experimenting with you, plot the empirical error, then the risk during the test, and the defense, which is this doctor risk. And then you show that these three lines, they match what the theorem says. Then you can do experiments that show a classification. And classification when you show the behavior of alpha, alpha, I shot every pair of words of as an, as an unsaturated fats and unsaturated depending where they are outside, inside or on the market. But wait, because here, when we have the results. But before you present your results, then you have to explain what you want to do. Well, first. So first I want to show the minimization. And then I want to demonstrate the behavior alpha i. That's the first thing that you have to do when you write your experiments. What do you want to do? I want to do an experiment and we want to show the relaxation. And then another one to demonstrate the regular buffer. Then how? Well, the first experiment, Islam, it is, explained, what do you want to do? So we're going to measure the total risk or estimated salaries by the difference between the training data, the training error, and the test error. Well, we will use synthetic data in a problem which is linearly separable or almost leanness Bible. It is a tree. In the experiment. To experiment. This is a, this is B and explaining and B. Cross validate. See, you explain how you will do that. In the first experiment, you don't cross validate anything because actually what you have here is C to that aim to how, how, how, how, sorry, six months I realized the upper right. Alright, so first explain what do you want to do? How you want to do it. And you're treated as an app, which is in this case, how they generate the data. And how do you personally I'd see. And then finally you present your experiments. And finally, after presenting our experiments, you've thought about them. And for them on brush and just go back to the beginning. Outline, whatever is more than enough paragraph or two. Here you have to write wherever it should be. 333. Yes. It says in the experiment B, we will cross-pollinate, see. And so we have, you have to learn how to generate the data. I have, I just, I forgot about that. One. What experiments you want to do? What, what do you want to You want to show with them how you're going to do them, which includes generate and generate the data, and also what parameters you need to cross-pollinate and how you will translate it. And after that, you can just present your results. You want me to explain much about the last check, that everything that you explain is sufficient for me to redo the experiments. Check for reproducible. It's very important. All right. So I made, this thinks she's asking students to write papers. Ran a business. If you do it well, that's good for you, right? Because then you have a way to write a vision and in fact that an effective manner, it's a sort of algorithm to write papers maybe that you can then modify or discard if you know other ways to do it. Of course. Sometimes students don't do a good job. And I could never understand why. Right. Sometimes works out so good that I ask students permission to show the papers, to show the laboring, and then an a, and a screen for others to see how well things are explaining. Why does the struggle of the paper? And sometimes Weber, Sarah, really, really bad. They know nothing then convulsions, they miss experiments, they may inspire some of the theory. And this is something that cannot be justified. I can I justify this? Because everything's explain. Your smart people. You are engineers or physicists or whatever, your as your degree, right? You, you, you, you are here because you will have to pass. You pass a lot of difficult exams. Needed. Another form where our thanks. So this is not the worst thing. Yeah. Somebody ever asked to write, you should do a good job here. Why I'm saying this? Because if you're not doing well, you will have a bad about Greg here, right? And then this exercise is two-fold. First, it's merely to write a beggar to see how well you, how scared you are to write a paper. Or second, of course, this is worth for you to review all the theory. For you to understand. Thanks. The best way to understand something, the best way to learn is to teach, right? And this is the closest thing that you have to teach to explain it in a paper for others to understand, right? So if you explain this things for us to understand, you will learn it. And you will be, this will be in your mind for a long time. So then if you have to use it in your research, then you will be they good at that? Some take pride in that, right? We will do that again at the end of the class when we talk about Gaussian processes. And the process is going to be the same. Of course, the topics kind of different. And then you can compare yourselves with super vector machines. The super vector machines that we just, we started here they are for classification, but we will see some machines for regression. Washington processes. I will only show you in detail the Gaussian processes for repression. But then in this case you can compare the results are super vector machines and Gaussian processes and see what are the advantages and trade-offs, trade-offs or both. So that's, I think that I'm not missing anything. Let's just take this paper. Does I don't like it. So that's it. Questions. Any question from the audience? This is the assignment. All right. That is Assignment 4. Yes. Okay. Doesn't work here. Yes, it will still give us glide. Furthest person was. You want us to do a shorter version of that paper that is something that will pull it to the paper. Let's see, let's go to. You're talking about there are three. Alright. So sigma 3.13.1 yes. Summary or maybe not the summary by the whole section. Theory are these papers? Right? And then you have an outline. You have an outline of it as this little, too much maybe. So. To summarize the theory of this module in a maximum of three pages using the following stopper. While this is exactly what I explained or pretty much for the extra here. First, explain the concepts of risk and risk. You can start with H or you can start many other ways, right? But risk and empirical risk, and then you bow, they come up with the concepts of complexity and overfitting. Complexity. Carrying the way you want. The baggage I want to use. I mentioned x, h. This is what I want there. And then introduce the concept of VC dimension. Well, it's going to be the same, right? So complexity on our feeding from a point of view, from an egg, from according to the point of view, and then introduce the VC dimension. And once we know what the VC dimension, then NMC a diameter running this theorem that describes the bond and the actual waste. They Barnum performance BC theorem that we saw in class. Explaining NMC and then explain. And with all these elements, we can go to the super vector machine criterion. Not the, not the criteria, criteria, which is the singular VC criterion. Sorry, they, they SVM criterion, which is the gradient that uses this to Alice. But they are lipid is the empirical risk minimization of w squared. And with this, we go to a dual solution of these criteria, which is 0.6. Now, once we have the duo develop, what are the properties of a simple vector? Machines are super vectors. Basically the behavior of f. From a theoretical point of view, what happens with alpha if the sample is outside, inside or on the market. And you have three pages to do that. But then you can just copy, paste that code into your and your Beta. Right? So, and this is why I want to have this homework graded as soon as possible because I want to detect what are the mistakes and errors in that one. So you do it very forgiving. Ends up in the 2.2nd 13 habits here, you just specify. Yes. Okay. So here you have some data and then you have 3.2, which is the practical part in width. You have to, to play around with the super vector shapes, right? That's basically how to go back and say open a new tab over here, right? That's it. So this assignment 3.13.2, they are the theoretical bonds. And then the experiments. In the paper, you have to explain all these things. It's not going to take long. And I suggest you to write a paper or four pages. You can write a paper of as many pages as you want. But I think that everything fits for pages. Double column if you want, right? And so in order to write a paper is also good to get used to the standards. And I advise everyone to say hello to lab. If you haven't worked with bladder, It's a good thing to let me see if I can. There is a GitHub when there's something on obviously, they use all the time. This is my classroom. Yes. I use it all the time to write things. This is my book. And when you write, you can write very complex things. And everything is pretty much automatic. Right off, by the way, we have the neuron here. So everything is written in a very professional way. If you use ladder, if you want to use this thing is for free. And you don't have to install anything on your computer. But you can install on your computer and the work locally? Yes. Could you post the link as a reference for a lot of Otherland? Right? So that egg is a magic way of writing as opposed to the one you see is what you get of war. Then a logical way. Bribing means that you need to use some foliage. But then poly styles, they are consistent. You don't have to put this by hand. You don't have to do anything. Everything is fully automatic and very stable. And then you change a graph of position. It this will not mess up your document. That happens in Word right side. We're going to use this. And so once you get it, it's going to take a week to learn. And then you will never go back to one Latinx it for free. I don't get any this is not any. Right? I don't get any money to advertise it. All right. Thank you very much. Yes. Sanctions against the orange is just the best guess of introduce them off. Yes. Yes. Well, when you want or indirectly, whatever used to be used that way, next step was previously introduced. Whether or not Yes, Sarah, I'll say I'll say. While machine learning is voice not used, I mean that kids, it's a poor unit of something. Arrive. Sweat itself. I mean, why aren't we doing this? To apply it to physics, to whatever order. We have due dates one after the other. There.