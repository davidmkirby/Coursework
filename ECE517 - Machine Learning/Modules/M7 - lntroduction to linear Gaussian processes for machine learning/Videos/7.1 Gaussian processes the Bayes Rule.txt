 Hi, welcome to Module 7, in which we are going to talk about Gaussian processes for machine learning. And we are going to start with the Bayes rule and its relationship to regression, in order to make sure that you understand what comes later. This is the Bayes rule, so assume that we have a universal possible events. So for example we are flipping four coins, and then event A is the event in which we count three tails in the outcome of the experiment. And B is the experiment which the two first coins that we observe they are tails. So these are two different events but they're not joined they overlap, for example if we count three tails it maybe a case the two first they are tails. So A and B happen at the same time, and this is the event that is intersection of both. Now, A it has a probability, and B, it has another probability. And then, let's assume now that B happened, that we know that B happened, then the probability of A changes. If the probability of A is what we call the prior, the probability of A given B will be the posterior. And then if we assume that the probabilities of the events, they are represented by the area of the circles, then we can compute the Bayes rule the following way. Since B happened, then the rest of the events of the universe disappear, so the only possible events they are included in B. Now the probability of that A happened given that we know that B is an observation that will happen, is equal to the area of the intersection given over the area of B. Remember, this area represents the probability that A and B happened at the same time, and this is the probability that B happens. So the probability that A happens given that B happened is equal to the probability of intersection of the probability of B, which is the condition. This is an example, so we have a probability of A, which is 5 over 6, and the probability of B is 3 over 6 next. Let's make sure that the probability of IA, given, sorry, A and B, the intersection is 2 over 6. As you can see, the probability of A is equal to this probability plus this probability, 5 over 6, the probability of B is equal to this plus this, which is 3 over 6. So, the probability of the union is equal to the probability of A plus the probability of B minus the probability of the intersection. And this is true because if we are to gather the probability of A and the probability of B, the intersection, we are counting it twice, so we have to remove it once. Well, the probability of A and probability of B, so the union of both probabilities, we assume that is 1. So, the universe of events, is equal to the union of these two, then, if we isolate the probability of the intersection, we can see that it's 2 over 6. Now, what is the probability of A, given that B happened? It's simply the probability of intersection, over the probability of B, which is 2 over 3. We can do inference over an event A, given B. So the idea is that we have a distribution of B over A, and we need to know the distribution of A over B. So, This is the rule that we just reviewed, so. And then with this expression, we can construct this simply by, Multiply A times B or B, and we have this expression here. Then if we change B and A, then we have this alternative expression. But the probability of A and B and the probability of B and A, so the intersection of A and B and the intersection of B and A, they are the same. So these two expressions they are equal, since they are equal, we equal them and then we isolate the probability of A given B. And we have this alternative expression for the Bayes rule. Now let's assume that we have an event A which is nothing but the set of parameters of a linear estimator, where y is equal to w transpose x. And, there is a probability distribution of x and y, what we want to compute is the probability of w given the observations y and x. Remember, x is the input of my model, and y is the output, this is the set of predictors, this is the set of regressors, so y is equal to w transpose x. Now, we're treating w, not as the set of parameters, but as a vector that contains random variables. And these random variables, they can be modeled with a probability distribution. How do we do that? Well, assume now that A is w and b is y and x, then using the Bayes rule, the probability of A given B is equal to the probability of B given A times the probability of A over the probability of B. We simply define B as the set of two events, now, using the Bayes rule again, the probability of y and x is equal to the probability of y given x times the probability of x. This is the Bayes rule in which now A is y and B is x, so we have this. And using again the Bayes rule, we can say that the probability of A and x given w is this expression here. What do we do here? Well, here we put an event A and an event B, and now we have an event C. So this, Event will remain as a condition here and here. What happens is that x, which is the input of the system, is independent of the value so the probability of x given w is equal to the probability of x, they are independent. So, using the Bayes rule, and keeping this condition, we have this. So the probability of a and b is equal to the probability of A given B times the probability of B. Now using these two expressions, we change this probability by this probability here. So we have this, and the probability of y given x, we change it by this probability, and we put it here. And now, the probability x we can remove it, and we have this expression. We have an expression that says that posterior probability of w given a set of observations y and x, is equal to the probability of y, given x and w times the prior probability of w over the probability of y given x. This probability is what we call the posterior, remember that we don't know w, it's a posterior. This probability here, it's called a likelihood, we call it likelihood because y is an observation, right? Imagine that we have a set of training data, y and x, well, y and x, they are observations. Since y is known, we call this a likelihood, right, the difference between this and this is that w we don't know it, so we call this posterior, y, we do know it, we call it a likelihood. And this is the prior, so since in the denominator we don't have the presence of w, when w changes here, w will change here. So, we can remove the denominator and say that the probability of w given x and y, is proportional to the probability of y given x and w times the probability of w. We can summarize this saying that, the posterior on w is proportional to the likelihood times the prior. Posterior proportional to the likelihood times prior. The conclusion is that if w, well this should be a w bold, w is a set of parameters of this estimator. And we have A model for the probability of distribution for w, and we call it the prior probability of w. And then p is the posterior probability given the observation of y and x. Then, we can compute the posterior using the prior and the likelihood. And we can compute the output likelihood using the expression of slide five like that.