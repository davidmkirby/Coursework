 Hello, we are starting to talk about linear regression, given that you got the idea of divide use for regression of the first part of the first lesson. And we are going to start with the formal definition of linear regression. A regressor or a linear regression machine is an estimate it has this shape. So the probability, sorry, the function f of x which we will call latent function is equal to x transpose w. And y which is the decide, output is equal to the latent function plus an error. And The bias is included here in the input. So x, it has this form. x has d dimensions, dimension d plus our dummy variable. And this dummy variable when multiplied times w, it produces a bias. The error that we are modeling here is assumed to be independent and identically distributed Gaussian process. So all realization of epsilon, they are random variables without Gaussians. And these Gaussians, they are all identical. And they are independent. The variance for this error or noise is sigma n squared. So this is what we call this additive white Gaussian noise. Then we can take care of the noise process. And we'll take f of x as a constant term if x is observed. If x is an observation, then y will be a Gaussian process with a mean equal to f. And a variance equal to sigma square, right? We go back to the last slide, if x is observed, then f, I'm sorry, x is observed, then f becomes a constant. And since epsilon, the error is a random variable, then y is a random variable. Since each of them has a mean equal to 0, then y is random variable with a mean equal to f of x and the same variance as the error. Then we can define the likelihood of sample y of n given the input and parameters w. The likelihood of y given X and w is a Gaussian random variable whose mean is X transpose times w and whose variance is sigma n squared. Now we know that the errors, they identically distributed and independent. Well, since they are independent, the joint probability of vector y that contains our values of yn is equal to the product of probabilities. So with this we have the likelihood of a sequence of values y given the corresponding predictors x of n, in a set of parameters w. This is a set of Gaussians. This is a product of Gaussian so the probability, the joint probability is a product of Gaussians and hence it is a Gaussian. If we compute the product of all these Gaussians we have a Gaussian with this four. So this is multivariate Gaussian random variable distribution. Y is a vector of n components, X is a matrix that contains n vectors of dimension d and w is the set of parameters. So this is an exponential that has a mean equal to X transpose w and a covariance function which is an identity times sigma n squared. Now, since we have an expression for the likelihood of the observation y given X and w then we need a prior distribution for parameters w. Well, we will model w as our random variable that has a mean equal to 0. This a vector of 0's and it has a covariance matrix sigma p arbitrary. This Gaussian it has this expression. No, we have the prior and we have the livelihood. Remember the prior times the livelihood is proportional to the posterior. Here we have the as we derive it in first lesson. Here we have the likelihood that we computed in class last slide and this is the prior that we modeled here in this slide. So the posterior is proportional to the prior times the likelihood. And remember that this is a Gaussian and this is another Gaussian. So we have a product of options that must be a Gaussian itself. So the posterior of w given y and x is a product, is proportional to these two exponentials. Since they must be a Gaussian we can add together the exponents and then operate and we have a Gaussian that has this covariance matrix. And it has given mean which is here. So here we have the computation of both. And finally, the posterior of w is proportional to an exponential that has a mean and a covariance. The covariance is equal to this function here, this expression here where what we have here is the matrix of all the data. So this is matrix. And here we have a term which is the covalence matrix of the prior w. And the mean of w can be expressed like that. And I need you to take a close look to this. We can compare this to their list of squares, the minimum mean square error or the ridge regression that we studied in other lessons. In ridge regression or minimum mean square error we have this matrix the inverse of this matrix for the case of rate regression, this matrix is added to diagonal gamma I. So this expression, if we change sin minus 4 by gamma and this matrix by identity. Then we have an expression which is similar to the one of retrogression. But here we don't have to value income and we have actual value and approx value which is the noise or error v. Though we have a likelihood and we have a posterior. Now, then we have another problem, we assume we have a new sample that doesn't belong to the training set. So we don't know why and we want to estimate it. So we estimate it using the function f, the estimation that it will be w transpose x. If we simply want a good estimation for that, we use the mean of w, why? Because this mean is the mean of the posterior, so if we use this value, we will use the value of w that maximizes the posterior. So this is what we call the maximum of posterior estimation. But we want more. We want to compute not just a good prediction for x, but we want to do here, is to compute the probability distribution of f. So the function that we need to find is the probability of f given x and w. In order to do this, well this is exactly what we can find using the expression of the likelihood of y. If we change y by f and x by x star, then we have the probability of f given x, and given a value for the volume. But we want to remove the influence of w and we can do that using the Total Probability Theorem. So if we integrate this probability of distribution, alongside the posterior probability of w, given w. We have an expression for the probability of x that depends only on the test sample and all the training samples and nothing else. And this probability is exactly what we want. Why? Because if we have this probability and this probability will be a Gaussian since these two are Gaussians. Then we're provided with an estimation or a prediction and also, we will provide with a confidence interval of this estimation. If I provide not just the estimation but its probability distribution, I will be providing how good or how bad is my estimation. In order to find this expression we solve the integral and then we have this expression. So the probability of distribution of my prediction is equal to a Gaussian that has this mean. Which is the mean of w times the new sample and it has a variance. And this variance is equal to this x transpose, A- 1 x. So the advantage of this over the standard minimum square error of this digression is that. Now we have a distribution on the prediction, not just a prediction, but we have a distribution. And we can judge how good or bad is our prediction. Just taking a look to the variance of the prediction. And also we will see that this method can be kernelized. So we can compute kernelized versions. We can produce non-linear versions of our predictor just using kernels. That can solve this lesson, that we're having to use the linear Gaussian process for regression. And the main things that we have to remember are first the concept of regression, the idea of data likelihood, so the probabilistic model for y. We assume that y is iid, so the joint likelihood of y is equal to the product of likelihood. So the joint likelihood of my sequence y for training is a Gaussian which is a product of a Gaussian. Then w is not a set of parameters anymore, but it's a latent random variable for which we assume that it has a Gaussian Probability distribution applied. And then we can compute the posterior using the bay rule. The posterior will be proportional to the prior times likelihood, since both are Gaussians the posterior is a Gaussian that we can find. And using the posterior and using the total probability rule we find the posterior of our predictions. In next lesson, we are just going to see some examples.