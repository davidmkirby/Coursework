 Let's go ahead with the examples. The first one is an example in one dimension and the model that generates the data is this one, y of n is 0.5x of n plus variance plus a noise. And xn is simply a uniform random variable between 0 and 1, w is a Gaussian noise with variance sigma squared. The standard deviation is 0.5 and for training, we take 50 samples from this linear model. I have to say that the linear Gaussian process is initialized with a standard deviation of n is equal to 0.9. But we'll see later that we can validate this value using maximizing the data log likelihood. For the test, we have 10 samples and these 10 samples, they are uniformly spaced between 0 and 1. And I simply present the result here, so you understand the model. So in blue, we have the training samples with noise, right? And in black, we have the regression line with 10 points. And as you can see, of course, they don't have the notes and they are our prediction. These bands here, they are the bands that define the 1 sigma band. So if we assume that every sample of my prediction is a Gaussian random variable with variance sigma squared, this is the 1 sigma band, and this is the 2 sigma band. If we compute the number of training samples that are inside the 1 sigma band, we will see that we have 68% of them. Which is pretty consistent with the theory because 68.3% of the samples are inside a 1 sigma band in a Gaussian. And for the 2 sigma band, we have 96% of the samples inside the 2 sigma band, and the theoretical value is 95.5%. So this model is in good agreement with the theory. We have another more elaborate example here and in the example, we process a set of random data, x of n, using an autoregressive moving average model, like this in the figure. Well, it's not difficult to say that if we have a sequence of x of n, this block here takes a window between x of n and x of n minus p. We multiply this data times the coefficients b sub 0 times b sub p. And then the output of this model is also delayed, so we take a window from y of n minus 1 to n minus q. And we weight the sample we've done together and this is our output, to which have some Gaussian noise. Now. So what we want to do is to predict the boolean of sample y of n using only past samples of y of n. So we don't actually observe x of n, only y. The idea here is to construct a prediction system, for which the input is y vector for n-1, which is defined as samples from y n-1 to y n-D and we take it as a column vector. The prediction function, the latent function, is equal to the value transpose y of n-1. And this can be represented like that, so we take samples from y n-1 to y n-D. We multiply each one times one coefficient w, 1 to the value D and this linear combination is our prediction. We generate N samples from a Gaussian distribution with zero mean and unit variance. So we construct a sequence of iid samples with zero mean and unit variance. And then this data is the input of the system of slide 4, the autoregressive moving average model here. The values of the coefficients are these ones, it's not important how I designed them. But anyways, I used a MATLAB function, that basically what it does is to construct the coefficients of a Butterworth filter of order 4 and cutoff frequency 0.05. So a and b, they have five components each. Now, the length of the predictor, the prediction vector, is 3. So we take elements y of n-1, n-2, and n-3, in order to compute y of n. In order to train the predictor, we generate a sequence of 100 data, and then we use a different sequence for test. The noise added after the filter of slide 4 is a Gaussian noise of zero mean, sorry, and variance sigma N squared and we use a couple of values for that. We have here the result, this is fit together with the other experiment. This is something that you will need to reproduce as part of your exercises. So this two figures represent the prediction of a test sequence. And in order to do these experiments, what we do is to use the same training and test sequences, but we change the noise. In this case, we have a noise with a standard deviation of 0.05 and here, we have 0.01. The actual values of my prediction, the actual values are the red ones. And the values predicted by the system are the black ones and these bends here are the 1 sigma confidence interval. So what we are saying here is that each one of these predictions is the mean of a Gaussian random variable with a given sigma. And what we're saying is that with a probability of 68.5%, the actual sample group will be between these two bands. If we reduce the noise, the uncertainty of the model decreases, so we have a band that also decreases. In both cases, if we count the number of errors that are inside the 1 sigma band and the errors that are inside of 2 sigma bands, these are in high agreement with the theory. Actually, our model is correct because the system has a Gaussian distribution.