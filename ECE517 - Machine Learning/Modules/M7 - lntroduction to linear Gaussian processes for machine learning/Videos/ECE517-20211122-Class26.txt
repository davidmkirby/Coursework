 Today. So I hope you saw them in videos. That our introduction to what might they, they are in the election to Gaussian processes. But of course I'm going to reveal all the concepts. We'll start well, by doing that. The beginning of it, which was so twice. That's right. So the idea is that we have a model where they follow, they are considered many, many months. So we'll have two of these are members that we have or equal to w transpose x plus error. And we consider a sequence of inputs and outputs plan during the training. They both have known. And so we know we can get this error. We can, we see they are two. And this error is, consider a random variable, a random sequence of which it's one of the elements is it, it's drawn from a Gaussian distribution. They are independent and identically distributed. And so y is also a sequence of random variables that are independent. They are identically distributed except for the fact that each one of the elements, why are bad? They have a given mean. And so with this, we construct what we call the livelihood of y. For the sequence. For this sequence, I wear white board. See what works. So for the sequence wind, we have a probability of Y given the knowledge of x and given an arbitrary value of w. And this signal has this, this distribution, this probability distribution, which is multivariate Gaussian distribution. For waste, the mean is this vector x transpose times X is the matrix containing 1 and w is an arbitrary vector. And now the next step is to assume that W is also a random variable instead of a set of parameters. All right? So this is right. Thanks. So W is a random prime. Well, we can talk a lot about that. But for w, we will also assume that it is a random variable drawn from a Gaussian distribution. And without any knowledge about the observations y and x, W, it has at random this distribution that we can say it's arbitrary. We can put whatever we want because we don't know anything about it. Right? So we chose a Gaussian essentially because it's easy to deal with this. So we assume that the distribution of these parameters is multivariate Gaussian with with covariance matrix that we call sigma b, which is also our trie. We don't know anything on it. Right? But we will see that this can be modified for the pilots weren't in a convenient way. And the mean of the random variable is u in some veterans it. So with this pie or distribution. With the previous likelihood, we can compute the posterior of w with respect to y and x. So here, what we do is to apply the Bayes rule. Prior times likelihood proportional to postition. Plus if the prior is Gaussian and it was, the likelihood is a Gaussian. Here we have the sum product of two Gaussians. Can you move the camera, Please? Of this spring this year. So with the prior and the likelihood, Wittgenstein, the posterior prior times likelihood proportional to the posterior. Plus, we know that this is a Gaussian. This is another Gaussian. So this is a product of Tufts. And then it must have the shape of a Gaussian, right? A product of functions in different dimensions. Of course, here we are talking about the dimensions in a space occupied by y. And here the dimensions of w, we mix them together with the product. And what we have is another Gaussian, right? So here we have Y, and here we have w, Here we have a Gaussian. And here we have another notion that product of these two is subduction. Is it has a shape of a Gaussian, but it has properties and probability, so it must be engulfs. So when we have to do is to do this product. We want get this product. We extract the mean and the covariance and we normalize edge. So the role of this, it adds to one. And then this quantity here, it's not necessary for this process. This process is called in literature, a skull completing the, completing this point. And it's here, it's it's summarized. All right, so what is this probability of w given y and x and posterior is proportional to the likelihood that, that drive these two. They are proportional to do exponentials, this exponential as this exponential here, the normalization factors that we ignore them. So we just get the exponentials because they are the ones that gave the shape of the Gaussian. So multiplying this two is equal to a single exponential whose argument is equal to the sum of this argument plus this R group. Right? So where do we want this posterior? Well, if we maximize or we take the maximum of this posterior, then we will have the value of w that has the maximum probability density. So it's going to be the best. From a Bayesian point. You might find in a Gaussian, the maximum is equal to the mean. Hi, Here we have a maximum which is the mean here on our imaginary zoom in. Here we have our marginal, which is that point here would be the maximum a posteriori. So its duet, we compute them. We ignore the firm 1.5. There is a term 1.5 here. We just ignore it by now and then we compute the sum of these two. We have this, this long equation here that the sum of the first argument, the second argument. And then we, we operate, we end up with this equation here. Where a, it has this a is a matrix that has this expression. Well, this is what we see in the exponent of this new exponential which survived. But this too. But what we want is not this. What we want is something that is a function of w as a covariance and it has a mean, right? So now what we do is to operate over this expression. This expression is the one that we want. We, we identified terms. And here we are assuming that this matrix is equal to this one because we made it appeared here and it has a fun pass. There, will play the role of the inverse of the gradient matrix. Alright? Alright. So we operate and then we identify terms. That's it. It's a long process. Yes, they can of beer. And then necessarily we have that the mean, it has this expression here. And the covariance is a to the power n minus 1. So we wisdom on ice. So my posterior, posterior probability of w given x and y and training training set is proportional to the exponential of minus one over two. W minus W bar, which is the mean transpose times a times w minus w. Then w bar mean. It has this expression sigma n minus 2 times a minus 1 x y. This is a vector, this is a matrix. Matrix is a scalar and the covariance matrix, covariance is a minus one, which is inference. It's expressed here is the inverse of sigma n, Sigma n minus two x, x transpose plus sigma p minus one. Right? Now, a lot of precautions. Let's interpret it and it will make sense. So though your mean is the value of w that has the maximum probability, a posteriori. So it's the optimal value. Right there. This video is the one that has the maximum probability density, the most probable one. Right? Here we have the covariance. Let's rewrite W mean. This is, this is the maximum a posteriori solution. Let's, let's add Theban of this a little bit. Well, w is equal to sigma n squared a minus one. So this here, sigma n minus two x, x transpose plus sigma being minus 1, minus 1 x y. This is, these are matrices. Why this is a vector. And then we put this thing inside here. What we have is x, x transpose plus sigma n squared, right? We put Best Buy. There is a microsite here, so we have to invert this side and we have sigma b minus 1 x y. And finally, for a particular case in which sigma d is an identity, right? If we choose sigma to be an identity where we have is x, x transpose plus sigma n squared I minus 1 x y. And this should ring a bell. What does this? This is a solution of what? What algorithm, what criterion? This is a solution of what? Something that we have. Same side of that retrogression. That is Richard Russia, where sigma is it? Using my square is gunman. Alright, so the optimum value of sigma, I'm sorry, gamma is sigma squared, which is the value of their power or the error, error sequence. Right? So when we optimize gamma, what we get here, it really well if we can't do it well, then what we have is the power of or the variance or the error. This error is the minimum possible. But here, we can put something else which is not necessarily an identity. We can put something else that, and this, by this has to be a covariance matrix. Sigma b must be a gradient matrix, which means it must be a positive semi-definite matrix, that's it. Any. And that is an interpretation of this is a foreign or what we call DIC on our regularization. Right? So what we are here is something with positive. Or non-negative eigenvalues. So this is positive definite. But what would be the interpretation of putting here something which is not an identity because they added this. It has positive eigenvalues. That's it, right? What is, what will be the minimum of that? So recall and we have a prior, and this prior contains this matrix here, right? In my prior. My prior. Here. I set up this matrix. It's arbitrary in our, in our algorithm, sigma be a set arbitrarily. We could go beyond that and say, we are putting on prioritizing my P2 writes and we can extend this algorithm. It's pulling a prior on w sigma t. And we do that. We can do an inference with several levels, right? But we're not talking about that. Yeah. Let's assume that this is arbitrary. And so can you share your screen for a second? Sorry, we can't see the screen. Yeah, I was writing I was going to write it. So our screen here. So here we have a prior, prior us by this matrix. All right? And so if, if I, if I draw it in two dimensions, this is a probability of w given. Given the covariance matrix, we might have some distribution that has the shape. The shape. And this, in this case, sigma being might be, for example, 1, 0.50.51. For example, that would be the value of sigma b. That will give me a shape like that. Alright? Recall that sigma b minus one is multiplied times w transpose w. So here, here I am saying that I give the same importance to the variance of W. But I want sigma b to have to take into account some correlation between the first and the second components of w. But if I choose sigma p equal to 1, 0, 0, 1, I am telling the system that I don't care about any at any convenience or any correlation between first second parts. Okay? And so this till they will give me different solutions, right? Once I multiply this times the prior, times the likelihood, I will have a different distribution, right? It will last from here to here, okay? Depending on what is my prior and posterior will be different. And the convolution is exactly this. I might take into account relationships between different components of w. And then here I am getting the same importance too. One of the components of w, If I would hear a smaller value, that means that I don't care that much about the second component. And I care about the first one. Of course, we don't do that. And if we do, we don't do it explicitly. We don't do it in an explicit way. We'll talk about that. So this is my maximum a posteriori solution, which is similar to the solution that we have enraged. But here we have an interpretation for forgotten, which is their notes or pay out, right? If sigma square is 0 or if this matrix is a matrix of zeros. That means that I don't have, I don't use a variety of zeros here. That means that my prior is a delta around the origin. So I don't put the prior. And so the exponential will become a constant equals one. Right, Let's go back to this screen here. So if I put sigma p here equal to zeros, basically what we have is prejudice. So here what we have is a constant and then this will be equal, exactly equal to the, to the likelihood, the right. And in this case, my solution will be X, X transpose emerson that x, y, which is the minimum mean square error. So since they, my posterior is exactly what to the likelihood. Maximizing, that will be maximizing the likelihood. So a solution without this as a maximum likelihood solution. But we don't care about that. We care about the maximum posterior dosage or window because this is not the end. So we have this solution here. W is the inverse of that Romanians times X1, Right? Exactly equal to the original question. If sigma p minus one equal to the right side, sigma b minus one is equal to 0. Then what we have is maximum a posteriori. What else? Okay? But here is the real thing. Now we have not, we have a maximum positive resolution. By beyond that, we have the posterior probability of w. And we add the likelihood of each one of the training samples. We can compute, Sorry, we can compute the likelihood of a test sample. Given there. They are given the input and given they were given an input and given an arbitrary value for W, right? So this is something that we can compute exactly the same way as in the case of the training data. This probability, we assume is a Gaussian and it has a mean which is w x transpose x. And it has a variance that is sigma square by independent w. And I want a solution that doesn't depend on w because it's arbitrary, but that only depends on the training data. So I want to know what is the probability distribution of my prediction for now for a sample not previously seen by framing, right? I want the distribution of the prediction given a new sample that we call it Hex time. Given that angle here, we need an extra access time and not given w by given the training samples, that training, they are given the knowledge. So just, let's get rid of w. How do we do this? Well, we have this distribution and we put it here. And we multiplied this times the posterior probability of w. And anyway, if we integrate with respect to w, what the solutions are, this integral will be simply the probability of my prediction and the label style given the new sample and given the training samples. So here we'll have, WE will write this as the probability distribution of my new prediction given the knowledge that they have. And the only thing that I have to do is to solve this integral. This integral is salt. I don't have the details here by it. I have the details in that book that I wrote that men, actually, if you look in the literature for everyone, cites the solution, but nobody writes a solution. So I did it in a book. I'm, I'm I think I'm going to ask for permissions and not what the chapter just to Gaussian processes rule defined by each other. Two Gaussian distributions, distributions of yes. And so this is a Gaussian distribution. This is a Gaussian distribution. And this is called marginalization because we intimate respect to w. So w, this BBS process of book. Now on that book, now that book is. I want these two to make you live. Maybe not. That that book is the compendium of all the research that my three bullets either in 15 years when we were in a CD at an Alpha span in, in a, in a cave. In a cave where they serve for the wine. And we're drinking a lot of y. And so we were all the families, they're having fun laughing. And then somebody says, we wish right above the mat and add somebody else, my beer. And then we did it. We did it. By now. Now, I I wrote another book. Or you cannot buy any given by it. But did you do then you tell me because I have to donate, I cannot get any any afternoon. I had to donate the benefits of the board. We cannot get any any money for any book that you buy that I wrote graduating. But I will try to blow the top there. It's an iBook and it's about single brand, I mean, Machine Learning for electromagnetics. That first bar is, your theory about this is, is written there. So here we have a Gaussian, here we have another Gaussian. And so this is a marginalization with respect to w. So there must be another gosh and is not hand has a mean and a covariance amine and a vague I'm sorry, because this is urinate single bay. So we have a mean and a variance. Then the easiest thing is to compute the mean of this expression. And the mean of the integral is about the danger of me. Right? So we do that and we easily get our value. And the same with the variance. The variance is equal to this, they mean of this expression squared minus the mean squared. So when we do our linear algebra, it's extremely easy. And then we get a mean and a variance of this expression. And this is all within, because the Gaussian gets too full to fully describe its mean and its anion. So we don't really need to obviously go, right? That is very difficult. I mean, it's a cumbersome to zombies be true, but we know that this is a gunshot, so we compute the mean and the variance, that's it. And so this is the Gaussian normal and the mean is w hat, sorry, bar, the variance. It has this expression here, right? So the mean of my prediction is equal to W hat transpose times x. So here we have the maximum a posteriori date. All right, so the maximum a posteriori of my prediction is it's still the same as in the case of ridge regression. Right? So one can say, okay, we already had, that's right. Why do we need the Gaussian process? For two reasons. The first is that we don't have just them being a traditional, we have the variance of my British. Say it is a small value. Then I can, I know I can trust the prediction in this daily or is, is, is a high value, then I know that the confidence interval is very wide, so I cannot trust the prediction. And since if my model is good, if my model for the error is a Gaussian and my mother for the prior is adequate, then this is optimal. And if it being optimal, their variance is why, I'm sorry, there's nothing that can be done. So basically done do not trust machine learning, right? But as I said, this under the assumption that the pipe, the prior and the likelihood they are good, they're good, right? They are not far away from reality. So this is the real thing. But that is another reason. Well, this aid, it contains some parameter which is at least one, which is sigma squared. And what is the value of sigma x-bar? We don't know, right? We have to one way or another adjust this value of Sigma squared. So this is somewhat, this is something that we can, we can, we go back to we can go back. To the expression or the training data likelihood. And we maximize it with respect to Sigma squared. And I take B. And then we have the optimal value of sigma1. And with this, we have the variance of the prediction. And this is the first difference between Gaussian processes and what we have done before. Here we have provided that my model, my probalistic model for the likelihoods accurate, then we have an accurate model for the distribution of my prediction. Right? So f star is a function, is w transpose x, where x is x star, w transpose x, That's f. Stop here. This expression, it says that this function f star is latent. We can answer it. It's a random variable that we cannot observe. But we can see it's been annotated. Alright, so Epstein, which is w transpose x, is a function which, which we call a latent function. Basically because W, which is the set of parameters of f, w can do. It's also later, we cannot see it. We don't know which one is the best, but we can see the mean and we can see the covariance made it to the right. That's it. And so this is linear. By these can be customized. So we can repeat the whole process. But we insert their representer theorem inside. And we work with a dual expression of all this and we get an alternative for Gaussian processes that are non-linear, but still keep all the properties of Gaussian processes. In mandibular we can get, we can have a maximum a posteriori for our model. We can have a maximum a posteriori for my prediction. And this maximum a posteriori, if it is Gaussian, then we have a mean and a variance. So that's, that's good. Alright, costumes. Costumes. Now I'm going to do is of course, summarized everything again and the whiteboard. So you can see everything at a glance, right? So this is what I want you to This is what I want you to retains. All right, I want you to present this to be able to reproduce what I say here. Though, that for us this we have a model y n equal to w. Suppose x plus an error. This is for the training data. So why is inside a vector from y one to y n? And I defined as a column vector. Now, matrix X contains all values of x one to x n, right? This is a matrix and this is a bunch of vectors of dimension D. And here we're assuming, we're assuming that x and convince a constant, right? So the first or the last element of X condenser one, it's a one. And w inside condensed be the bias. So we don't see it, but it's inside. So here inside we have a bias. First, second, second. We assume that E n is a random variable which is IID and it's calcium. So be an error. It's drawn from a normal or Gaussian with 0 mean and a variance which is sigma squared. Sigma squared. We don't know where it is, but it's the same for all values of n. And then given this, we know that that y n is drawn from another normal YN. Given amine, an amine is w transpose x n. And the variance of y is exactly equal to the aims of the issue. Still, they have the same variance. The only difference is that these are pseudo mean and this mean. So here we see man's heart. And then also we know that y hat is conditionally by I. Which means that if I know w, k values Hawaiian, they become independent. With this. For the probability distribution of better, why this better, why? It probably distribution of Y is another Gaussian. By this is multivariate Gaussian of all the elements of the sequence is it has a mean which is x transpose w. And the covariance is sigma squared times the identity. Since one of the elements are YN conditionally independent, then the distribution of y is equal to the product of distributions and the product of identical Gaussians. Gaussians we say that with a then the value of and they produce another Gaussian, which in this case is multivariate. It has n components. Whose mean is this? Which are all this means better. Aren't equal variance, which is an identity matrix times Sigma square. So the variance of each one of the various, why is she mad? And they called, and a covariance of between two values. Is it because they in five? We assume that W is a random variable. Random variable we model it with a Gaussian. So it has a prior, which is another Gaussian with 0 mean, where 0 is a vector of zeros and a covariance and we call it sigma B. Arbitrary. This is my prior client, prior, right? This is what we call the likelihood. That's prior on w, on Y given X. And with this, we can compute the posterior distribution of w. So with this, thanks. We can slide our stereo. It says the probability of w given the observations, which is another hormone that has a mean. It has a conveyance. The right discoveries we buy a minus one as an instructor. And a. And so this, this posterior, we can't build it as something which is proportional to the likelihood times the prior, right? We compute it with you. Prior we could. And I go over here and we obtain another Gaussian. Yes. I'm confused as preterm and the normalization of like yes, I've done it right next to it. And w comma. Sorry, sorry. Yes. Come on. You're given these two. Yeah. And where are your a is equal to sigma, sigma n minus 2. Let me say this. I never remember. I think this is the right expression than caveat because I never remember. The 66. Yes, w, w bar, w r is a vector. That is, we call it w1 represents the mean. So a has this expression, right? And then W bar is equal to x, x transpose plus sigma n square. Sigma p minus 1 x y vector, matrix-matrix made it coming. All right, so this is my maximum. Yes, thank you. Posteriori solution for w. And this is something that we said. If we change this by gamma, by an identity where the ridge regression is sigma p minus one is 0. And what we have is maximum likelihood solution because instead of having a posterior, we have our likelihood times point. So a livelihood and what we would be maximizing would be the logical thought. Some minimum is by error as maximum likelihood and range regression is something that approximates the maximum a posteriori. And finally seven. We don't want a solution that contains a much. We want a solution that contains, that was stadium. So we compute the probability of F star given x, star, x and y. Which is good given that, given that F star is equal to w transpose x time, right? So w is some set of vectors of parameters. X is a test sample not included in the training. And then this is what we call a latent function. It's the prediction. With this, we cannot see it because we don't know the volume. By we know the probability distribution, which is equal to the integral for w of the probability of F star given x star and W times the probability of w given x and a y differential of W. And this we know it's a Gaussian with a mean. And this mean is W hat transpose x time. And with a covariance, which is x transpose times a times a minus 1 times a minus one's rights must be a minus one times x star. So this is the posterior probability of F star. And then the mean, I mean here is the maximum a posteriori solution for f star, which is, or f star is in the US and reflects the maximum a posterior solution for my prediction over my new test samples. Where x, well, w bar, is this an equal variance? Variance is this priority queue. Sorry, I didn't see where you're pointing out. This is the valence. So we have this matrix will have these failures, will be a scalar and it's that has still has an interpretation. We can go farther and see what is a depredation. What does this contain side? Why this works, right? Bye. Nia. We I only for today. I like this dolphin process stops. I could be a target a target signed on to hang on to limit myself. And I just want you to understand, we must reproduce these seven points that I have here. With this, you can say that you know, by Gaussian process. And of course there's a bunch of other, some data, some examples, right? And you will be doing more in your homework. And also as an exercise, try to, from this expression to compute the mean and the covariance and the mean and the variance of this expression. All you need to express this. Trunk. Tried to compute the mean and the variance, right? As I tried to upload that time. And I have, I think it's in my archive. I have a published paper when I do all this grooves right in the door without, without the primal. So basically this is an exercise. I understand. They understand what is a Gaussian process and why we want it. But there is more, and in particular in actual space for non-linear Gaussian processes, which is the most interesting thing. So we're going to repeat everything from scratch. Just using a dual expression right here. The way the authors of the book, while the authors of this work is they do it in a primer and then they apply, they, they apply, they represent the student to get a dual expression of this. Right? But there are other ways. There are three different ways to progress on this. Thanks. Yeah. So I've added with all this material, right, but just don't read it yet. I want you to be able to reproduce all these things on your bill would say, Well, yeah. I mean, I had to take to save this expression and white because I never remember. It is sigma goes here, here, whatever. And that's it, right? I don't want you to I know. I don't want you to, to learn this by heart. I don't write well. Basically will ears. You learn how to put all these expressions. But this is NADH may want, I want you to understand the reasoning of a from the beginning to the end. This is the recipe. And of course there are some equations here. They're mostly more than once. They are. This, this, this, and this is for, because I need this to, to populist. And so once we have this algorithm, derivation of this algorithm, you can see that it is very simple. It's very straightforward to program. Remember IT support vector machines, right? We need to go to the wall. And then once we got to do all, we need to apply another. What are the programming and we haven't started? I just say it exists. You use it and it works. But here, we just need to invert the matrix. That's very straightforward computational environment. This is not that bad, right? Well, it has actually and with the helmet and is the same as a supervisor machines is it depends on the number of samples. That's her power, enters her power. And you can optimize this by using flicks. So in an optimized got from process, this has a competition over enough n squared, n squared. So while it's not, not been an easy to program exists of all lengths. What is the most difficult thing to do here? Well, let's assume that we only have one parameter, which is this. Alright, enrich regression. You need to sweep, right? Sigma, sigma, sorry, gamma in order to find the optimal. The good thing here is that we do not need to do any cross validation. All right, we avoid cross-validation here. What do we do here? Sigma is here. And here we have a likelihood. So let's, let's compute the derivative of this with respect to Sigma M equal to 0. So the value of the optimal value of sigma squared is the one that maximizes this equation here. So we have to compute the derivative and then received by gradient descent or a similar procedure because the equation when you compute the derivative equation is not gloves. So we have to proceed iteratively. But we do not need cross validation. Right? The world is difficult than I believe, right? So we don't need cross-validation. But still, the date, the optimization of sigma1 is something that it might be bumpy. So we do not have one solution. The solution, some solutions exist, but the solution is not unique. So in optimizing their language though, respect to Sigma and we mined under a minimal local minimum. So the best we can do is to use different initialization values. For sigma n square and then do the optimization several times. And so will, you will see some, some initializations and converts to a minimum. Some others I will come to another, right? You will find several, several minima or several maxima, and then you have to choose them the best of them. And there are many tricks that they are applied in the software that you have available in Python by virgin, side by or in MATLAB. So basically it works, right? But it's not straightforward. At the trachea is to use several videos for this and start over the initialization several times. And this is the most difficult and most time-consuming part, right? But we do not need any cross-pollination, which means that we save an incredible y with your computational time. Alright, so this has said, as I always say, there's no free lunch in Gaussian processes. We don't have to, we don't have to cross-pollinate. But still the fact that the solution of not unique my produce suboptimal solutions by the price that we pay is that we need a model for the error within our model. Alright, and we choose a Gaussian mile because then it's very straightforward to solve it. The model that we choose, maybe we might say, Yeah, this is very nice, but my error doesn't love life. I don't feel that this is Gaussian. We can try other and we try other distributions because they're Bayes rule still works. Yes, we can. But then the posterior is not that easy to find. And we need some other techniques to find adequate posterior, right? If the prior and the likelihood a Gaussian, the posterior discussion on. So this is our Deborah case of what we call conjugate priors. Alright, but when we want is always a prior that it has, that it's the same family as the posterior. And in this case is very straightforward because if this prior is Gaussian likelihood discussion that was dangerous Gaussian. All right, so these two, these two, they are conjugate the conjugate distribution so that when we multiply the prior and the likelihood, when we compute the posterior, the posterior it has in it. It's of the same finding out why that happens with many functions, right? So I have combinations of likelihood times prior that give me a posterior which is equal to the same family that if they, if the inference is possible, that the same function, for example, yeah, for example, the gamma function is conjugate of a mole. All right? So, yeah. So we have moduli and then we have a gamma, gamma, beta. Gamma is kind of falls off by Young and a Beta S, S will be to the right or below its pKa is by target. Yes, exactly. The binomial there, yeah, there for a modularly is the age that right? So yeah, then there are tables. If you, if you type in Google can do that, then you will go right to the Wikipedia page. And there is a bunch of them right? By its side. We can still do it, but it's not that easy. And so we will need to work together with conjugate priors, wave of light, an IV, which is called variational inference. So if, if you got to the software today, somebody you're getting your adventures, livelihoods that are not Gaussian, then the price they will be vitro conjugate priors. And I'm applying this variational inference. Do you get, you still get a distribution for your posterior, right? But then combinational, but it is not. It becomes our interests, right? But it can be done and it works. And this is basically the beauty of GARCH process. And of course, you will see that this maximum, a posterior solution and a maximum and a, and a variance. They have parameters. When all these parameters, they have to be optimized here. Right? And, and last, well, if we optimize something with the training data, what phenomenon we observe. Overfitting, overfitting, forget. So that's what happens. When we optimize. With respect to the training data. The optimization will leave with respect to the training that we might fall into overfitting. So what do we do that one instead? What we do is we take one sample about here when somebody appeared here. And we compute the likelihood of the sample with respect to the rest. We optimize, or we compute the gradient. We put it back, take an ensemble, we compute the gradient. We add all these together and we go gradient descent in order to minimize the sum of all these great. This is what we call a leave-one-out procedure, right? It's a leave one out. But this is easily one out. But this is not still, it, this is not a cross-validation. All right? Some people say, yeah, with validation in Gaussian process because we have only one eye. Well, it's not the same. It's only training data. It's all of them. And we don't sweep any parameter when we are do is to optimize using gradient descent or Newton based approach. All right, computing the gradient. So the Haitian rights and we use a second-order optimization which is much faster. We can apply another optimization that while it's, there are many ways or several ways to optimize this, which are faster and more efficient. And a symbol gradient civil radian is the idea, right? We go towards the position where they're going to be 0 by we may use the gradient or we may use bother similar techniques. And always using a leave one out. So we do not optimize the likelihood, but we optimize a one-sample respect to the rest. Right? So the sample is, the sample doesn't, is not in the message. That said. So what is left here? Well, now, the next thing that we're going to do is to provide you with a solution that includes kernels. So here, this thing, we change it by Phi of x. We know that w can be expressed as a linear combination of data. And this linear combination is alpha. So we will provide with a solution that instead of having the loyalty has an Alpha and instead of having this dot products here and here, this product here and here, we will have a solution that contains solid dot products between subjects. For right. Here is the mean of the posterior. Sorry, there was, they are here in this posterior in here for this covariance. And we will have TO results from this derivation. First, the pure non-linear Gaussian process with a mean and a variance for the solution for the prediction. Plus a new interpretation of this, or write a new interpretation. So we will understand better what's going on here, what happens here? Why is this a covariance for my y is there's a posterior Cobain's. And so here we will see that we have a prior covariance. So what is the answer there of my prediction when I do not know anything about any training data. And then abstraction, which will be negative, it will decrease. It will make this posterior covariance smaller than the prime. Well, we will see you all this stuff. But I said at this point, please just take a close look to this. Let me know if there's something that they don't fully understand if that data needs to be passed. So we first plot the distribution and that will be decided. Processes. Yes, but we cannot see that because w is arbitrary, right? Well, you, if you can see y, and y must be a Gaussian, but you cannot do a lot of white to see a histogram. Because every sample, every, every value of y, it has a different mean. And how we come up with this evolution that data is based on religious. We have to know about the nature of the data. For example, why The observation that comes from a set of antennas. The main error will come from Bionics. We need to know what we are. We are observing. If, if y is always positive, if it's always positive, then E or epsilon cannot be a. Sorry, this is positive always. Well now it doesn't really matter. The error must be harsh. But yeah, let me think. If y is always positive, cannot be golfer. In y goes between two different values. Between 01. It got to be Gaussian either. So we need to know what is the nature of the data. But in many cases the Gaussian approximation is good. And I think that we can do is the following. We got through all the process, right? Withdrawal process. And then we obtain a value of F that has a mean and a variance, right? We take every prediction and we subtract the mean, right? And then, well, we have to do that with training data. The training data as we can take some data up for them. So we can subtract the mean. And we had the error. Now, we divide the error times the standard deviation. So the square root of this and the barriers that we are left with, they are random variables of 0, mean and variance equal to one. And there we can do a test to see you there. All right. This is something that they do, for example, to detect anomalous. Why they don't buy, I predict something which is a classic McMahon. So you predict something for which you already know the value, right? So you predict a current of a network of our grid given the voltage. And you know it. So even compute the error. If an error and you compute the variance, you divide amphibians. And so our values, they should be inside a multivariate Gaussian. Some videos there will be way out. They do not belong to the same distribution. And this is what we call an anomaly. It might be a fault. It might be something like, say, even though that in order to test whether your system is good, in some papers, what I did is to, to compute, to compute the fraction of samples was error is between 1 sigma or between it is within one sigma. Two segments. If the fraction of videos that are inside one thing my 68% and they've fragile above average that an insight to sigmas are about 98 I belabor ratified I remember. Then this is compatible with the Gaussian distribution. It might be the case that it's not Gaussian, but it works pretty well. And in this case, when you get more samples and the samples they have an error that is beyond two Sigmas then to not trust me something right now, sorry. When sigma is very high, right? Then, do not trust the song. That's why we call them. Are they considered anomalies or outliers? No, no, no, no. Let's see. Let's see. Let's do this. And we'll see example their sample set of slides. Let's assume, let's consider an interpolation, interpolation task, right? So we have a function which is late that say for example, this thing here, right? And then this function is blatant. We don't know it, but we have some samples here, right? This function here, for example, right? And from the samples we have to do an interpolation. From the samples. We have to construct this function. Here we have noisy samples are not too much noise or will have a mean that goes like that. And then here, well, here maybe the samples they work, right? But here we don't have we don't have to make it eight around here, right? We have the samples. We have samples here, right here. We have some balls here. And there is an area where we didn't have samples. So the machine doesn't know what to do. So it will do something like that. For example. Right? Now, here, we know that this function here is not correct for two reasons. First, this into the image I've said, and second, we can see that there's a lot of samples were run. And second, we know the latent function. But in general, this is not the case. We are not in two-dimensions. And of course we don't now related function, say we don't feel it because we're going to be the BAMs where we will obtain in the model is right. We will obtain something like gun, for example, something like that, and something. So here, the variance is small, right? If this confidence interval is equal to two sigma's, that means that 98% of the errors, they will fall between this two. Here. We have the same 98% of the samples. They will fall between these two elements. By this confidence interval is, is high here because we don't have information. Alright? So my predictions here, they will not, they will not be too. Uh, it's not that we have our layers here. Now. It's that we don't have information, right? So for example, my prediction maybe like that. So when I have my input, the output will be this. This is another layer. It's a bad marriage. And the machine will tell you, Hey, this is about prediction. And I'm sorry, there's nothing I can do because afternoon for me. And this is a good thing. The same thing because we don't see as based on data, we don't say, we don't know what I'm going to have false. All right? And in this case, it's very useful to have something that tells me whether to trust it or not. All right. Well, good working during the next session. Next door. Okay. Let me let me take a look to pathogens.