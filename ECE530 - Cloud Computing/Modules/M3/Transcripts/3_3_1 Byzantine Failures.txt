 >> So let us discuss about some theoretical aspects of some of the failures and the Byzantine failures. So many things that a 3PC commit as a practical protocol in order to detect failures. But to really use 3PC commit, we will need a perfect failure detection service that never makes mistakes. It always says, P has failed if, in fact, P has failed, and it never says that P has failed if P is actually up. So the question that we have to answer is, is there a possibility to build such a failure service? So let's discuss about failure in models. At the Cloud, we have seen different types of failure models, and each of them can cause different reactions to the systems. So many things can fail in distributed systems. A network can drop packet, or even once the packets have arrived to the host, the operating system can do so before they get to the user space. Links can break causing a network partition that isolates one or more nodes and it can cause partition tolerance. Process can hang by halting suddenly. This is especially important in JVM, Java-based systems, where you may get these huge spikes in your JVM that you don't know really what happened, but may cause an issue. A clock into the system can malfunction causing different types of issues in terms of reporting in correct time. So a machine could freeze up for a while and then resume. Process can corrupt their memory and behave badly without actually crashing. A process could be taken over by a virus and might have a malicious way that deliberately disrupts a system. So if I get bad actors exists on the Cloud it can give you these attacks. So let's see, the best case scenario is fail-stop with trust notification, and the worst case scenario is having what we call a Byzantine failure. In 2008, Amazon S3 was brought down for several hours when a single-bit hardware error propagated through the system. So what this means that a single failure in a single subsystem could cause the whole thing to go down. So the question is, how do we protect against that? Linux and Windows use timers for failure detection. These can fire even if the remote side is healthy so we get inaccurate failure detections. Of course, many kinds of crashes can be sensed accurately, so for those we get trusted notifications. Some applications depend on TCP, but TCP itself uses timers and so has the same problem. So the bottom line is, when you start using timers to detect something and make a correlation, this happened after that, then subsystems we use timers which may also be reporting incorrectly. So then, how do you really figure out what was the cause of the issue? A Byzantine case, this is like the Byzantine model which is the Byzantine Empire back in days Greek before, after the Roman Empire, that was Byzantine Empire which was based with a Greek language. The idea is, since programs are buggy, it can be appealing to just use a Byzantine model. A bug gives a random corrupt behavior like a mild attack. What I forgot to say is, Byzantine failed at discourse the automatic byte will get resurrected. But going back to this slide, Byzantine model is hard to work with and it can be costly, you often must, outvote the bad process.