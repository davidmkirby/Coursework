 >> So let us see now some examples of failure modes that can happen on the Cloud. So external case two-phase commit and three-phase commit normally used in standard Linux and Windows systems with timers to detect a failure. Hence, we get inaccurate failure sensing with possible mistakes, P thinks L is faulty but L is fine. Three-phase commit is also blocking in this case, although less likely to block than two-phase commit, and it can prove that any commit protocol would have blocking states with inaccurate failure detection. So Werner Vogels: World-Wide Failure Sensing. Vogels wrote a paper in which he argued that we really could do much better. In the Cloud computing setting, the cloud management system often forces slow nodes to crash and restart, and uses as a all-around fixer-upper. Also helpful for elasticity and automated management. [NOISE] So this is true. What happens is many time actually, they believe that instead of actually waiting forever and causing your whole system to halt, especially when you're trying to do like three or two phase commits, it's better to actually kill the slow nodes and have abundant time of errors. So in the Cloud management layer is a fairly trustworthy partner, if we're to make use of it. AWS actually does that well, when they detect a potential failure node because a node is a little slower or whatever, they totally terminate it and they can take it out, and then they just bring a new hardware or a new VM. Suppose the mailman wants a signature. He rings and waits for a few seconds. Nobody comes to the door, should he assume that you have died? Hopefully not. Vogels suggests that there are many reasons a machine might timeout and yet not to be faulty, as we see in this example. Scheduling can be sluggish. So what can cause delay in the cloud? So scheduling can be sluggish, like when you schedule something, how long does it take to schedule and so forth? A node might get a burst of messages that overflow input sockets and trigger a message loss or a network could have some malfunction in its router or links. So that means that although the message can arrive or they can be lost, but we don't know when it will arrive because of input queues and message losses. A machine might become overloaded and slow because too many virtual machines were mapped on it. So this can be like the actual hardware can be overloaded. Even the JVM, honestly, within a virtual machine can halt. So for example, if you write your software in Java, Java uses its own virtual machine, which is called JVM. Actually, the benefit of that, it allows portability between operating systems at the same time. It's a virtual machine so it can have the last word. So an application might run wild and page heavily. Page may be like you may get or you may have memory leaks so it can cause taking a lot of memory. So Vogels suggests we recommend that we add some failure monitoring service as a standard network component, instead of relying on timeout, even protocols like RPC, TCP could ask the service and it would tell them. [NOISE] It could do a bit of sleuthing first, ask the operating system or that machine for information, and then check the network. So why clouds don't do this. In the cloud, our focus tends to be on keeping the majority of the system running, no matter what the excuse might be. If some node is slow, it makes more sense to move on. Keeping the cloud up as a whole, it is way more valuable than waiting for some slow node to catch up. So in the end of the day, what matters is the end-user experience. So what experience do you get when you use VMs? So the cloud is causal about killing things, it avoids services like failure sensing since they could become bottlenecks. So what bottom line is what I mentioned before, is in order to have a good experience, it's better to kill an instance if you think it's slow than actually keeping that and have big slow because it can cause other errors within services as well and probably disorders to other systems. Also, most software is buggy, so let's now go into details about two types of bugs; the bohrbugs and the heisenbugs. These based on Bohr and Heisen, two very famous scientists. Bohrbugs are boring and very easy to fix, like Bohr problem of the atom. You get to figure out, "Oh, there's a problem here. It needs a fix, I'm going to fix it and I'm going to move on." Heisenbugs are the most difficult one. They seek to hide when you try to pin them down, caused by, for example, concurrency and problems that corrupt data structures. It could be visited for awhile. But it's hard to fix because crash seems unrelated to the bug. So you try to say, "Oh, this is the reason why it crashed," but then you can't really figure out that bugged out, what was the actual bug that caused. Studies show that pretty much all programs retain bugs over their full lifetime and that's true. Actually, many software are being created over a duration of like let's say five years or so. So all of a sudden, we have a new version or new variation, you always have bugs that, in the beginning there will be a lot of bohrbugs and then you may have a lot of heisenbugs. So if something acting strange, it maybe actually failing. Worst of all, its timing can also be flakey. When you have like billions and billions of dollars that you scale, you cannot trust timers at all. Too many things can cause problems that manifest as timing faults or timeouts. At the same time, with millions of nodes and billions, it's hard to even synchronize the fibers within all these nodes. So for example, how do you get all that to work? If a node fails, that actually happened before another one if their timer is running faster. Again, there are some famous models and again, none is ideal for describing real clouds. Real clouds is what we said, it's a very difficult distributed systems problem. We have to absorb that, timing can be a significant issue in the cloud.