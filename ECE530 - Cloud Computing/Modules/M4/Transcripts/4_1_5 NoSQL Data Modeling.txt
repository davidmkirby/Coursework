 >> One of the main things that somebody working with databases they have to do is what we call data modelling. A lot of things have been said about relational data modeling. It's complicated it requires some domain expertise to do that. As more and more systems move to the Cloud then the NoSQL database becomes more of a de facto thing, then I think that's what we'll discuss today. Fundamentally, the NoSQL data focus around what we said before as flexible schema, which unlike SQL databases where you must determine and declare a table schema before inserting the data. In this case you don't have to do that. This flexibility facilitates the mapping of documents or entity or an object. Each document can match the data fields of the represented entity, even if the data has substantial variation. In practice however, the document in a collection share a similar structure. What you would see as we move forward towards the slide deck is that we will focus mainly on the documents data just because it's the prevailing NoSQL paradigm, as well as because it's similar to explain. What are the challenges in data modelling? The key challenge in data modelling is balancing the needs of the application, that is the performance characteristics of the database engine and the data retrieval patterns. These are the three main things that we need to balance out. The needs of the application that performs correctly with database and the data retrieval patterns. Which means that if you can decide a random data model, without that I would say the application itself or the database or the retrieval patterns. When designing data models always consider application usage of the data, like the queries, updates and processing of the data as well as the inherent structure of the data itself. For example, one of the common things that you need to pay attention is, what types, whether this is like a point queries or what it's like scans across many keys, and what type of scans it may be, and then decide accordingly with the data model. Make a decision designing the data models for results around the structure of documents and how the application represent relationships between data. In the SQL space, automatically that can be done through joints, but this is not allowed or they should not actually allow those SQL because you don't have to wait. There are tools that allow applications to represent these relationships. One is called the references and the other is called the embedded documents. Embedded documents capture relationships between data by storing related data in a single document structure. In NoSQL, documents may make it possible to embed document structures as sub-documents in a field or array within a document. In this case, what you can see is you can have the contact and then you can have an embedded sub-document which is in the phone and the email, and then the access, then the level of the group itself. In this case, what you can see these now you have established some form of relationships between the data and you have done that through an embedded process. Embedded documents capture relationships between data by storing data in a single document structure. When you use embedded documents, you have "contains" the relationships between entities one-to- one relationships, and you can also have one-to-many relationships between entities. In these relationships the embedding or sub-documents always appear with or within view to the cortex of the one or parent documents. If we go back to this example, this is the sub-documents. This is a one-to-many relationship. Embedding provides better performance for read operations as well as the ability to request and retrieve related data to a single database operation. Again, if we go back and request the phone, we can say, db.IDX, find contact.phone, and within a single query you can actually tear back the sub-documents. Embedded data models make it possible to update related data in a single atomic write operation. Similar to the [inaudible] , you can also do an update of the data, and you can do that in a single operation. The second way you can do relationships is through references. References store the relationships between data by including links or references from one document to another. Application can resolve these references to access the related data. In this example, you have like a user ID,id object ID. Then you have a contact document and then an access document. What you can see here in both cases, we have replicated the ID. The ID field is different. But then you need to have a user ID, which actually points back to the previous document. It's subsets. This is kind of emulates adjoined within a relational database. When to use references? In general, use normalized data models: when embedding would result in duplication of data but would not provide sufficient read performance advantages to outweigh the implications of the duplication. To represent more complex, many-to-many relationships. To model large hierarchical datasets. Fundamentally, if you think about it right, embedding is where you have one to many or many to one and references when you have many to many relationships. Also when embedding will result in duplication of data. If you have, let's say, many times in the same field that you probably want to use references because then you can actually have one instance of the data. References provides more flexibility than embedding. However, client-side applications must issue follow-up queries to resolve the references. In other words, normalized data models can require more round trips to the server. Now these actually cause a number of issues because if you would update both your object, both documents at the same time and you cannot do transactions, then it may actually become the in causes to the state. Write operations are atomic at the document level, and no single write operation can atomically affect more than one document or more than one collection. This is what I just mentioned. If in the case of references, if you actually update your document, you could also have an atomic operation within that document. You cannot have an atomic operation across different documents. A de-normalized data model with embedded data combines all related data for represented entity in a single document. This facilitates atomic write operations since a single write operation can insert or update the data for an entity. Just mention that. Normalizing the data would split the data across multiple collections and will require multiple write operations that are not atomic collectively. Let's go ahead and see a little more details about the query processing in the NoSQL space. NoSQL has some fundamental limitations that we need to be aware of. It calls for a more relaxed data consistency model. It provides primitive querying and searching capability. Obviously by data consistency we mean that now you don't have like consistent partition-tolerance. In some cases you have to give this up for [inaudible] available there, partition-tolerance or some other data structure. Many of the NoSQL DBs today is based on the Distributed Hash Table, which provides a hashtable access semantics. To access or modify any object data, the client is required to supply the primary key of the object, then the database will look up the object using an equality match to the supplied key. In all cases we said you provide the object ID or the document ID, or the key in the key value pairs, and then you return back the data as the value of the information. For example, if we use a Distributed Hash table to implement a customer DB, database, we can choose the customer ID as the key. Then we can or set or operate on any customer object if we know it's an ID. For example, if we have cust data, this will be a distributed hash table. Don't get over the customer ID. Then if we go to set some data, we'll use the same customer ID, then we will modify the customer data. Then if we work through some other query like execute we'll use still the customer ID and then the function that we want to perform with the data. In the real world, we may want to search data based on other attributes than its primary key. We may use also search attributes based on, let's say, greater or less than relationship. You know, this is going to code. Or we want to combine multiple search criteria using a boolean expression. You also have these leads. Some of the NoSQL databases provides an indexing and query processing mechanism within the local database. In this case, we can have the query processor broadcast the query to every Distributed Hash table where a local search will be conducted with result sent back to the query processor which aggregates into a single response. In this case, for example, you have the query processor which receives the queries, then it propagates the query across different nodes and receives the response and then responds back to the customer in every single response. This is some way some database actually work like that. This is some aggregation of the results and that's why these scatter and gather local sets.