 >> Long-term storage, obviously the terminology itself may not be the right one but it assumes that you need to store a lot of data and you probably need to store it for a long time. You don't have very frequent access patterns [NOISE]. The fundamental component, this long-term storage area, is the object storage that is redundant scalable object storage using clusters of standardized servers capable of storing petabytes or even exabytes of data. Object storage is not a traditional file system, but rather a distributed storage system for static data such as virtual machine backups, photo storage, e-mail storage, backups, and archives. Mainly it is accessed through APIs. It has no central brain or master point of control. It provides greater scalability, redundancy and durability. Again, this is not about either [inaudible] files, this is mostly about using the application and services that need to access the data. [NOISE] Objects and files are written to multiple disk drives spread throughout servers in the data center and all that is being handled by the infrastructures service provider. IaaS software responsible for ensuring data replication and integrity across the whole cluster so again the user does really need to know all the details of how this is being done. Storage clusters scale horizontally simply by adding new servers. Should a server or hard drive fail, the IaaS vendor replicates its content from other active nodes to new locations in the cluster. IaaS vendors use software logic to ensure data replication and distribution across different devices, inexpensive commodity hard drives or servers can be used in lieu of more expensive equipment. Technically, the service provider deals with how the data be replicated and what storage system it is actually stored. Most of the Cloud providers either AWS or Google or rather, usually talk about eleven dynasty's durability and scale past tens of trillions of objects. The difference between blocks and objects is in one case you access the data through an API, in the other case you use this form of blocks. Obviously, as we said, block storage is when you tag that delivery to a machine whereas in object storage you use an API to access the data [NOISE]. Let's see now how do you really make a storage decision beginning with what we discussed, the ephemeral storage, block storage and on object storage. In ephemeral storage, you run an operating system and scratch space. In block storage, you add additional persistent storage to the virtual machine. In object storage, you store data including VM images, or even PDF files and so forth. In the first case, ephemeral storage works through a file system, in the second through a block device, but they subtract that through the file system. The object storage is through APIs or vendor-specific APIs. When we see where it is accessible, ephemeral storage that's the hardware of the VM, is actually within the VM, looks as we feed a VM, but it can be sent across VMs. Object storage is anywhere. Now, in ephemeral storage, the VM is terminated, so you lose the data. In block storage deleted by the user, the data, and again the object storage the data is deleted by the user [NOISE]. Usually, when we discuss about it or how about [inaudible] to add terabyte. It's a good space to store in ephemeral storage, but above that, you probably want to use some form of block storage or even store it in object storage because it can store up to exabytes of data [NOISE]. Now, S3 as the beach or AWS product that offers object storage, it provides different types of DSS similar for others, like Google, the airline, and so forth. It provides S3 Standard, S3 Intelligent-Tiering, S3 Infrequent Access and all of these come with different price tags. For example [NOISE], in S3 Standard you pay a lot for storing the data, and you pay very little to retrieve the data, but if you go down to S3 Glacier Deep Archive, that's what you actually pay a lot for the retrieval, but you don't pay a lot to store the data. Let's move to the next slide we'll see this, so when you try to see the different areas, like where each one is being used. All of them provide the same durability. The common use case for S3 Standard is when you have active data, whereas a Glacier you have a near-line archive. I would really [inaudible] archive data [NOISE]. As you can see, the list of the features that the provider provides, it's pretty much the same across all this. But with both dark is the slide right there, public pricing for S3 standard. There she's like Glacier, you see the storage per gigabyte is much more, it's multiples, it's an order of much more than S3 Standard compared to Glacier Deep Archive. Whereas when you see the retrieval line [NOISE], it's the difference. Is that the retrieval for Deep Archive is supposed to be almost two times more per gigabyte more than what is paid S3 Standard and the reason for that is Deep Archive is used for archival pitch, so a database, it's like to motivate you from accessing the data from the archive. Then there are different types of price tags in different perspective like if you add the data, the added data to S3 Standard is very low, but if you add the data, in Glacier, it's much more expensive. The rest of the course catalog with that. Common media and entertainment use cases, daily production, news, sports, web or social broadcast can use an S3 Standard, but when you need to really keep your code that preservation or long-term storage that when you actually use the Deep Archive. The use cases is different per product here. Let's now go to data archiving. We said here [NOISE], back in the days, Glacier was actually used to be separate at all that at some point it was embedded within S3 so that's why it's flat. But it barely providers provides this data archiving it down. They say, combined with those exponents to make it seamless out of it. IaaS provides a secure, durable, extremely low-cost cloud storage service for data archiving and long-term backup. Customers can reliably store large amounts of data for less than one cent per gigabyte. Actually said that it's actually worth less than one cent its much less than one cent per gigabyte. To keep costs low, low data character codes are optimized for infrequently accessed data where a retrieval time for several hours is suitable as we say, like for example, Deep Archive can take up to 40 [inaudible] with backup data. Whereas in S3 Standard it can be really fast [NOISE]. It can be very useful to decrease the cost of storing data that you don't really access. You just store it there for, let's say once a year you may access it. Now, the other aspect is there's also other ways that you get to store as the attachment data, and one of them is, this is the device that AWS provides where you actually can use a USB to store types of data that you get translated to a centralized location and you can transfer like terabytes or petabytes of data. Actually, there was a law conference, they brought a whole track where you could actually use it to store a lot of the data, so AWS provides more and more and even other providers provide more and more ways that you can actually store the data. This is actually called the snowball device, that's how AWS calls it [NOISE]. As we said, there are different offerings that exist, based on cloud providers, Openstack and the blocks are received that addresses Elastic Block Storage. In block storage, Openstack Swift, AWS S3, Azure Blob Storage, Google use Cloud Storage. Data archiving in the AWS Glacier. Others, [inaudible] and so forth. Huge data transfer, AWS snowball, Azure Import-Export. You know different providers provide different names for each of these offerings.