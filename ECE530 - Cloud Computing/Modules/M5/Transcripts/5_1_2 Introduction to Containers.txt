 >> So let's move on to the second part of the microservices where we're trying to introduce the containers. From microservices to container, Agile software development is a broadly adopted methodology in enterprises today. Effectively Agile is where you continuously iterate over the software we are building and deploying. So now I want to moving towards the idea of full-stack-responsibility for individual services. So back in the old days, what would happen is there will be somebody who will do the development, somebody who will do the quality assurance like test the codes, someone who will deploy that. So you will have these different verticals of people that, once you start deploying services on the Cloud, you have different types of externalities. But we've seen that this has slowed down a lot. So more than our companies what they apply is this full cycle responsibility where somebody is responsible for the beginning to the end. This is because we're moving, from a monolith where you don't have like centralized testing, but you have like isolated business logic testing only for the service that someone develops. Infrastructure needs to scale differently and the self-service model for project is taking center stage. So what we see here is we see different Cloud providers like Amazon, Google, Azure, Openstack, and so forth. Then you have, virtual machines and on top of that you deploy different types of microservices. Containers now are becoming what we call the foundation for this like along with proper DevOps and orchestration. So what's a container? A container is more like a lightweight VM, it's not really a VM, and we'll discuss it in a few seconds. So when we discuss about microservices, let's think about the complexities and the design considerations. We need to do have like a distribute application logic. With microservice, the logic now is spread across the services and more importantly, these embedded in the control and data flow between these services. You have now diverse technology stack. The system maybe comprised of in-house developed services, open source software and external libraries. So what that means is when you have microservices and you have these independent functionality, you can have a service that is based on robots or software and then you could have in-house developed software, as well as services. A great example in some of the companies, they may use like an open-source databases like Cassandra. Then they will develop their own way of accessing. The data Cassandra from it's own a specific side is developed in Java. Or it might be, they maybe using some sort of other inop the famous open-source project. One of them is like Envoy which approx developed by Lyft. At the same time at the backend, you may have something else that you have developed in-house. One of the issues now of course with microservices it's kind of hard to test and debug, when you have all this interactions, the first of interactions with the hundred microservices deployed, as you try to identify where is the problem within the stack, whenever you actually see an issue, it's kind of hard. Then sometimes we may get into the part where we will have what we call the butterfly effect, like a minor change of a service could eventually be catasrophic for the whole service. We have seen that in many cases. So many times, what happens is the focus of the whole company becomes about, how do we disengage in it's service? The errors, so it doesn't have a compounding effect in other services. An example would be if for example, a service is getting out of memory or is generate multiple traffic that the downstream services now have to accommodate that. So it creates more pressure, they ran out of memory and so forth. It can escalate too many services. So it can be catastrophic. So containers in some sense it is related to microservices, but it's not like a 100 percent about one matching. Container is more like an infrastructure. So this is more the new concept of virtualization solution for platform as a service and infrastructure service due to containers increase in density, isolation, elasticity, rapid provisioning. So what happens is when you have a VM. You need to effectively start a VM board in your operating system. So you need to take some amount of time to start a VM. It usually takes a few minutes to put a VM, check everything and so forth. With containers it's more like a lightweight package instead of a virtual machine. So you move effectively from a large monolithic application that has to be developed within a virtual machine, to smaller type of components that can be just deployed really fast with containers. So containers is actually [inaudible] top operating system. So you're going to actually slice and dice operating system. So at the same time, you can containerize parts of the applications. We're going to learn that through the homework as well. When effectively some part the application is one container, some other part is the other container. You can move parts of applications in different types of cloud infrastructure. With virtual machines when you produce a virtual machine you have a basic something that is related to a specific cloud infrastructure, whether it's AWS or Google or Microsoft and so forth. But once you move towards containers, now you can move containers between different operating and different Cloud providers as long as they have the same operating system. So if you use Ubuntu then you just need move containers across Ubuntu operating systems. It simplifies immigration complications between private, public and hybrid Clouds. The beauty about that is now the other frameworks like Kubernetes, where people use it to schedule containers across different Cloud providers. So let's see about, how did we come up with this idea of containers? If we see about the  history of the cargo transport, back in the day, we will have all these goods. Cars, oil and a pianos and so forth. What we'll do is we'll try to do a mapping between that and the ways that we can transport the services in these goods. So that was how we use to effectively move data. Now in the last 40 years, we move towards a solution where say, okay, the phase between the transport and the actual goods becomes container. So as you progress, you can't fit everything within a container. Now what the transport happens now in moving containers. Only at the last mile you're actually moving the actual products. So this is the same idea. So if we see the same analogy with virtualization. Back in 95, we had a thick client-server applications on a thick client, well-defined grand type operating system middleware. Then you run that in monolithic fiscal infrastructure. To those [inaudible] there after you know now the clients are becoming thinner and thinner you have applications that effectively just on mobile, just do rest APIs. Then you have services that are being developed in smaller elements, business logic. Then you have some sort of running on physical resources or Cloud or private infrastructure virtualized. So effectively what we did is we move from your millions of dollar of spending in many Frames towards people now using, spinning up by hundreds of virtual machines pretty easily to solve the problem. Of course, when we try to think about what will be the problem if we do that. Because when it is  effectively we see like they separate former Soviet. Now you have not rerun again or on the physical hardware, but you have to run it on top of virtual machine sort of hypervisors, which means you are actually paying an overhead for that app performance overhead for that, because you're not directly accessing the memory. That happens through the hypervisor. So when we try to take the same issue with the container ecosystem we discussed before. You have to start a website, you have database, you have Web frontend, you have Queues, you have Analytics DB. So you have all these different elements, all these different services with your echo system. What we'll do right now we're moving towards an idea of deploying that of containers. The containers now can then be deployed anywhere. So it becomes oblivious to how you deploy these microservices to the actual hardware that you deploy the services. So now you can deploy the container on top of a QA server or develop the system on a public Cloud on a production cluster, or you can even develop it on your laptops. Now the great thing about that is now you can still have containers on your laptop, which actually gives you a significant advantage because the same [inaudible] and adopt the formula there are the same behavior that you see of the business logic on the container on your laptop will actually be the same as you move to the Cloud.