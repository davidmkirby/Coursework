 So let's start our class today. Yes, Since I will record them, though, I know the answers and I know other whether they are non hear something. Okay? Okay. Okay. Yeah. Actually, I got alarm about that. Some place on the parking yesterday, right? Hello, everyone. Good. So yeah, we can start our class and I will record the class for me if necessary. They can check the video. Afternoon, everyone. This is the class off course. If I spray and the University of New Mexico. So thank you for coming. As though was wounded. Here is only a lesson. Yeah. We're finished. Your earnings, uh, approach including the okay. No, I open the room here. And isn't it It's just from the first two slides. Okay. Yeah. Okay. So yeah, last class we ended here by studying the discussion about the data level parallelism, right? And for those the best effect computing architectures, yes, about the single instruction multiple data, data computing architecture, we have discussed two types out there. Variations, The including the vector processor and the SIMD, ISE though extinction. So yeah, we have already know the approaches 0 vector processors, the ISM, the, yeah, in order to write the data level parallelism. So let's first have the grip review by showing the difference between de facto processor, a single instruction, multiple data stream. So actually a vector processor sense we've talked before this canada of architectures are now considered a separate a from the FIM, the computers. Yeah. Based on the fact that the vector processors, all the computers presented the factors one wards at a thin ham or N1 times shorter peptide and processors. Yeah, even though they are still based on a single instruction. Yeah, a NESARC teachers the mode, an SIMD computer process all elements of the vector simultaneously. So in the implementation, the vector processor are typically more flexible with non-fixed subvector. Let's add the flexible unless I know the programmers to have larger bulk field vectors. Yeah, Actually the field vector registers or the smaller fog more vector register. So that is flexible, right? So, well, on the other hand, thus the SIMD, they have rigid vector registers. Yeah, Also the vectors are fates. So beside the back processors and how those yet or gather instruction that it can move that data just between decibel memory. And that those three gestures to make a balance between the data storage. So a sub byte out that these other languages, actually the SIMD extensions and have certain advantages over the fence or architectures. Yeah. Since the SIMD extensions, they cost a nato to add to the standard ALU and it is easy to implement, end up computing lab teachers. And they require a little extra days for their control for the operation. Yeah, It means that it is also easy for the context switch all it'll cross little extra memory bandwidth. That is definitely new world or the voltage of the time, the extension architecture. And also there is no virtual memory. A problem for the SIMD extensions computing architecture since you know the simple memory of an OH, on that same boar operation seeing the memory. So that is that the advantages for the SIM extensions. So how about the start of variation about the GPU SQL? It started to talk in the last class. So. The GPU graphics processing units. So add the third time the architecture in order to explore the data about parallelize them to the GPUs. Actually, they ask our teachers with high power and operations for the computate, computation intensive operations, and also for the 100 parallel computing's. So GPUs, it has a long history that runs in parallel with the vector processor. And also GPOs are our age and I decided to lead to offload the graphics rendering from the CPU. Yeah, not as a computation. Already know the CPU. But they have become very popular for the leg, for applications from the media applications. And the reason that they are used for a variety of scientific and also machine learning applications that you are now GPU. Or we offer me know with the General Purpose GPU that out spoke about the GPGPUs, right? So combine with the availability of the programming language, the program GPUs and has opened up. And yeah, Actually again, say that an open option of using the GPIOs for the general purpose computer instead of the pure CPO as conventionally used. So GPUs for a heterogeneous execution mode that is modal, combine them with you and I also teach you as shown here. So yeah, this model can have the CPU, the host at the GPU, as that implies, in the computing system. Now we'll call the heterogeneous computing system all heterogenous execution model. So in this system, actually there is one Chinese at this challenge in life in partitioning the computation from the question between those CPU or GPU and also the usage of the system memory and the device memory. So you need to decide how to partition this computation between the CPU and GPU in this heterogeneous execution mode or heterogeneous computing system. So DPOs have, yeah, Every time of the parallel lines and that can be captured by the program and empowerment like the MIMD, SIMD or the multithreading and the instruction level parallelism. Well, the manufacturers actually the EBITDA have event of the US they like language to in order to explode all stores of the paradine, some it also in order to make the programming of the GPUs ease this through their computer, the Union fight the price architecture that away caught. Yeah, I meant for amino with a COOH, that computing architecture. So these are two oxygens you're at your OpenCL. That is the vector independent programming language give deployed for the multiple headphones. So on. This has met the programming of that GPUs much easier. And also the increased popularity of the GPGPU computing architecture. It by shuffle, currently computing our teachers. Yeah, it's common to say that GPGPU computing our teacher, combine it with the CPU and also that GPUs to dedicated for the computation from the application to boost the performance of that. Yeah, Also the angio as a credit risk. So a VGA has unified all the forms out the GPO paradise them at the coup that thread. Yeah. So the compiler and the final word, Kento Bento, combines thousands of the thread to explore the old phones, other paradigms of Gerasa execution. So actually the programming model as single instruction multiple thread. So Australia is associated with each data element in this architecture. And the spread organized into blocks. Yeah, we can have the thread blocks up to 512 element. So Almaty thread, SIMD processor at the hardware that can execute the horse red. Bob, actuate the block with almost or 32 adamant, it's cumulative persuade time. So that is the really a lot further level of the paradigms them off the thread. So those red blocks are organized into a grid and blogs, or it's curated independently and in any order. So different blocks in this architecture can not communicate directly between them. Well, they can coordinate it using the automatic memory operation in global memory. So the GPU hardware itself can handle the spread management rather than the applications or the operating system. So a multiprocessor, it's composed of multithreaded. If I'm the processors and thread blocks scheduler is actually responsible for gathering all the threads on the crudest system so that the whole procedure, including the controller that's gatherer, the execution element, and also the data memory. Now to combine together makes a system will work for that. Deployed the paradigms of. So when we talk about the GPUs, uh, yeah, actually, we definitely need to first know what is the computing graphics, right? Yeah, that is the application of all document form application that we can use GPU to deal with this kind of computation. So actually computer graphs as a feel of the Computer Science and started actually dies. A method for detune it, synthesising in ourselves and manage virtual content, shown here. So, you know, the term often refers to as a start out, those three-dimensional computing, computer graphs, graphics. It also lets you say DALYS, the two dimensional graphics, and also the image processing, right? So computer graphics is started the manipulation of the visual and the audio metric information using the computational technologies answer now, it focuses on the mathematical and also the computational data as the foundation thought, the image generation and also the foundation of the processing rather send purely arithmetic issues, right? So computer graphics actually often get fresh air from the few the author visualization. Although you know this to fade have many similarities. So as the picture showing here, these pictures here actually is that the real applications of computer graphics and is better at ammonia and r1, r0 up the two-port desktop. All right. That is iconic model in 3D computer graphics created by da, da, da, da, da, by Marty. Now we're in around 1975, right? So what is the high demands ends up processing spayed mammary axis of the above computing the computer graphics applications, actual graphics processing units were called GPU, is a specialized electronic Tokyo designed to rapidly manipulate and also added the memory to accelerate the creation of the images in the frame border, HH for the output to display device, right? So they need extremely high performance and that speed, the memory axis are in this computer graphics applications. So they either satisfied this demand, justice issues. Actually, GPUs are used in embedded systems, some also in mobile phones, personal computers, and workstations, and also some game consoles. So more than GPUs are very efficient at Malibu, manipulating computer graphics and also legs image processing. And they're highly parallel structure can make them more efficient than the general-purpose CPU. They are more efficient than the general-purpose computing unit for the better or for the algorithm that can process large block of data that need aim paradigm so that I have the common computations in current applications, especially for the machine learning applications and the AI models, right? So bad why GPUs are what I used for this kind of applications. Object there as the rapid rise of the GPU computing. Yeah, From this video, we can have an intuitive understanding and Fiona about how the GPOs are working. Yeah, also the speed and the rise of the GPU computing. In the, in this short video, I will show you. Hi, thanks for tuning into prosperity. This video is a sixth and a multi-part series discussing computing. In this video, we'll be discussing the rise of GPU computing. Cpu utilize multiple cores and as of recently have an increase in four counts. Graphics processing units or GPUs, essentially take the concept of parallelization and expand on it in a massive way. Observing that trend from them, the 990, as you can see, core construct steadily increasing for about a decade from one core in 995 to 24 cores by 2006. So a steady rate of growth of about two cores per year. 2006 was an inflection point, has GPU computing, where we saw massive jump from 2004, Course 2 over 5 times 128 by 2009, progressing to present day, you can see that the shift in massive parallelism has been focused on more and more from our rate of growth of about two ports per year to now about 200 as of this year 2018, we are now ration graphics architectures such as NVIDIA, Volta with core counts over 5000. To understand why GPUs are becoming so widely adopted today, it is best to first understand their original purpose, graphics more specifically for gaming. I'm sure that's how the majority of people myself included still view companies such as in video NAMD today, gaming has an extremely computationally intensive task. And as the years progressed and it's only continue to grow more and more complicated. There are so many things to simulate, such as materials, lighting, shadows, physics of different materials and their interactions with, I think, as well as other materials, various fluid simulations, procedural generation. The list can go on and on to highlight the level of complexity some games can reach. I want to play a clip from one of the most ambitious games and development today, star citizen. Hey, you can see from the thousands of other applications I didn't even mention, games require in the order of millions, even billions of computations per second. And this is only set to increase as technologies such as VR started getting more traction, this little eye GPUs are focused end of increased so rapidly and parallelism since the mid 2000s. This massive parallelism is not bleeding into other applications. One of the most mainstream currently. And why such mass adoption of GPU such as artificial intelligence, more specifically, deep learning. We'll explore this topic much as GDPR in this channel video series. But essentially, machine-learning models typically require billions, trillions or matrix operations, which are just simple multiplies and additions GPUs by default, Excel, I drink water, not so repetitive calculation is due to the recent gaming. Thus, deep learning was all this. The positive feedback loop, increasing graphics and simulations and increased AI performance will repel each other forward, such as AI and computer characters and increase realism accumulations and physics. This also translates you progressing scientific innovation as well, both in the micro and macro scale with the use of GPUs to model and research the smallest things such as protein folding to things as large as more accurate while they're simulations or even larger, such as gravitational wave simulations. Now a word from NVIDIA CEO and co-founder Jensen, to highlight some of what I've talked about further, in order to train this neural net with huge amounts of data, you need to do huge amounts of computation. Isn't days. I said Baroness. Manufacturers about GPU or the path on recently. Right? Yeah, because plant and trillions and trillions of operations necessary to effectively, for this neural network brain, learn how to perform an intelligent task like image recognition or voice recognition. Well, that handicap, that handicap was overcome with the discovery of the GPU. And so these two factors, the end of Moore's law and the emergence of a new software development method. A new software technique happened almost exactly the same time. And these two dynamics turbocharged the adoption of GPU computing. This form of computing we've been working on for literally a decade and a house. In fact, you could say that ever since the founding of our company. We've focused on only this form of computing. No company of our scale and size has ever dedicated itself, does this one singular field of computer science, GPU accelerated computing, was all we do. Now as a company of 12 thousand people. We've now dedicated and invested some close to $30 billion in the pursuit of advancing GPU accelerated computing. Easily observable by NVIDIA stock price of GPU computing is a new industry standard and is now being massively adopted across all fields that require intensive computing. This is also observable by that try to compute performance over the past 120 years. But the last seven data points from 2006, all being GPUs. The majority of GPUs are still primarily at 60 nanometer node sizes, able to deliver performance a teraflop levels such as and videos per skill and ANDs data, high-end consumer cards, which it will clicking around 12 turf lumps. This is just a general performance for calculations run on these GPUs, as discussed in a previous video, this computing series, hardware and software optimization is kinda increases performance much further. This can be exemplified by invidious latest GPU architecture, Volta, who specifically designed for artificial intelligence. They're highest-end cards. The Tesla be 100s, will support count of 5 thousand 120, that a node size of 12 nanometres, in general, performance of 15 teraflops. However, when running machine learning computational tasks yields a performance of 120 teraflops, eight times greater than its general performance, well exceeding the prediction of Moore's Law, this insane performance is achieved you to tensor coerced and tensors sort. As mentioned earlier, deep learning involves many matrix operations. Tensor quarter of specialized hardware and bolts of GPUs that allow for asynchronous computation for the multiplications and additions involved in these matrix operations, the shields 12 times greater throughput than the same operations on a scale card tensors sort, simply referred to as tension or RT, is an optimized compiler for machine learning code. So essentially, the damsel to card support various machine learning languages such as TensorFlow, pytorch and others. Then tensor Arctic compiles and optimize the code to be wrong a tensor course, this is done through various processes such as reduced precision layer fusion, multi stream execution, and much more that we'll explore in a future AI video. This optimization gives 40 times booths and performance and 30 times boost in efficiency. And this design methodology has a pinnacle of hardware and software optimization. And how one to the 14th law performance of the sheet for these machine running computations in terms of practical applications for machine learning models. And 40 times boost an image recognition and a 140 constants do natural language processing is seen as well as a have latency for both. This is a huge deal when talking to our virtual assistant. For example, three tenths of a second versus 1 tenth of a second make a vast difference in the experience. Also worth noting, this is just the first iteration of Boulder architecture. The Tesla, the 100 is a data center trust only Bible anesthesia executed because it's quite expensive and arrangers to $70 thousand put its purpose isn't for an average consumer and mainly made for startups and other such competence. Hasn't recently December 2017, the Titans be what's attached to this cart as a first foray into consumer little machine learning with a price tag of $3 thousand as time progresses and district hard selects a V1 100, consumer cards only gets better and cheaper. It's opening up AI for everyone. In terms of general GPU computing, also referred to as GPGPU computing, there are various optimization, both hardware and software being made. Gpu is a built-in memory called urea, which is essentially like dram. New GPU memory architectures are reducing the latency cost of memory AND gates. This is called beach being high bandwidth memory. And like 3D NAND utilized morphs yeast paste, which allows for more memory, can be added to GDP, as well as bringing the memory closer to the processing guy to reduce latency. Also evolving PCIe standards and 4 and five-minute will also assist with data bandwidth and power consumption. If you want to learn more about memory and be sure to watch the previous video in the series if you haven't already, in terms of software optimization and videos, Compute Unified advice architecture, could a platform, it's beginning to grow massively. Co does essentially of parallel computing platform which allows developers to utilize the mass parallelism to GPUs for general purpose. There's also improvement and the graphics and simulation front, Direct X 12th and a Vulcan APIs, these a lot better GPU, multi-threading CPUs, communication and much, much more when it comes to gaming and other simulation and graphically intensive tasks. All in all a GPU, they're just going to have their prime were more adoption and exponentially increase in performance due to major innovations that both hardware and software. And they solve a long ways to scale what general performance expected to continue growing into the 2040. Its performance is currently growing at a rate of ten times every five years. So following that logic, by 2040 will have GPS 100000 times better than today. At this point, the video has come to a conclusion. I'd like. I think the video about 30 viral content is better. I talk a lot about the NVIDIA GPU computing. Yeah, so we'll know the performance and the Annelida we can gain by using GPU, comfortable with the conventional CPU to deal with AI and machine learning application with a comfortable home step, the mammal access influence of applications, right? So yeah, we know the origins of 30 if you're computing and also the reasons why we do the math adoptions today. Yeah, Actually, for the demand from the application, right. Yeah, As mentioned, that the modern GPUs are very efficient at manipulating computer graphics and also the image processing. That's why that why they used for the image classification or the machine learning applications today. So the highly parallel structure in the Gypsy or provided by the GPO can make the GPUs as themselves more efficient. Yeah. Especially compared with the general purpose CPUs, you know, yeah. They have the advantages for the Ag reasons that can process large blocks of that data actually in parallel. Folks them on a personal computer or GPU can be present on love video card, or can be also placed in lead to imbedded in the motherboard. So you are asserting CPUs. They imbedded on CPU die, right? So they have different platforms and GPU, much flexible or taxable for different types of the computing systems was different or all that hardware platform. So as you're in February, we can say that a current-day used a heterogeneous computing system. Yeah. Any cred with the six years in all sorts of GPUs on one single chip board? Yes, there is a GPO, two and also, you know, CPUs and GPUs are responsible for specific operations. Yeah, leg for the computations at the data processing. So they have bad teeth, mammary components. And finally, they can work together to process the instructions or data instruction from the application, right? When they are dedicated for different communities, all the data operations, right? So that is why we can combine the two together to accelerate though computing and also that they are processing in the hybrid or the heterogeneous computing system here. So, yeah, basically a GPU on teacher is similar to the one we previous discussion about the vector architecture, right? Yeah, then work well with that did not have a paradise on problems. And they can support for the scanner against their transverse. And they have the support for the mass flow rate gestures. And also they have lots of files to, on the GPU perform unless if you are a teacher. So the difference is that they didn't not have scatter processor and they use money straight to hide the memory latency for the data access. And they have many functional units, uh, yeah, as opposite of the few deeply pipeline units here. So why they can provide the parallel computing to improve the performance on GPU. For the GPU memory structures, there are different memories that can support, or they are supported by teach you a picture here. So as soon as I am, DNA has a private section of the off-chip the run. They call it the PRI bait memory. So this is the USA to contain the slag phase or the spanning the gestures and the private variables during the operation, right? So each magistrate SIMD process are also has a local memory. Yeah. The local memory is share with them the maze and shared by the US red wasting this block. So the memory shared by all the time, the processor in the GPU memory and the host Can rate and also can write the teacher memory directly. So in this heterogeneous architecture, it is easy to read the data that's stored in the cheeks your memory. So that APHA, that the great feature for the data access and to hide the memory access latency. So yeah, as we can nurse, I'm a front don't shop baby. You thought much about the GPOs from EBITDA, right? Actually that NVIDIA engineers colonised the home use of the shadow programs balance showed the increasing use of computations and that they realized that a is hard to effectively use the, all the processing units or wasting of vector architecture. So they also estimated that as much as two times performance improvement can be realized directly from scatter architecture that can use more than 100 scanner processors. So accion that is combated with one that can use a 32, four component vector processors. So based on the architecture efficiency of the speller, decide. I said the engineering from Nvidia, this starting from the GIT actually invaded move that you are scattered processor based on the design, based on their observation about the present the units became used in the GPU. So GPUs can take advantage of the massive data level parallelism to provide a very high flow point rate. So to be different from the, the transverse vector processors and the SIMD extensions, agenda, a single instruction, multiple thread execution model can provide by GPUs can better support for the Conditional Flow. Yeah, that is a conditional operations during the exclusion, right. So in addition to the DOD actual true that core yeah. Also measured in the short video codec or is the simplest data processor that have the fluid come. That the pipelined arithmetic logic unit, that is, you end up floating point unit. So it can execute a single floating point or the integer instruction per clock. So it has a very simple instruction pipette. Well with performance. And enter, the GPO can use the scanner and again are and also the vector, mask and legs, the operations with shopping, that is that an extension. Some jobs a day. Actually, GPOs are proposed to add processors optimized, especially for the 2D or 3D graphics, right? Including the radio, the ratio computing, and also some display. So it is a highly parallel hide, a multithreaded process or automized for the visual. Computing. The GPOs today can also provide the real-time racial interaction with the legs. Computed. Objects are better graphics images and also that the video. So it serves as both for the programmable graphics processor and also does get about parallel computing platform. So it is also called the heterogeneous system by combining the GPUs and the CPU in this thin system as we've shown before, that GPGPU, right? So, but integrating one or more CPUs, as we showed before, or one or more Jeff Shields in the system today. It is a trained to half-man eco-system designed for the computer. Architectures. Write that dy is the case voice that different computing course was GPU or CPU in the multi-core system design in that trained about biomedical computing system. So did demonstrate more about that here at true by combine the GPU and CPU interested. Yeah, then the heterogeneous system can be generated as shown here. So heterogeneous system lactation or also called an edge as a. So it is the cross vendor stead of the specification that are low for the integration of the CPU and GPU on the same bus. But then with the shared memory to deal with the same task because all different tasks. So the heterogeneous system architecture is being developed by the heterogeneous system oxygen foundations. Yeah, it includes among ministers with the AMD and found the alarm actually the famers, a heterogeneous system with this other arm or it's a big little Accenture or other kind of heterogeneous architecture. So these types of bonds stated aim to reduce the communication latency between the CPUs and GPUs right here, and also the communication between us or Computation devices. And the aim is to make these various devices more compatible from a programmer's perspective, right? Done it the way you make easier for the programmers to take you use this available resources, right? So ready if the programmers of the task of planning and moving data between devices, disjoint and memories, right? So they have currently being done ways to open sale or ratio in the food system introduced by the CEO of the EBITDA, right? So that as Tom tools we can use this resource is including GPU CPU and author their memories by OpenStack or the coup that system. So modern GPUs are very well started to perform the single instruction, multiple data and also single instruction multiple threads architectures. Modern CPUs are still being optimized for branch operations. So that's why she was a partner in the combining of CPR and secure, maybe the touring for the architecture design. So here is also another video to show, but CPUs and GPUs on the new chips, yeah, has, has a lot of the cheers to show their heterogeneity on the computing architecture design. And yeah, I hope you'll then get something away after watching this video to know about the heterogeneous system with CPU and GPU here. Yeah. In 1978 to first year undergraduates, one of the most prestigious universities in Japan, to Tokyo Institute of Technology match in disabled department store, one of the few places where they could play around with microcomputers sharing a common interest in video games. These two students, along with others who met regularly at this department store, started the legendary video game development house, how laboratory a couple of years later, where games like Kirby, the mother's series, Super Smash Brothers were created together at how these two young men created the NES game pin bowl, one of the first releases for the system. They were subtour row, what would later become Nintendo CEO until he is and timely passing in 2015. And the other, Satoshi much Walker, who is today Japan's leading authority in supercomputers, and a man behind one of the first axis scale supercomputers to be deployed in the world. The fugato Qu barring this supercomputer is a revolutionary chip that gives us a glimpse of the future that's to come to computing. The 864 fx is many core CPU, like AMD is apneic or Intel's CEO. But at the same time, it behaves like a GPU. In some workloads matching and VDS most powerful offering fault. Not only is this both the CPU and GPU, it's also considerably more power efficient than any competing products. Da 64 affair exposes a lot of questions for the semiconductor industry. While heterogeneous systems are all the rage and hype around new packaging and things like 3D stacking on, getting all of us excited, da 64 effects features this more traditional monolithic design. While Intel is focusing their efforts into a unified API around x 86 and a Andes pushing open standards within the same instruction set, 164 effects is based on making use of its SV vector extensions. Today we'll look at how this chip operates. Why could challenge Intel, AMD, and NVIDIA in the Cloud and hyperscalers and what it could mean for us PC enthusiasts, just like your water and months work, I kicked off a gaming revolution in the early eighties, Professor Matsuda orcas, a 64 effects might now turn the semiconductor industry on its head. A big thanks to today's sponsor hosting. After struggling for months to get the cortex website working properly, securely and with fast loading times in my previous hosting provider, no choice but to look for an alternative when after publishing an article, the website went down for a whole day because of a flaw in that old hosting service. At around the same time, posting got in touch to sponsor a video and I thought it would be a great opportunity to migrate the cortex website hosting services if I thought they were good or would run the sponsor spot here on the channel. And let me tell you, it's been a night and day compared to the vast majority of hosting services I've used in the past, that performance is phenomenal. The migration from the old provider was super easy that chats, customer support is quick to respond with no tickets. Who any of that nonsense and it works 24. I'm really impressed with hosting and our beekeeping. The ctx dot Tech website hosted that from now on. If you need to host a WordPress website or an e-commerce store, for instance, I highly recommend go to www.hosted.com forward slash cortex and use the code cortex in all caps to get up to 91% of yearly on the web hosting plans link in the description. When I say that the 864 effects these both the CPU and GPU, probably the first thing that comes to your mind is AMD API use, which essentially have a GPU embedded into an SoC da 64 effects. Completely different, doesn't have an embedded GPU. It's just that it's CPU cores can function in a similar fashion as a GPU. Those, but also general-purpose CPU cores sounds confusing. Da 64, if Alex is composed of four, C and Gs will call memory groups. Each of these C and Gs has 13 cause of which 12 are given to the user. Each of these scores in turn, are connected to one another using cross wire. You might be familiar with how interconnected scores in a ring topology on skylight can cascade lake. This is a different type of configuration when it comes to the cause, but the CFGs themselves are in a ring bus, just like Intel's current line up, the hybrid nature of this chip comes in part from this quirky design choice, resulting in massive memory bandwidth from the cause to the L2 cache and further down to the BM, which functions as sort of a mix of L3 cache and system memory. But we'll get to that in a second. So even though this is the CPU, there are many elements inside each core. There are very similar to how GPUs are configured. In total, each a 64 effects and it has 52 cause, 48 of which are active. The remaining being we said for the OS and for redundancy. If you look closely at the chair up, you'll notice that unlike Zen 2, which has a bunch of triplets connected to an IO die in the middle. Yes, 64 a faxes monolithic with four days of hedge VM2 memory adjacent to it, it would be easy to confuse this chip with a GPU like the radio on seven or even NVDA as fault. But again, while those are strictly GPUs, da 64, a ferric sulfate similar is also a general purpose CPU, can run Linux and even Windows. So if you're looking for a super expensive HPC chip, PowerPoint on, well, do it. Of course, the 864 effects was designed with HPC workloads in mind, particularly AI, scientific simulations and data analytics. Usually GPUs are used for these workloads. So because of that data streaming nature, in other words, GPUs can take a ton of data as inputs, compute on that data, and then output a ton of results using the massive memory bandwidth that's typically available to GPUs. The 864 effects was designed with this functionality in mind. So it too is a data streaming monster, much like the DNA and cheering microarchitectures, da 64 Effects is capable of sustained a line CMD loads and has memory aggregation. If this is going over your head, you can check out my video on DNA versus jury, where I discuss how these two architectures working in detail, the massive bandwidth the HB M2 provides along with the SV factor extensions and the ability to work on different types of data like float 16 or float 32 integer makes this chip ideal for HPC workloads. You see in HPC, memory bandwidth has become a bottleneck for performance increases more than anything else. In the last five years, we've seen growing demand for data intensive workloads like where the simulations, geology, enemy, quantum physics, fluid dynamics, pharmaceutical research, and of course, data analytics for things like computer vision and machine learning. These workloads have massive datasets. They have to move around cherubs to be computed on. So they need to be shared between potentially thousands of cause. That's the basic principle behind supercomputers. You connect a great number of cores which work in concert to get massive performance in highly parallel applications. But how does the data move around? It does so using interconnects. So you've probably heard of is infinity February cool, entails email. These are high-speed buses. There are based on PCIe data at super speeds and with low latency. So rates exactly what the doctor ordered for workloads with massive datasets, right? Well, the problem is that to transfer so much data at the speeds, a ton of energy needs to be used. Most of the power consumption in HPC doesn't actually come from computing, but rather from data movement. For this reason, Fujitsu has its own interconnect called tofu, which focuses on energy efficiency while still retaining high speeds and low latency. In fact, it's actually better than Intel and AMD solutions. Nda 64 Effects is capable of, God can chew. And three teraflops. Bandwidth will be 10 times more power efficient than mainstream X86 CPUs like Z owns and APIC, looking more closely at performance into he menos fluid dynamics benchmark a single, a 64 effort scores 346 giga flops versus 85 giga flops. On to top-of-the-line Intel Xeon platinum 8186 CPUs. So a single late 64 if x is four times faster than a dual socket, high-end Z on mushy or eight times faster chip versus Chip, all while consuming less energy in compute bound workloads this year on stone to as badly in comparison. But ask. Da 64 effects in a real-world application like Wolf, popular weather forecast and simulation application, which is more compute intensive, da 64 effects is still three times faster socket versus socket than DAT 180, 60 on. And this is what happens when a process is designed specifically for certain types of tasks versus the general purpose CPUs that Intel and AMD make that can go into consumer products will HBCU cloud and enterprise environments. In other words, da 64 effects is a domain specific processor, its domain be HPC, of course, could this be the future of computing? We'll come back to that in a minute. If we take a look at the rack unit that's going into the forgotten who nodes receive few curious things. The first thing that will stand out to you is the fact that a dual socket bodies water cooled, it looks kick-ass to it has sort of steam punk vibe. Water cooling in HPC makes a lot of sense, not just for the performance and cooling benefits, but also for scalability. But another thing sticks out like a sore thumb or rather it's special because of its mission. Can you spot what's missing in this sport? That's right. There is no RAM, unlike traditional service systems, da 64 effects doesn't use RAM. The system memory is on chairs. It's those hedge PM, two days we saw earlier. This is really interesting, is integrating memory on-chip is going to be a trend that we will see carried over to consumer products in the coming months and years. So it's possible that as we get absurd amounts of on-chip memory, RAM might no longer be needed being replaced by H BM Who next-generation memories, which will greatly benefit from being closer to the logic cause when it comes to bandwidth and latency. So while RAM currently offers this capacity is a massive bottleneck when it comes to bandwidth and latency. If HBS commoditizes, like all the other memory types did eventually, DA 60 shows what can be achieved with large amounts of on-chip memory. We get to bandwidth, low latency, and capacity. So the 864 effects doesn't use system memory. So what, what's so special about beyond saving on costs while it comes down again to scalability because parallelization is being brought to training, AI workloads are now requiring massive scalability. And the fact that the 864 a fancy, so tightly integrated and makes it a lot easier to scale as needed. If you have an X86 system with Intel or AMD CPUs and NVDA voltages and RAM. Whenever you have to add more nodes, you will have to add more of all of these components with the 864. If everything is inside one CPU functionality, the GPU functionality. Know why they use the same, weren't there for the application form for computations. So in the rumen of this short video, there were shorter the parlor design. There are cultures where Sichuan Gypsy or even the memory and how they have the better performance. So if you are interested in what's minutes here, right? This slide here, so we can continue to show them what good use here. So actually, in addition to go on, heterogeneous system was CPU and GPU, right? Yeah, As we're introduced to also, NVIDIA has bringing the world's most advanced data center that the GP or in around 2017. Yeah, It is a quote, The Nvidia Tesla, they were hung with him. So always the continuous development when the NBA by NVIDIA, actually this very Nvidia Tesla, they were hung. It has been proposed for the AI computer warned that that stage and also for the HP is a powerhouse. So actually that even yachtsmen CG that may well on the accelerator is clamped at the highest performance, was 10 performers are parallel processor. Where's the highest performers? And an anion was defined two powers the most compared to its normal influence. Enrich, say that I authored the legs are graphics workloads. Yeah. And it was stage but offer this this years. They have some developments and also what Sarah's off by generations from Nvidia. So guess what that evening. Yeah. By the way, one can get GPR write Ada houses. They can either when new hardware innovations that can provide tremendous speed up for the, especially for the deep-learning Amazon generals of the frameworks. Yeah, In addition, they can provide a far more computational hardware for the horsepower and cheer for the HSA is this term Jana, all sorts of applications. So Seminar 2, that friendless generations like Sir pasco, G0, G1, good to cheer, but you may walk on the resolution in the previous slides from EBITDA. It is composed of multiple graphics processing. Plasters were caught the teaching space and texture processing pastors who are teaching save files and also from streaming much processors lesson plans, and also with the memory controller seeing their comparative measure. So a cheerful at their product go about that. Tesla, they weren't born yet. There are some k computing features why they have so high performers and author of native here so that you have, let me welcome. You actually had they have new streaming much processor. Now just as our culture, right? Especially optimizer for about deep learning. So what are the major features? A major new radius that the legs are screaming multiprocessor that is at the center of the GPU. And the new loan at them as like 50 percent more energy efficient. But the progress generation Post-war the SLI and enabled the major boost in the floating point is 32 and also blimp on 64. Yeah, Hang, give the performance is a thin power envelope. Get that extended. The generation of the videos high-speed interconnect and delivers a higher batteries in the mornings was improve the scalability for the multiple GPU and multiple GPU and the CPU system configurations tomb. And also may have the HB M2 memory that will be faster in a higher efficiency and vote and has a high need, 10, 16 gigabytes. Memory subsystem cantilever, more peak mammary batteries. And also they have some thoughts on multi-process service. Madison Museum of the GV. We'll get our teacher by media and to provide the hardware acceleration. Especially for the critical components on the true That MPS survey and eight enable that improve the performance. And also the isolation between these components in a better quality of service for multiple computation application shared bytes, so GPUs, so they have, well so that e has a unified memory and the address translation surface. So that NVIDIA GPU memory technology has been used, including new axis counters to the more accurate memory pages to the persons or that axis the pages, the data's more fragments. And also more efficient. Memory access for the between the ranges are shared between based processors view the cooperate groups and the new cooperative launch APIs in that TV on Hungarian as the new program model that introduced by true that system. Yeah, it is used to organize the roots of communicating stress and the cooperative groups. Although the development you express the granularity add this completed annotations does read, multiple threats can be communicated. None will have Sam to express the reader and more efficient parallel executions, Right? So the addition that also have the maximum performance and also as a maximum efficiency promote In the maximum performance mode and test our bot hauling it. Actually the accelerator well operated that we can say that unplanned spring up to its thermal design power as we mention that the similar design part, right? So, yeah, in order to accelerate the applications that can repair the fact is the computational speed, together with the high is the data throughput. So when the final law and that, that, that the development from a Vaidya also hamster of all to optimize their software. Yeah, with the stuff we're approach is based on their hardware architecture design. Actually a new versions of the deep learning frameworks such as the coffee to MXNet, TensorFlow and authors humps the performance of the border of the two Geneva, the genre table, faster training times, and also you can get a higher multipole tuning performance. So combine arrays, the hardware deciphered by a baby or to give a wound and also the software tools to optimize the performance and also other credit hours, or are we doing? I love the upgrade is to further explore the data level parallelism, right? So that should be done by hardware design. Also, Tibet avoids the software already then. That's what our nation that we need to do that yet. But comparing the first variation of the SIMD architecture, the vector processor, there's always a certain law by the GPUs. Actually we have the following observations. Or basically we can say that the GPUs, yeah, they add the vector processors and the risers I think that you'd use in terms of the rays and the blogs and on rats, it is best to think of them as a vector processors. Yeah, vector processors, IgG that our designer run the single instruction, multiple data, SIMD instructions, right? And the typical desktop CPUs contain the SIMD execution such as the processor from Intel. Yeah, there are no them to perform thumb or vector processor or some vector operations efficient and about their focus is still on law, no latency execution of the scholar code. In contrast, a vector processor expect most of the computing issues can be expressed in terms of the vector operations, right? And they are optimized to perform this operations as quickly as possible, right? So perhaps some EVA and the expense of the scholar performers, but they can't get the operating performance better. So under this model, it's just me. And like the EBT as GPU, right? They correspond to more traditional cyclical in the heterogeneous system as we're shown. So this and mode, they contain some number of the legs, the asserted your y vector registers. Now that it's been explored, the operations on the vector we just are at the rub. So they appear to be 32 threads because each instruction during the operation, they are on those 32 lays and ones, right? So where others read muster per said clubs Deb, Because you know, they are actually in a single stream of their instruction, right? Because basically they are a single instruction, multiple data stream architecture. So well, That's the best defense seizures actual vector have the US dollar unit. And a GPO is designed to handle a large number of the thread. In each SIMD with a GPU has a larger along both the gestures that, you know, again, amygdala assigned by the thread scheduler. So in addition, I assume I know all of the load operations and also the store operations have on the GPU, they are separated across a net's, right where they are not. I am back to persons or add data. We're showing me for a vector processor, right? Besides that, you need to know that GPU occured. They rely on a dress coalition. You need to merge node in the store operations together. So benefited from this, fishers about the GPUs come bear with the vector processor. And also SIMD extensions actually has better performance due to the hardware design. All there was shown that the software tools to manage the operations dynamically, right, together with their hardware design. So nasa aka benefit, we can get wisdom, GPU combated with that. So specifically we can say the component on that magical with SIMD and also the GPUs here. Gpus have a larger number of the SIMD processors here. And also more layers, more processors. They are different, right? So this more computation units into your cast support by the hardware integrated GPU platform. Yeah, actually, it is better for the MD spreads. Hi everyone though. The largest size and also the total memory size, like ten times to a 100 times smaller in GPU compared with batting the Matkal always SIMD. So that is the benefit to find the GPOs to. So we need to know about cache coherence. Actually it is own enabled in some of the G20 system because they have the more complexity in both GPU to manage their memory and cache coherency. So it might be much complexity in the GPU platform compared with the traditional a vector processor or the ASM be architectures here. So that's awesome. Cooperations between the vector processor and SIMD ISAs was the GPUs due to their design and yet the computation memory at the Software Management. So again, now we have shown the three variations of the SIMD yeah, there that the hardware design in their software to use, to optimize all to further deployed the data level parallelism. And now also we show you that existing over the previous product from the industry, especially for the legs, the punctually used to computing like teachers from NVIDIA, AMD and also ought to deal with applications today. And they have different features for different applications and different performance too. So this add the base, you're calm contents bought them, computing our teachers. So in the next class we will continue to show you some programming on these architectures and on the popular or the why they use computing architectures. And how this, there will be challenges an existing partners when we're using these architectures. And I will show you then in the next class here. So yeah, we can stop here in this class. And thank you so much for coming. And any questions you can stage your asked me, if not fair, for tuning in. Thank you. Everyone. Take care.