 Hello class today. Oh, it's so good to see you everyone and good afternoon. This is the course, I'll say if I were a computer occasionally and the University of New Mexico. So predators class last Wednesday. Yeah. We discussed based on the basic components of a computer architecture design. In the previous class, we have to talk about the customized to all the emerging at pitching it also the architecture design. So we have these got the four types of the basic computing, our pictures including the traditional one CPU and also GPU FPGA as well, the A6. And we have the overview of the lodge integration Rob, CPU, gpu, FPGA, and also ethics. So an addition that according to know the details of the futures and also the performance between the CPU, gpu, FPGA, and ethics. We have the comparison between them in after we compare the aspects in the design of this or basic computing architectures, actually we ha, we can't see the, both the advantages and disadvantages of this types of computing our components. Yeah, Actually, according to the computing demands, overpowered moments from the applications to so for instance, among this more tides, the most traditional one CPU, yeah, CPUs have the highest computing adapter been a. So we can quote that this somehow the general-purpose computing architecture, right? So, well, CPUs have nodes to put in pyridine is the more we trying to optimize or to do some optimization here. So from the CPU to the GPU and FPGA until the Isaac's. Yeah, there will be a higher parallel lines meet at a higher throughput that we can achieve the higher power efficiency. So A6, I can sign up for a specific application to achieve the higher performance, the higher energy efficiency. And also A6 that benefits from their design cost and also the complexity. So that's why basics are widely used nowadays and also with the technology development. As rise, you know, the increase in emerging applications nowadays actually lemme all the artificial intelligence accelerating pad phones today. Yeah, the applications of basically computing architecture design as better eye for the AI. Yeah. Composed of the processing elements that we'll call it p 0s. In this B is multiple Ps that are multiple processing elements are connected in different topologies. Actually, that is one part of that. These are bought the basic architecture. So these, these dyes, including the processing elements and also the connection topology of the A6 exit. They can provide that in comparable energy efficient, the lowest literacy and also other form factors that makes the A6 or why do the steps are for that? It applications, all the mercenary applications for the accelerating. So in addition to that as the reported from the top take off, that is the figure shown here. Yeah. A6 are becoming much more popular for the I get a spectrum of what the implementation of the AI applications, yeah, then the tree wants FPGA GPU weren't the CPU. So we can also obverse of VS to them A6 after this, Isaac's work dominate the market. Yeah, as predicted in the Fugger, right? So this is a quote that has the nature or the voltages in the algae efficiency, lower latency, and also areas. That means the cost of what the computing architecture design by Isaac. So this is the general comparision between this four basic computing architectures, CPU, gpu, FPGA, and ethics in how ethics are the more popular nowadays for the emerging applications, it better for the fusion at the accelerating platform designed for day. So. One of the twin about the future of computing, as we discussed last class, that is the heterogeneous architecture. Yeah, Unless can of heterogeneous architectures actually more than one type. Now Miss, can of the computing components can be integrated in the same computing architecture. You can include the tubules, GPUs, DSPs, FPGAs is even the A6. So types of these components can be integrated in the sim computing architecture to generate the heterogeneous architecture. Yeah, Actually according to the derives from the application, right? So this short video is here to show the future of computing. Yeah, yeah, especially visible on the heterogeneous architecture. About the CPU, gpu, FPGA, say Gerasa types here, CSV. This video is a sudden been a multi-part series discussing computing and the final discussing classical computing. In this video, we'll be discussing about heterogeneous system architecture is, and how it's going to shape the future of classical computer. To summarize what we discussed in previous videos, CPUs are general purpose devices designed to execute and manage complex instructions, while GPUs are massively parallel, devices designed to execute streams of calculations as fast as possible due to their parallelism, this translates to current architecture with the CPU managing most of computer operation, such as the operating system, input-output devices, and various other tasks on the GPU does a hard-hitting in terms of computation. For the longest time we were making the CPU execute and manage all the tasks, leaving the GPU only for graphics and simulation purposes. This was and still is extremely wasteful in terms of computation. The CPU already has to deal with OS overhead and one with various other issues. I don't know, penalty on performance with plateaued CPU clock rates, the miniaturisation of the transistor coming to an end. More cores on the CPU not having significant boost in performance, as well as thanks to the increasing adoption of GPUs in general computing and increasing a parallel platforms like cuda, this is beginning to change. This yields a new type of computing architecture called HSA, heterogeneous system architecture. Hsa is where multiple compute devices work in unison instead of being sediment in operation. Another huge factor in HSA paradigms taking off as a view and improving memory and data standards. For more information on the CPU GPU and new innovations and memory and data to gain deeper insight into what I've discussed here, be sure to check out the previous videos in this computing series. Now what we haven't discussed in those previous videos as FPGAs and P6 to other types of computing devices that will play a crucial role in Utah, say, the Field Programmable Gate Array. Fpga is a special type of computing device. Unlike other computing, it's hardware can be reprogrammed for specific tasks. To be more clear, other computing devices have fixed hardware and software optimized to run on FPGAs and reprogram hardware. So hardware can be optimized. Results were due to this hardware reprogram ability. Fpgas are more expensive and also quite difficult for the average developer or computer enthusiasts to work with Harvard. They allow for massive parallelism and uses much less power, which fits perfectly for a variety of needs such as data processing, we're streaming, for example, referring back to a heterogeneous architectures, FPGAs can be used as accelerators to process data and then send it to the CPU. And when paired in a system with CPUs and GPUs, massive improvements can be seen. Now we already have industry-leading capabilities with our Azure GPU offering, which is fantastic for building trained AI models offline. Okay, but to support live AI services with very low response times at large scale with great efficiency better than CPUs. We've made a major investment in FPGAs. Now FPGAs are programmable hardware. What that means is that you get the efficiency of hardware, but you also get flexibility because you can change their functionality on the fly. And this new architecture that we've built effectively embeds an FPGA based AI supercomputer into our global hyperscale cloud. We get awesome speed, scale and efficiency. It will change what's possible for AI. Now over the past two years, quietly, we've deployed across our global hyperscale data centers. It 15 countries spanning five continents. Okay, so let's start with a visual demo of what happens when you add is FPGA technology. One of our Cloud servers were using a special type of neural network called a convolutional neural net to recognize the contents of a collection of images. On the left of the screen. What you see is how fast we can classify a set of images using a powerful cloud-based server running on CPUs. On the right, you see what happens when we add a single. 30 watt Microsoft designed FPGA boards to the server. This single board turbo charges the server, allowing it to recognize the images significantly faster. It gives the server a huge boost for AI tasks. Okay, now let's try something a little harder using a more sophisticated neural network to translate languages. A deep neural network based approach we're using here is computationally much harder. It requires much more compute. But if achieving Record setting accuracy and language translation. Okay, so to test the system, let's see how quickly we can translate a book from one language to another. Now I picked a nice small book for this demo or in teeth. It's about 4040 pages. And we'll go over to the monitor here. And using 24 high-end CPU course. We will start translating the book from Russian to English. Okay, now we'll throw for boards from our FPGA based supercomputer at the same problem, which uses a fifth less total power. As you can see. Thank you. As it targets a single FPGA accelerator incorporated an HSA system can yield significant boost in performance for artificial intelligence tests. And similar performance boost extend to other compute tasks as well. Beyond FPGAs, there's also A6 application-specific integrated circuits, the most optimized type of computing device, a six, are fixed and hardware power as the name states, it is application specific, meaning both the hardware and software designed from the ground up to be tightly coupled and optimized to go specific subset of costs, but do them extremely well. For example, a six that's, you know, a lot of use in cryptocurrency miner will discuss various types of A6 in future videos on this channel, such as on the Internet of Things and other computing applications. For example, Tensor Processing Units, TPUs for use in AI and in videos, dr. Dx card for use in self-driving cars. As a side note, A6. Other reason, Apple phones and laptops are so fast and fluid. All hardware specifically designed for their devices as well as software that I can fully utilize all the hardware resources. The problem with ASX is out there significantly more expensive in terms of research and development and implementation. This is why most companies and people up for generic ship such hover with the increasing complexity of problems, computers most salt and the coming end of the miniaturisation of the transistor will see exponentially increasing this in the coming years. So based off what we've discussed to a heterogeneous architectures to see people manage computation resources. Fpgas will accelerate data processing and GPUs or A6, we'll crank up the calculations necessary in terms of the computational performance. This yields, it all comes back to what we've talked about over and over again in the previous videos in this series, increased parallelism. Now when discussing parallelism and heterogeneous architectures, there's another law witness looked up the Stefan's law. This law essentially stapes soured, increasing data size and performance booster came through parallelization. In other words, the additional more cores and other hardware and software parallelism increases because parallel work increases with data size. Simply put, until we run into power issues, we can keep adding workhorse. And as long as the problems we give them are sufficiently complex, the course will be useful in terms of heterogeneous architecture. This means it's going to keep adding more compute devices. Now luckily, it seems a world has found such a problem. Deep learning for use an artificial intelligence, a field of computer science that has now gone means treatment is increasing in popularity more and more every day, deep learning algorithms utilize and large amounts of big data intrinsically parallel, well explored this much deeper in this channel AI series, deep learning also acts as a positive feedback loop and can propel the field of computing much further. We can see this in technology such as AI, smart caching, and going beyond that, deep learning can help us identify ways to maximize heterogeneous architectures to develop new A6, and much more to push competing performance for. So what heterogeneous architectures as well as increase in parallels times that utilize big data such as deep learning. We'll see massive increases in performance over the years while exceeding the expectations of Moore's Law. If we look at Moore's Law in terms of heterogeneous architectures, we're still a long way to scale, possibly another 75 plus years of performance increases. To add to this, who knows what other types of architecture and software changes are to come during this inflection period in the field of computing. Now before concluding this video to highlight this shift in the computing industry to heterogeneous architectures. Washington's clip of Principal Researcher at Microsoft, Catherine McKinnon. So now what we're seeing is specialization and hardware. Fpgas are specialized processors are combining big and little processors together, I think, powerful bass processor with that very energy-efficient processor. So software has had an abstraction that all hardware is about the same and one thread of execution. So in order to make software or two different versions of crazy hardware or different generations apart. Her, as we go through this disruptive period, the software systems are not prepared for this. And so my research is targeting both how you do that as a software system, but also programming abstractions that like to trade off quality for energy efficiency. Let you reason about. Fact that sensor day that is not correct. And how do you deal with these inaccuracies in programming model that you don't need a PhD in statistics or computer science in order to, you know, as you can see, this big data system has combined CPU, gpu, FPGA. Isaac's benefited from their futures in or Invalides. That's them. Some, sometimes I'll save USA. I used both the control and the management team, the clincher and FPGAs asics, what the real computation, especially for data intensive computation today, to accelerate the computation in the system. So, yeah, as the CEO in the video, that you have the heterogeneous architectures with these types of computing components. Agenda stuff and this stuff to work. Masters could be accommodated until this hall worse to work to Benzer to boost the performance of the architectural D. That's why that is the training for the software and how to work co-design for the advanced computer architecture for day. So back to our lecture about the heterogeneous architecture. Yeah, as we said that the more and more computing course is processors has been integrated into the computing architecture. Actually, there will be the heterogeneous multiple platform with multiple computing elements or the processing elements here. So yeah, this heterogeneous architectures, in addition to the pure desire out the only the CPUs, GPUs or FPGA or the ethics at you. They say it's another way for the computing like security side. So yeah, so the heterogeneous, heterogeneous multiple platforms, we need to know what is the heterogeneous computing fors. So heterogeneous computing refers to a system. And this distance can use more than one can of processor cores, as we've shown that CPU gpu, FPGA. So this distance can gain the performance, all the energy efficiency in not just by ending the same type of the processors achieved by adding this this Daimler co-processors. You ever did, they incorporate the specialized or processing comorbidity legs, the Apigee and A6 right into the traditional CPUs in order to handle that particular tasks from the applications. So the heterogeneity in the context of the computing IRR. And it refers to a different instruction set architecture. Not here bother you, but the heterogeneous refer to the different instruction set architecture. In this kind of heterogeneity actuate the main processor has one instruction set architecture. In other processors have another instruction set architecture. And this is very different. So there are other types of heterogeneity to ask were taught that they, they can deal with the same instruction set architecture. So for example, as objects are showing here that the product will call the big later OK feature. These days, the one exception where the, you know, the instruction set architecture of this course is on this architecture are the same. And the heterogeneity in the big picture refers to the speed of different microarchitectures of the same instruction set architecture. So this can make it more like a symmetric multiprocessor. So the big outage or heterogeneous computing architecture. And it is a, it was developed by a couple of relatively a better CV and best lower power course we called the later architecture, as well as the relatively more powerful animal power hungry whilst we caught the big covers here. So typically only one side num is either coarse or the big course. The one side of this course or the other will be active. And her once said about the course will have to the same memory radians on this picture. So the workload, the hymn, can be swept up between the course and the course on the fly. So the interns off this architecture design is to create a multi-core processor. And this processor, oh, this, this computing platform can just better to dynamic computing meets. And they can use the low, lower, or less power than the scale. Yeah. Oh no. So that is the two. No to send next or the processor according to the jaw Diamond, according to the computing the math from the task to minimize the power consumption is there to show the later ones if the performance can be say is five. Otherwise, be a course where I'll be active to do the computation. So marketing material process at that up to 75% savings in the power usage or some activities according to the big data architecture. So Mosley, Chrome, the, you know, the big picture actually, they argued that to create a multiprocessor system, system on chip. This is representative of the multiprocessor system on chip, as you will know as the MPS Hosted Apps picture. So yeah, vision. And that's our kin off the heterogeneous platform could be the IBM Silk Road bad anion. That is a BE architecture. This is done. There's a type of heterogeneous architecture design. This oxygen is the power architecture. It is based on the microprocessor keep whatever for the high workload and media will go based computing. So thus their crosses are, in this architecture was designed by SDI that is popular among stony and IBM. Yeah, they collaborate to create this picture. So although IBM has the main part of this architecture, so this is the boot was massive floating point operation, a mat and as the original process are worth develop a way. So how architecture core surround that with the eight synergistic processors here also, does the processor has grown computing potential? Yeah, it is a widely regarded as the challenging program, a beverage because it is much more complex. So the cell broadband engine architecture here by IBM, Design for distributed processing of data will weigh in order to facilitate a family of processors with a range of the available cores and memory configurations. So there's a teacher or no self-image or dress, different domains where they can use the same basic hardware design. So there's, our teacher does still a E system has one or more PowerPC program elements were called PPE here. This can handle the system management and one or more synergistic power elements that we'll call it the SP here. They can perform that data. Happy. Now is the habit data computation and the parallel computation here. And also this teacher. This system also has internal interrupt controller and IE, IC. And they ha, one element, interconnect bus, EIB, the KM, a connection between this course and the components in this architecture in order to connect all the units wheezing the processor here. So that is the basic design of this architecture at the shore here. So generally, a heterogeneous computing system refers to a system that this system contains different types of computational units of bugs them what the medical, including the CPUs, GPUs, DSPs, FPGA is also the A6. So setting the example shown in this size, the hybrid architecture easier with the CPU, with a CPU and FPGA, CPU and GPU or more here. Yeah, although the snail processor has strong computing potential here is widely regarded as the Chinese program embarrassment. Words are heterogeneous or different types of processing elements. So the computational units in the heterogeneous system typically includes a general-purpose processor. That means that, that the legs are CPU that can run the operating system, as we said in the video that the CPU can use or to the, for the management of this, we're substituting bus system. So that is one part of the general-purpose crystals are that it can run the operating system. So in the past, actually, the heterogeneous computing may different instruction set architecture as I mentioned before. So this cat, you'll be handled differently with different instruction set architecture. Well, a motor example now we are using the heterogeneous system architecture actuated the systems and many of the day. Especially for the users and they use the multiple processor types, typically CPUs, GPUs, you on those same integrators. So q, in order to provide the best of both worlds, right? The general GPU processing at web. It can also performed mathematically intensive computation. Very large data set. Well, this teacher have, have the, both CPUs and GPUs can run the operating system and perform traditional Sarah task. So that the common way for the molten heterogeneous I picture. So in the heterogeneous architecture or the heterogeneous computing systems, the level of the heterogeneity in the modern computing system. This level of the heterogeneity as gradually increasing as furthest down of the who, the fabrication technologies allows for the formulae describe the components to become a greater part of the system on chip. Or we can call it done. So say our medical system on-chip MP SLC, as we mentioned before example. But this time of the, the, the, the, the systems to integrate components to become an integrated part on the same chip. That means our system on chip. Or for example, there are many new processors now include Bill enlarge or the interfacing with other devices, lags, the PCI as Ahmed, USB or assertion or the memory controller. So also, as well as the programmable functional unity and or hardware accelerators like GPUs, programmable network processors. They are also integrated in the same architecture on those system on chip to finalize, auto-generate a heterogeneous computing system. So as we talked before, the general purpose computer or the computing system has remained that thumbing computing future for the last 50 years. The type four types of the basic computing system and also the heterogeneous system. So it is a Java by largely by the readily spatial off the Moore's law for the architectural design or development. So, and this showed the science. However, it has become increasingly more challenge in order to achieve the performance gains from the general lives to hardware. Yeah, Eva you instead the stage for the resurgence in specialized architecture. So today's specialised, in addition to the Application Specific, Integrated, the so-called ethics we talked before, actually, work has a special or specific application that the base focus on. So they can offer the limited flexibility, especially for the A6. You know, they are not configurable. And they are conceptual design, fabricate and program, right? But this can of architectures where my ship. So another type of computing NA Code, that domain specific computing program at things to prove, prove that there need not be continuous tradeoff between the efficiency. This efficiency lags that burning the A6 and the flexibility and the hallmark of the general purpose processors. This is a customized specific. Now according to the computations, this is the kind of processing that involved a gaping application domain for high performance and the power efficient in the realization actually what the computations for the particular application domain. Or they can both the Chinese and the application domain. So let go of the dummies, both of the computing at your goal is to develop the domain. The best effect computing system, not only for the application specific form. This is the heterogeneous multi-core system. This system comprised of many cores that makes general-purpose processors measure rubbers, processor's, hardware accelerators, memory, input, output devices as what the programmer interconnections in our cheer significantly improve the performance of the application wasting this domain. So the domain actually the dummy as larger than any one application. Yeah, especially compared with application-specific integrated approach, the ethics designer for the specific application. I'm sure that the main as larger than that of the one specific application where you know, than one processor can effectively address a problem more efficiently compared or than the general-purpose processor. But they always thought a change about the time that the cost of building AS best ever purpose system, like the AC, domain specific computing system. Yeah, this system Pauling, the architecture, that this architecture can improve the efficiency of the computing through a specialized processing. Well, they can maintain the programmer vanity. So this is the dummy specific computing. This. This can AV system contents larger than the asap wants to solve some challenges in the design of the acid our teachers. So originally the dummy specific computing. I was motivated by the situation that you're not. The issue though might have, hi, I'm computing demand in one or a few, select the application domains. And the customizable computing system for they are for that particular application domain, right? For the performance or the power efficiency. So the objective of the domain-specific computing, actually, it is to make the best use of the techniques that these techniques include the A6 and PGA computing component. So the dummy specify. Computing can make the best use of this available techniques for the power performance efficiency was lower. So Kiana occur general computing. Actually I think I didn't need like the email, the application select the email. Word processing, web room, same. This can be easily achieved by any existing computing technology, right? Even for the CPU. So when the dummy specific computing system can be used for some CAN of the emerging applications, such into the house care application at the graphics for the M developer, the simulation for the incubator. So co-design houses all the financial analysis. Well, an investment banks, they can use to transform fear for the same law for the image recognition and a boy, video processing. Even. So, they are more performance and efficiency since they are designer for the domain of the applications. Yes, somehow likes to application-specific thought. They can deal with larger part of its applications in the same domain. So they use certain day or so. So basically the example shown here to show that dummy computing. So the dummy specific computing architecture or the system have to customize the reconfigurable boss and also the interconnections here. Yeah, this is the main difference compared with the A6 because this is somehow like the FPGA, that reconfigurable part about the bars design the interconnection here. So this will Confederate part, including the bars and the interconnections in the dummy specific computing actually can enable the low latency, high bandwidth interconnects for the data sharing between this course in grid computing system and the interconnection between the course now co-processors. The configuration between the cash backs, the memory banks. In order to make the communication requirements all of the particular application or a domain of the applications, or even different phases of the same application. So they are more fine-grained for their applications to for the bush or the performance and the energy efficient. Here. This is one example about the specific computing architecture design here with the customizable reconfigurable bars in the interconnects here. So furthermore, the dummy specific computing system. Yet they are characterized by actually three types of the components. Yeah, again, use this example. Here. They have the types of components including the fixed, of course is what the computation. Now, customizable courses. Yeah, and also the programmable fabrics at these are the basic types of the components here in each of them has different level of customization about recompile, configurability and also the parallelism. So a folk, some of the catherine, My thought course, they have a higher customer. The customer, the vision for the different, for the finite difference between the stormy off fabrication of students for their demands. And also the reconfigurability and also the parallelism in this programmable February case. So yeah, Generally the customizable heterogeneous have football from a specific computing system, has the fixed number of the processing course ads were shown layer and the course is on this computing system. They different why did, in terms of the energy efficiency and different, why did in the performance and also the error. That means the design cost, right? So they have very limited reconfigurability. Some of them even do not have the recoverable morbidity as we showed before, this, the fixed part and the during the processing. They'll customize the course can know the voltage or the frequency scaling to depth of the power, demands all the performance, the net. And also they can offer a stead of the tunable options are, for example, the register file size is the size. This is though the whites of their data pass upgrading, pregnancy and the supply voltages, they can have, the dynamic change for this part of the leg, the options that you can choose according to your demands. So actually according to the needs for those specific application, right? The program February's the SAR part in the domain specific computing. Here. The program above February's, they enabled by the dummy specific computing. And they can provide the maximum flexibility here. They can implement the custom instructions. Actually buys visualize the co-processors. Nexo, a theaters, FTD. Do say the operation. Yeah, In order to accelerate the performance. So besides that, though, I picture a customized in terms of the number of the computing units and also the types of the computing units, number of the peptide status. So they are better to implement the context operations according to the programmable fabrics enabled in that specific computer. You have teachers here. As a summary in this lecture. Yeah, based on the introduction about the current basic computing, actually buy from the the instructions in our teacher, the memory and also the hardware to the software interfaces. Yeah, after that, we have not trained of the costume and emerging computing architecture. These are in this lecture. Yeah, they can be divided into three main categories here, including the programmable processors that dedicated processors and the heterogeneous multiple systems visit favorited the general purpose processors and thus visualize the programmable processors have been disgusting. We have discusses them in comparing with their reconfigurable processors. For example, the FPGA, as a dummy specific computing system that pyrogen we're configurable, right? And also the fixed one about the application-specific in births occurred. I check that domain specific converting also has a long Pardo bought the fixed cost. I ain't there are computing system. So after we introduce the four basic computing architecture, ask whether there are fissures. Yeah, these are the other voltages for the computing. In order to achieve the performance and power efficiency, the design costs. Right? After that, uh, we introduced the heights of the twig in the computing lab, t-shirt design, that is the heterogeneous computing of visual design. So we have shown the typical producer or the pictures here, including the big ladle teacher and also the IBM cell broadband engine. Yeah, This Joanne teachers. Both types of the heterogeneous monopole systems. They add these died. And they can provide the performance power efficiency. According to their different types of architectures with different performance, different power in their architecture. Even they benefit from the, the topology of this architecture. It's all of the courses. Actually they manage it together, raise the software like the controller or the management to boost performance or to further explore the paradigm zone on this course. So among this can of the computing systems, yeah, you should know how to choose the suitable one or from this architecture design in order to satisfy the performance and as the implementation plan for the specific application you are facing. So definitely based on this architecture D size, we need to compare with the features of this distance. And we also need to consider the system cost, the computing speed, the power consumption, and also the design reuse. Yeah, this is commonly referred as the one design objective about the reuse. Although dogs I reduce or yeah, that is related to it that you find cost to write as when the tab to the mafia, that means how long it will be ready. And it is also about the design cost. So that is cost, the time to market before the implementation. So they have to add the considerations. One way to choose at which time of this architecture you need for the implementation, Hadoop phones for your specific application. So you will consider all of them or you have multiple choices here. After we know the train odd the cluster by the company are teachers or the addition to that. Actually, there is another feature tree out the computing. And our teachers, I truly caught the ubiquitous computing. So this short video will introduce some about that. And we are related to some about another type of computing, about the IBM who all that quantum computing. But this is mainly about ubiquitous computing here. On the shoe. Hi, thanks for tuning into Singularity Prosperity. This video is a 12th and final and a multi-part series discussing computing. In this video, we'll be discussing the future of computing, more specifically, the evolution of the field of computing and extrapolating forward based on topics we discussed so far in this series. There have been three primary areas and the evolution of the field of computing since its inception from his earliest 3000 BC extending to the 940 does a tabulating era. This era of computing was focused on simple calculations and data collection encompassing many technologies. To list a few of the advocates, the Pascaline and mechanical calculator, that difference engine and the census tabulated from the premise of storing and manipulating data came about the second era of computing the programming error, beginning in the 1950s from the inventions and theories and many great minds. This sterile lab for complex construction carried out by computers by creating a language for them that could be represented with physical hardware, machine language, in other words, binary. As time progressed and as is the case now, layers of abstraction allowed programming and higher level, more human friendly languages, which are then compiled down to machine language. We're still very much in this era of computing. However, since 2010, the field of computing has been going through and other disruptive period, a transition to the third era of computing a cognitive error, allowing machines to execute based on learning from large amounts of data instead of executing pre-programmed instructions. As a field of computing has been evolving towards the Cognitive Era. Another paradigm shift in computing is accelerating the transition. Infinite computing. Before continuing, competing encompasses many of the topics we've discussed in previous videos in this series. Be sure to check them out if you want more detailed information on certain topics. Back on topic. Infinite computing refers to the use of cloud computing. Computing as a utility power by the principles of heterogeneous architecture. The Cloud is currently powered through a combination of CPUs, GPUs, FPGAs, A6, and memory devices, each of which play a pivotal role. These devices had been, and it will continually increase in performance and efficiency due to shrinking transistors, new materials, 3D integrated circuits, human memory devices and standards, as well as other optimizations in software that are made to be tightly coupled with hardware. Beyond these classical computer technologies. New fields of imputing able to truly operate in parallel, will also be utilized and are slowly starting to be used in the Cloud as well. One, optical computing, which will provide significant speed-ups and data transfer, as well as compute devices to quantum computing, which will be able to solve new types of problems and reduce the probability space an optimization problems. Three clock less parallel neuromorphic architectures which are based on the human brain and will provide significant performance and efficiency gains and artificial intelligence applications. Under heterogeneous architecture, all of these devices, architectures, and Paradigms we'll work together on the Cloud based on the needs of the end-user, provide maximum performance and efficiency for our desired task. Hence, the given name of this paradigm. Infinite computing. Infinite computing will be an additional tool for computer enthusiasts, scientists, et cetera, and an alternative computing method for the majority of the world's population. For some examples, let's look at some resources that may be allocated a certain types of individuals or groups, ranging from light usage to business or startup. As you can see, the future of computing it will be truly personal and optimize for your specific needs. It is worth mentioning that this paradigm of computing a centralized and trades off accessibility for potential privacy and security concerns, a decentralized cloud-based on blockchain principles could change this. However, this is a topic for a future video beyond the impact of groups or individually users, the principle of infinite computing also applies to our devices called Edge devices. For example, referring back to the last era of computing, cognitive computing, this means pairing AIA steps in devices. What the Cloud high personally envision this occurring is implement and quantum computing practices to reduce the probability space of the numerous potential machine learning models the problem may require. And then neuromorphic architectures paired with classical von Neumann architectures, we'll train and infer based on the highest probability match and return the model toward advices. There's also a positive feedback loop which will affect the entire field of computing, where increased computing leads to better AI, leading to increased imputing due to new architectures, paradigms, devices, et cetera, produce via the machine learning models. And the loop goes on and on it. To note that there are countless directions the industry can end up taking. And the view stated here are my extrapolation based on the information we currently have. To add to this, there are some forms of computing we have yet to even discuss, such as photonics and bio or DNA computing a topic best slept for this channels future Biotech series. One thing is for certain, however, in the coming years and decades, computing will truly encompass everything. This is referred to as ubiquitous computing. Ubiquitous computing is a concept of computing fueled by the rise of abundant, affordable, and start computing devices. Or computing is done using any device in any way. And in any format. This can range from devices such as a laptop, desktop, and mobile phones to smartwatches, refrigerators, glasses, warehouse automation. The list has truly endless, along with a Global Admin Activity and big data, Ubiquitous Computing's and next pillar of the technological revolution that is currently occurring and will be covered in much more depth in this channel's video on ambient intelligence. Moving forward in the next set of videos on this channel will cover the final pillar of the Fourth Industrial Revolution, artificial intelligence. And then afterwards, how these pillars working in conjunction will impact and shape the future. When the video comes from conclusion, I'd like to thank you for taking that. This is the general introduction about tonal conferring or the future of computing, right? So, yeah, yeah, Nowadays fund a clade to the ED, bond dot clusters or through their mobile devices right there I neutrino computing et al, Coda sign. So in the next lecture I will show some of our research about that. Guys. I'm from Hollywood example on the edge and the robot, the branches together with the fun escape. I wasn't actually put the hunt with the recordings. I don't know if my complete this lecture. First thing. So, so fine, this natural, we have 120 welfare customized learning computing device. Or no, you can remember including the programmable with dancers dedicated for sensor in order to hit your genes might term the big inhale and IBM pulse write those methods, but with a general-purpose processors. Asked when visualize the programmable professor, they discuss and income Perry was the reconfigurable processor, murder FPGA, and I authored the application specific anti-British. So kids. All right, so after that we have demonstrated that big picture IBM cell broad, broad band anion. To demonstrate critical parts of it are genius medical system to provide the performance power, efficiency. So after bad. But tell me specific computing whilst where these thoughts, That's a day. Yeah, When Mel and that they'll means recipient computing bodies to develop or for me, specific computing system banning lucky Georgina system 2. And I'm going to do us monoclinic system. And it's comprised of many or it's bad for mix. The general purpose processors, special purpose processors, hardware accelerators, memory input, output devices as well. The programmable connections are just, they can even improve the performance of their EBIT patients raising a dummy. So as from examples, are all the application domains were shown before that the image or video processing run. So while we also need to be aware that evidence now we should compare the future of this kind of computing system. And we'll also need to consider that cisplatin, past, that community spirit, the power consumption. But these nine-week is Agile is there. And also the time-to-market before the implementation of the applications on this type of computing systems that are available for you. So for this lecture, last but not least, yeah, i 0 negative symbol about that. Today's AI applications where it touches every aspect of our lives, right? So including the transport, find, mass route, Chow, healthcare, smart manufacturing, education, Analysis Services. So AI technologies, they will be, and they're both run out Dark Age toy connected cars. Smart manufacturing, medical imaging with permission. For this, a lot off dominates our lab questions. So the question to ask ourself that, how can we leverage the power of the bandwidth for this diverse computing systems as we can. And also its legs are particles that afterthought that we're Magdeburg are, That's outdoor. Apologies. So the answer lies in that emerging new ecosystem designed to. But you'll note the unit is heterogeneous. Yes. Of the computing power as shown here, existing comparing proponents were. So yes, you all know we can bring the obstruction to cahoot games platforms as we discuss today or in the previous class. So as we're not exist lecture proportional know what their genius processors are widely available. They are new platforms. Where are we expected to leverage a huge amount of computing power? So this includes accelerating unit, gpu, FPGA, or Berg, all six, right? So yeah, they, you know, the, the AI, machine learning and neural networks. They are, and they're from forefront of this new computing paradigm and new lectures that day. I also needed to dress the math and computing probability of a millionaire by the superclass of basic computers. So liberating as opposed to the sperm present or expand your old, principally the postdoc with their Genius program. The modes for the heterogeneous computing hand not standardized. They have lack of powder bed today, so besotted. Well, I said it's row for that gene architecture at the community, actually Georgia Tech. So the challenge facing many industries it out agenda, existing architectures. I can share with us at about day in adequate affords this AI and also the big data workloads so that open computing Snapple off the heterogeneous system architecture. We also put an edge as a, they can offer the level solution this new brand of teacher will know. And finally, you will, of the opportunities and not being used off. Yeah, orthonormal starting or more computing power. And the rumors the data centers are there. Why did in use by the heterogeneous system architecture and the system designers also, they will find on the paragraph, efficient ecosystem. And then one defines specifically to or just for this or you know, burden or an area of computer architecture on the particles. So both the architectural design and the particles like I was on, all, the management should be also develop or Florida performers air will energy efficiency optimization. So this RPA design training for the like, the Kafir mind that all the special lines, the ADA about the emerging oxygenating fine also for the emerging applications today. So these are all the content for the guest lecture for the customize and emerging computing architecture design based on our base of knowledge about the computing architecture design. So the rest of the 50 minutes, I will show you the brief introduction of why we have now about that. Hardware, software, feature design here, including the meter stick, Algorithm Design, realization, hardware and software. So yeah, this you'll find from the main part all know about our research it by bother. Why weren't thoughtful work? If I yeah, this is not only the compluvium outage or does that mean that we're on the radio, you should define some software were to use this hardware resources, right? And also Fonda shall be in the gametes, form a clade to the, with the mobile devices or to the banks device. There are devices actually there that the more constraints on the resources. Or they called their resource constrained devices. What? We associate their own biases for them or their airway, monkeys, Darwin cast, and also their parent gray. Yeah, This other resources concentrate on these devices. So with this plan of computing lab features, how you can design some software are goods and all cellular approach is to use this resources with versus recognition of your performance or energy efficiency. So that's why we need to do the hardware software poets flourishing on that corner of architecture design. Yeah. So in this lecture, I will show you some recent research. Agendas. Either works eight hours, Let's go blah, blah, blah, codes for original hardware, software defined otherwise, those Constantine edge AI systems. So before going to the details of the techniques, I will actually show you some real examples here. So when we talk about the devices are abroad or resource console application. So in this example evening, most of them have the relationship between them. So actually with that technology development, you'll maybe for me with this devices, Rhonda Medicare, right? This is one called the implantable cardiac defibrillator. That is the ICD device. This has been implemented instead of the conventional external monitor machines. So there's an Icelandic advise is the fan power device basis the fan for unlimited, all the resource limited here. So this device will be implemented into the chest and placed on buses being that it can monitor the wisdom and his travel for highway. In addition, it can and also it can detect, but rather the heart rate for the patients. So this does saying, well it's unclear, connect to the ICD device to the heart. And this can deliver the electric shocks so bear one or more well connected to the heart in order to face abnormal heart rhythm. If abnormal or resumes detected the device work the neighbor at led to sharp to restore their normal heartbeat if your patient's heart is beating too slow or must toolbox, right? So I said you give biases have been very useful in the actual improve preventing southern desk and patient race. White noise is fun, but yeah, that is the February nation. So Stalin started, have shown that they may have a role in preventing cardiac arrest. High risk patients. Yeah. So this basis for use of this device here. So yeah, conventionally are not in the ICD device, the heuristic algorithm proposed afford the hotbed of detaching here embark device VM. However, even though this peak hours and are not accurate. What's war sometimes big one now deal with some corner cases flexor, constantly intimate. There will be more than 40 percent of your total shops, the partial or the heart rate. They think Oh, there we are missing. So that means the axis of the heuristic algorithm that's not high enough for detecting irregular heart rate. So the ink a accurately detection and also the amazing of the heart rate monitoring. Yeah, they are extended terrible for the patients based where sometimes results in the increase of the past into the Hamlet deporting and never left foot shocks in some places. So that is fireable here. Yet in order to save more lives a bite their ICT devices here actually, Today's one research team needed by the research report and mobile phone Stanford. They proposed to use the machine learning flatness for the heart rate detection. Yet in order to increase the accuracy, right? So according to the report, the machine learning approach works much better than the traditional heterocyclic adolescence and even better than the cardiologist Ed plan definitely encourage THE accuracy. However, you'll know whether the owner was emerging models. We know that the size of the motor is too large, right? Yeah. Even comparable to her was that I was not made it work done to process the machine learning models that make the merging learning approach is unknown. Why did it forward into the ICD devices? But due to the left side of the model, because you need to long time to process. That is their low latency. So since the existing approaches to increase the accuracy of the neural networks, they will design their large size of the neural network to improve the accuracy, including increased layers input, increase the number of neurons. So now neural network models can definitely are cheap the bear so detection accuracy even than the cardiologists. But in some cases show that the accuracy can be reached up to a person. So however, as we stare, models are the neural network architecture models with higher accuracy or you generate with a large side of the neural network architecture. So the light side of the neural network boiler heartbeat or zeros farmer, in this case. The latency. It'll take much longer time. And then we use a lot of battery power. That is not borrowing efficiency. One thing I'm limited to about how likely the device due to the limited resources device because a, the battery-powered here as well use that example is shown here on the existing data integrated into the ice and the biosphere. That is a microchip here, there and unlimited memory size of the less than 200 or RAM and limited storage about the sram here. So when your rotational models implemented under microchip in this place, I chaired the memory capacity so far for meeting, but for the efficient deployment of the neural model on this device, that is not possible to deploy the model on this device. So they're following. We find that the machine learning approaches can only work for the in vitro barrel RDs with the relative no resources are that device, rather than hard to be deployed in the implantable devices, are due to the resource limitation on this device. What's wrong? What's more is that the expected computing machine learning mode in the ICD device. It cannot guarantee it the rack, which funds for the person. It takes long to phone the detection and the template, the accuracy and report the results to the, to the outside minor or cheapest manager to report the cases. So there are some challenges. Here are the latency and also the resource limitation on but the advice. So yeah, we can observe that one machine, no NMOS, but not only to this example, right? When the machine learning models implemented in this mobile device, if all of this resource limited. Devices, they are or so crossings on every expression for the isolated device, right? And also the power, the latency for eagle addition to the accuracy for the parent isotope device into or achieve the accuracy that should be higher than 72. Yeah, I didn't achieve 78. And also the area of the device will be better to this monarch enough, right, to be in Berlin at accion, to be in inches or chairs. Tuesday, I'm graded on a single device. Wherever you know the power they limited, the operation should be across is the power efficiency. Last time we know that the ICD-10 should be. Or to be able to give the rapid response with a short latency. That is to say the computation or other devices should have higher performance. So conventional approaches for the immersion when loaded into achieve higher accuracy. We started large size as it was shown in the previous slides. So however, there are restate, all straight resource constraints or the area power in Edge devices or mobile devices. And the reasons constants should be consider when that, when we optimize the accuracy of the model, right? Actually, there are also the strategy Mbeki bears moment of other applications including the voice translation in the AI glasses, smartphone, the smartphone, self-driving, cream detection, and also the beauty. So this program issues brought by developing machine learning murdered in their resource constantly. Advice if they urge you to be solved. So also not be spend that time and now the original but HBR that, you know, and the one we are all concerned about, our job security prospects due to the coronavirus had mat bending, right? It's good. You know, that there are new pass it to its though they feel working worm infection or the health care. It's David Park in Beijing. I was in February or from Mumbai. So well, actually, there's that force or Arthur application form, the Medical Medicare applications. They showed that their head is urging to do some optimization for deploying the machine learning models in the resource pumping devices, including the quad word is fine. Based on the basic components of their computing components we're going to use. Together with our software management. Approaches lecture defines our neural networks. Although this plan of panels together to solve these challenges appeal. So this is the only had the example or the motivation for the design here. In a next class, what I want to show some real size or bought hardware together with your software. Yeah, the frameworks for you, including why we learn about the FPGA and also the sphere and doing some parabolic system on chip, what they want to work on chip. So they sense the other day and I will share more details next class. Thank you so much for coming. Thank you. Take care of this line. I will. Yeah. Sanctuary. I support that.